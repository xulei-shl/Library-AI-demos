# CNKI文献批量爬取与管理工具

## ✨ 简介

CNKI文献批量爬取与管理工具是一款旨在简化CNKI文献获取流程的自动化工具。它通过模拟浏览器操作，实现文献元数据批量下载和PDF全文获取。本工具设计为5个核心步骤。

![](https://xulei-pic-1258542021.cos.ap-shanghai.myqcloud.com/mdpic/20250817172344.png)

## 🚀 核心功能

> excel文件样例见`examples`文件夹，只要提供相同格式的excel文件，即可执行相关步骤。


1.  **🤖 检索词智能生成**：
    *   输入初始检索主题词，调用大模型（LLM）生成更多概念相关检索词。
2.  **🔍 文献元数据批量爬取**：
    *   一键从知网（CNKI）获取文献的标题、作者、摘要、DOI等元数据，并导出为`.xls`文件。
    *   支持自定义时间范围、核心期刊筛选和最大结果数量设置。
3.  **📊 Excel数据合并与去重**：
    *   合并多个已下载的`.xls`文献元数据文件。
    *   数据去重：首先根据DOI，其次根据“题名+作者+来源”组合，最终生成`.xlsx`文件。
4.  **📈 文献相关性分析**：
    *   调用大模型分析文献是否符合主题要求。
5.  **📄 PDF全文批量下载**：
    *   根据合并后的Excel文件中的PDF链接，模拟人工操作批量下载文献的PDF全文。
  

## ⚠️ 重要提示与注意事项

*   **自动化原理**：本工具主要通过模拟人工的浏览器自动化操作来完成任务。
*   **执行速度**：为避免被CNKI识别为机器人，每个步骤都加入了随机延迟，因此执行速度并非极快，请耐心等待。
*   **人工干预**：
    *   **PDF下载验证码**：在步骤5首次打开PDF链接时，可能会遇到**验证码**，需要您进行一次**人工操作**。之后通常无需人工干预。
    *   除上述验证码外，其他步骤在您点击相关执行按钮后，均可实现电脑自动操作，无需人工持续干预。
*   **数据保存**：所有爬取和下载的数据都将保存在您选择的文件夹中。
*   **使用频率**：请合理使用本工具，避免过于频繁或大量爬取，以免触发知网的反爬机制。

## ⚙️ 前置条件与配置

### 1. 前置条件

*   **Python环境**：确保已安装 Python 3.8 或更高版本，并配置好 `pip` 包管理器。
    *   如果您不确定如何安装Python，可参考：[https://blog.csdn.net/thefg/article/details/128601410](https://blog.csdn.net/thefg/article/details/128601410)
*   **网络连接**：首次运行程序时，会自动下载浏览器驱动，请保持网络连接畅通。

### 2. LLM API 配置（可选，用于步骤1和步骤4）

本工具支持大模型（LLM）驱动的检索词生成（步骤1）和未来计划的文献相关性分析（步骤4）。

*   **默认模型**：默认使用免费的 `glm-4.5-flash` 模型。
*   **API Key申请**：您可以前往智谱AI平台申请API Key：[https://www.bigmodel.cn/invite?icode=PsQdPNHClZQ5IylmOOVTV7Y6%2FPWzOncT7%2Fq38lm1d20%3D](https://www.bigmodel.cn/invite?icode=PsQdPNHClZQ5IylmOOVTV7Y6%2FPWzOncT7%2Fq38lm1d20%3D)
*   **自定义配置**：您也可以在“配置管理”中自行配置其他兼容OpenAI格式的LLM API。

## 💻 安装指南

1. **安装Python依赖**：

   ```bash
   pip install -r requirements.txt
   ```

2. **安装浏览器驱动**：

   ```bash
   playwright install
   ```

3. **运行程序**：

   ```bash
   python main_gui.py
   ```

## 📝 使用教程

### 步骤1：检索词智能生成

1.  在左侧输入框中输入您感兴趣的主题关键词。
2.  点击“🚀 生成检索词”按钮。
3.  右侧会显示大模型生成的专业检索词，您可以直接编辑、复制使用，或保存到本地。

### 步骤2：文献元数据批量爬取

1.  在检索词输入框中填入检索词（可从步骤1复制）。
2.  选择文献的时间范围（“最近一年”或“自定义年份”）。
3.  勾选“是否只搜索核心期刊”选项（可选）。
4.  设置“最大结果数量”以控制爬取量。
5.  点击“预检索”按钮，仅执行结果数量统计；点击“开始爬取”按钮，则执行完整的文献检索与元数据下载。
6.  右侧的日志区会实时显示爬取进度和相关信息。

### 步骤3：Excel数据合并与去重

1.  点击“选择文件”按钮，选择一个或多个已通过步骤2下载的`.xls`文献元数据文件。
2.  点击“合并文件”按钮。
3.  程序将自动对选定的文件进行去重（优先DOI，其次“题名+作者+来源”），并生成一个合并后的`.xlsx`文件。

### 步骤4：文献相关性分析

1.  点击"选择文件"按钮，选择包含文献元数据的Excel文件（通常是步骤3合并后的`.xlsx`文件）。
2.  在"研究主题"输入框中输入您的研究主题关键词（如"智慧教育"、"人工智能教育"等）。
3.  点击"开始分析"按钮，系统将调用大模型对每篇文献进行相关性评分。
4.  分析过程中，右侧日志区域会实时显示进度和结果。
5.  分析完成后，系统会自动生成评分统计结果，并将评分结果保存到原Excel文件中。
    * 评分标准：9-10分（高度相关）、7-8分（相关性较高）、5-6分（中等相关）、3-4分（相关性较低）、1-2分（几乎无关）
    * 结果包含：相关性评分、评分理由、分析状态等信息。

### 步骤5：PDF全文批量下载

1.  点击“选择文件”按钮，选择包含文献元数据和PDF链接的Excel文件（通常是步骤3合并后的`.xlsx`文件）。
2.  根据需要设置下载参数，如保存路径。
3.  点击“开始下载”按钮。
4.  程序将自动批量下载PDF文件。请注意，首次下载时可能会遇到验证码，需人工处理。

## 🔧 设置项

配置项保存到`config.json`文件中。首次使用时，请将`config.example.json`复制为`config.json`并填入您的个人配置。

> **注意**：`config.json`文件包含API密钥等敏感信息，已通过`.gitignore`设置为不会上传到GitHub。

### 配置管理

在“配置管理”标签页，您可以：

*   保存常用的检索设置，方便下次快速调用。
*   设置默认的文件保存路径。
*   配置LLM API密钥及选择模型。

### 提示词管理

在“提示词管理”标签页，您可以：

*   编辑用于检索词生成的大模型提示模板，以优化生成效果。
*   自定义文献相关性判断规则（此功能将随步骤4开发）。