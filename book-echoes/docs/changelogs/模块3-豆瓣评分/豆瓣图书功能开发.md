# è±†ç“£å›¾ä¹¦åŠŸèƒ½é›†æˆå¼€å‘æ–‡æ¡£

## ğŸ“‹ åŠŸèƒ½æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°å¦‚ä½•å°†è±†ç“£å›¾ä¹¦ä¿¡æ¯çˆ¬å–åŠŸèƒ½é›†æˆåˆ°Book Echoesé¡¹ç›®ä¸­ï¼Œä¸ISBNè·å–åŠŸèƒ½å®ç°åŒæ­¥å¤„ç†ã€‚

### æ ¸å¿ƒéœ€æ±‚
1. **åŒæ­¥å¤„ç†**ï¼šISBNè·å–å’Œè±†ç“£çˆ¬å–åŒæ—¶è¿›è¡Œï¼Œåªè¦æŸä¸€è¡Œè·å–åˆ°æœ‰æ•ˆISBNï¼ˆé"çˆ¬å–å¤±è´¥"ï¼‰ï¼Œç«‹å³æ‰§è¡Œè±†ç“£çˆ¬å–
2. **é…ç½®ç»Ÿä¸€**ï¼šä½¿ç”¨é¡¹ç›®çš„ç»Ÿä¸€é…ç½®ç®¡ç†ï¼ˆconfig/setting.yamlï¼‰ï¼Œæ›¿ä»£åŸæœ‰çš„config.json
3. **å³æ—¶å†™å…¥**ï¼šæˆåŠŸè·å–ä¸€æ¡è±†ç“£ä¿¡æ¯ï¼Œç«‹å³å†™å›åŸExcelï¼ˆæ–°å¢åˆ—ï¼‰
4. **ä¼šè¯é‡ç”¨**ï¼šæ‰€æœ‰æ•°æ®çˆ¬å–ç»“æŸåå†å…³é—­æµè§ˆå™¨ï¼Œé¿å…é‡å¤ç™»å½•

## ğŸ—ï¸ é›†æˆæ–¹æ¡ˆè®¾è®¡

### 1. æ•´ä½“æ¶æ„

```
ISBNè·å– â†’ è±†ç“£çˆ¬å– â†’ æ•°æ®å†™å…¥
    â†“         â†“         â†“
å¼‚æ­¥å¤„ç†   æµè§ˆå™¨æ±     Excelæ›´æ–°
```

### 2. æ•°æ®æµè®¾è®¡

```mermaid
graph TD
    A[è¯»å–Excel] --> B[è·å–æ¡ç åˆ—]
    B --> C[å¼‚æ­¥è·å–ISBN]
    C --> D{ISBNæœ‰æ•ˆ?}
    D -->|æ˜¯| E[å¯åŠ¨è±†ç“£çˆ¬å–]
    D -->|å¦| F[æ ‡è®°å¤±è´¥]
    E --> G[çˆ¬å–è±†ç“£ä¿¡æ¯]
    G --> H[å†™å…¥Excelæ–°åˆ—]
    H --> I{ç»§ç»­å¤„ç†?}
    I -->|æ˜¯| C
    I -->|å¦| J[å…³é—­æµè§ˆå™¨]
    F --> I
```

### 3. æ ¸å¿ƒæ¨¡å—è®¾è®¡

#### 3.1 é›†æˆå¤„ç†å™¨ (douban_rating_processor.py)
- ä½ç½®ï¼š`src/core/douban/`
- èŒè´£ï¼šåè°ƒISBNè·å–å’Œè±†ç“£çˆ¬å–çš„åŒæ­¥æ‰§è¡Œ
- ç‰¹æ€§ï¼š
  - ç»§æ‰¿ç°æœ‰å¼‚æ­¥ISBNå¤„ç†å™¨
  - é›†æˆè±†ç“£çˆ¬è™«åŠŸèƒ½
  - å®æ—¶Excelå†™å…¥
  - æµè§ˆå™¨ä¼šè¯ç®¡ç†

#### 3.2 è±†ç“£çˆ¬è™«é€‚é…å™¨ (douban_crawler_adapter.py)
- ä½ç½®ï¼š`src/core/douban/crawler/`
- èŒè´£ï¼šå°†å‚è€ƒä»£ç é€‚é…åˆ°é¡¹ç›®æ¶æ„
- ç‰¹æ€§ï¼š
  - ä¿æŒæ ¸å¿ƒçˆ¬å–é€»è¾‘ä¸å˜
  - ç»Ÿä¸€é…ç½®ç®¡ç†
  - é”™è¯¯å¤„ç†å¢å¼º
  - æ•°æ®æ ¼å¼åŒ–

## ğŸ”‘ æ ¸å¿ƒé€‚é…è¦ç‚¹

### 1. ä¿æŒæ ¸å¿ƒé€»è¾‘ä¸å˜
æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼Œ**è±†ç“£çˆ¬å–çš„æ ¸å¿ƒé€»è¾‘ï¼ˆç™»å½•ã€æ£€ç´¢ã€çˆ¬å–ï¼‰å¿…é¡»ä¿æŒå®Œå…¨ä¸å˜**ï¼š

âœ… **ä¿æŒä¸å˜çš„éƒ¨åˆ†**ï¼š
- `search_handler.py`ä¸­çš„ISBNæœç´¢æµç¨‹
- `detail_extractor.py`ä¸­çš„è¯¦æƒ…æå–æ–¹æ³•
- `login_handler.py`ä¸­çš„ç™»å½•é€»è¾‘
- æ•°æ®å­—æ®µæ˜ å°„å’Œè§£ææ–¹å¼

ğŸ”§ **éœ€è¦é€‚é…çš„éƒ¨åˆ†**ï¼š
- åŒæ­¥API â†’ å¼‚æ­¥APIè½¬æ¢
- config.json â†’ setting.yamlé…ç½®è¿ç§»
- ç‹¬ç«‹è¿è¡Œ â†’ æ¨¡å—é›†æˆ
- å•ç‹¬ä¿å­˜ â†’ å®æ—¶å†™å…¥åŸExcel

### 2. åŒæ­¥å¤„ç†æœºåˆ¶

**å…³é”®è®¾è®¡**ï¼šISBNè·å–å’Œè±†ç“£çˆ¬å–åŒæ­¥è¿›è¡Œ

```python
async def process_row(index, row):
    """å¤„ç†å•è¡Œæ•°æ® - ISBNè·å– + è±†ç“£çˆ¬å–"""
    barcode = row['ä¹¦ç›®æ¡ç ']
    isbn = row['ISBNå·']

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆISBN
    if not is_valid_isbn(isbn):
        # ä»FOLIOç³»ç»Ÿè·å–ISBN
        isbn = await isbn_worker.get_isbn(barcode)
        df.at[index, 'ISBNå·'] = isbn

    # åªè¦ISBNæœ‰æ•ˆï¼ˆé"çˆ¬å–å¤±è´¥"ï¼‰ï¼Œç«‹å³æ‰§è¡Œè±†ç“£çˆ¬å–
    if is_valid_isbn(isbn):
        book_info = await douban_crawler.crawl_by_isbn(isbn)

        # å®æ—¶å†™å…¥Excelï¼ˆæ–°å¢åˆ—ï¼‰
        if book_info:
            for field, value in book_info.items():
                col_name = DOUBAN_FIELDS[field]
                df.at[index, col_name] = value
        else:
            df.at[index, 'è±†ç“£ä¹¦å'] = "è±†ç“£çˆ¬å–å¤±è´¥"
```

### 3. æµè§ˆå™¨ä¼šè¯ç®¡ç†

å‚è€ƒ`douban_spider.py:136-181`ï¼Œ**å•å®ä¾‹é‡ç”¨æ¨¡å¼**ï¼š

```python
# åœ¨æ•´ä¸ªExcelå¤„ç†è¿‡ç¨‹ä¸­åªå¯åŠ¨ä¸€æ¬¡æµè§ˆå™¨
async def full_process():
    # 1. å¯åŠ¨æµè§ˆå™¨ï¼ˆåªåœ¨å¼€å§‹æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰
    await spider.start_driver()

    try:
        # 2. éå†æ‰€æœ‰è¡Œ
        for index, row in df.iterrows():
            # 3. ISBNè·å– + è±†ç“£çˆ¬å–
            await process_row(index, row)

            # 4. å®æ—¶ä¿å­˜ï¼ˆæ¯10æ¡ä¿å­˜ä¸€æ¬¡ï¼‰
            if index % 10 == 0:
                save_progress(df)

    finally:
        # 5. æ‰€æœ‰æ•°æ®å¤„ç†å®Œæ‰å…³é—­æµè§ˆå™¨
        await spider.close_driver()
```

### 4. Excelå®æ—¶å†™å…¥ç­–ç•¥

**é¿å…æ•°æ®ä¸¢å¤±çš„å†™å…¥æœºåˆ¶**ï¼š

```python
def save_progress(df, output_path, is_final=False):
    """ä¿å­˜è¿›åº¦åˆ°Excel"""
    if is_final:
        # æœ€ç»ˆä¿å­˜ï¼šè¦†ç›–åŸæ–‡ä»¶æˆ–ç”Ÿæˆæ–°æ–‡ä»¶
        df.to_excel(output_path, index=False)
    else:
        # ä¸­é—´ä¿å­˜ï¼šç”Ÿæˆä¸´æ—¶æ–‡ä»¶
        temp_path = output_path.replace('.xlsx', f'_temp_{timestamp}.xlsx')
        df.to_excel(temp_path, index=False)

    logger.info(f"è¿›åº¦å·²ä¿å­˜ - æ€»è®°å½•: {len(df)}, å·²å¤„ç†: {len(df[df['ISBNå·'] != ''])}")
```

## âš™ï¸ é…ç½®è®¾è®¡

### ä¿®æ”¹config/setting.yaml

åœ¨`douban`é…ç½®ä¸‹æ–°å¢ï¼š

```yaml
douban:
  # è±†ç“£çˆ¬è™«é…ç½®ï¼ˆæ–°å¢ï¼‰
  douban_crawler:
    enabled: true
    base_url: "https://book.douban.com"
    headless: false  # ç”Ÿäº§ç¯å¢ƒå»ºè®®true
    delay: 1.0  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰

    # ç™»å½•é…ç½®
    login:
      auto_login: false  # æ˜¯å¦å¯ç”¨è‡ªåŠ¨ç™»å½•
      timeout: 30  # ç™»å½•è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    # çˆ¬å–é…ç½®
    crawl:
      retry_times: 3  # å¤±è´¥é‡è¯•æ¬¡æ•°
      timeout: 15  # é¡µé¢åŠ è½½è¶…æ—¶ï¼ˆç§’ï¼‰
      enable_stealth: true  # å¯ç”¨åæ£€æµ‹

    # æ•°æ®å­—æ®µæ˜ å°„
    fields:
      title: "è±†ç“£ä¹¦å"
      author: "è±†ç“£ä½œè€…"
      publisher: "è±†ç“£å‡ºç‰ˆç¤¾"
      rating: "è±†ç“£è¯„åˆ†"
      rating_count: "è±†ç“£è¯„ä»·äººæ•°"
      pub_date: "è±†ç“£å‡ºç‰ˆå¹´"
      price: "è±†ç“£ä»·æ ¼"
      cover_url: "è±†ç“£å°é¢é“¾æ¥"
      summary: "è±†ç“£å†…å®¹ç®€ä»‹"

  # åŸæœ‰ISBNè·å–é…ç½®ä¿æŒä¸å˜...
  isbn_processor:
    strategy: "custom"
    custom:
      max_concurrent: 4
      # ... å…¶ä»–é…ç½®
```

## ğŸ“ å®æ–½æ­¥éª¤

### ç¬¬ä¸€é˜¶æ®µï¼šä»£ç é€‚é…ï¼ˆ1-2å¤©ï¼‰

#### 1.1 åˆ›å»ºè±†ç“£çˆ¬è™«é€‚é…å™¨

**é€‚é…ç­–ç•¥**ï¼šåŒæ­¥ä»£ç å¼‚æ­¥åŒ–ï¼Œä¿æŒæ ¸å¿ƒé€»è¾‘ä¸å˜

```python
# src/core/douban/crawler/douban_crawler_adapter.py

import asyncio
import logging
from typing import Optional, Dict, Any
from playwright.async_api import Page, TimeoutError as PlaywrightTimeoutError
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class DoubanCrawlerAdapter:
    """è±†ç“£çˆ¬è™«é€‚é…å™¨ - é€‚é…ç°æœ‰é¡¹ç›®æ¶æ„

    æ ¸å¿ƒè¦æ±‚ï¼šä¿æŒ docs/refs/douban-spider/src/ ä¸­çš„æ ¸å¿ƒé€»è¾‘å®Œå…¨ä¸å˜
    ä»…è¿›è¡Œå¼‚æ­¥åŒ–æ”¹é€ å’Œé…ç½®é€‚é…
    """

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.page: Optional[Page] = None
        self.base_url = config.get('base_url', 'https://book.douban.com')
        self.delay = config.get('delay', 1.0)

        # ç™»å½•çŠ¶æ€ç®¡ç†ï¼ˆå‚è€ƒ search_handler.py:33-36ï¼‰
        self.login_completed = False
        self.login_attempted = False

    async def init_browser(self, page: Page):
        """åˆå§‹åŒ–æµè§ˆå™¨ - å¯¹åº” base_spider çš„åŠŸèƒ½"""
        self.page = page
        logger.info("è±†ç“£çˆ¬è™«æµè§ˆå™¨å·²åˆå§‹åŒ–")

    async def crawl_by_isbn(self, isbn: str) -> Optional[Dict[str, Any]]:
        """
        é€šè¿‡ISBNçˆ¬å–è±†ç“£å›¾ä¹¦ä¿¡æ¯

        è¿™æ˜¯ä¸»è¦æ¥å£ï¼Œå‚è€ƒ douban_spider.py:87-115 çš„æµç¨‹
        """
        try:
            logger.info(f"å¼€å§‹çˆ¬å–è±†ç“£ä¿¡æ¯ - ISBN: {isbn}")
            logger.debug(f"ç™»å½•çŠ¶æ€: login_attempted={self.login_attempted}, login_completed={self.login_completed}")

            # 1. æœç´¢ISBNè·å–è¯¦æƒ…é¡µé“¾æ¥ï¼ˆå‚è€ƒ search_handler.py:38-93ï¼‰
            book_url = await self._search_by_isbn(isbn)
            if not book_url:
                logger.warning(f"æœªæ‰¾åˆ°ISBN {isbn} å¯¹åº”çš„å›¾ä¹¦")
                return None

            # 2. æå–è¯¦æƒ…ä¿¡æ¯ï¼ˆå‚è€ƒ detail_extractor.py:37-94ï¼‰
            book_info = await self._extract_details(book_url)
            if book_info:
                logger.info(f"æˆåŠŸè·å– {isbn} çš„è±†ç“£ä¿¡æ¯")
            else:
                logger.warning(f"æ— æ³•æå– {isbn} çš„è¯¦æƒ…ä¿¡æ¯")

            return book_info

        except Exception as e:
            logger.error(f"è±†ç“£çˆ¬å–å¤±è´¥ - ISBN: {isbn}, é”™è¯¯: {e}")
            return None

    async def _search_by_isbn(self, isbn: str) -> Optional[str]:
        """å¼‚æ­¥æœç´¢ISBNï¼ˆå‚è€ƒ search_handler.py åŒæ­¥å®ç°ï¼‰"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                logger.debug(f"æœç´¢ISBN {isbn} - ç¬¬ {attempt + 1} æ¬¡å°è¯•")

                # 1. è®¿é—®è±†ç“£å›¾ä¹¦é¦–é¡µï¼ˆå‚è€ƒ search_handler.py:64-67ï¼‰
                await self.page.goto(
                    "https://book.douban.com",
                    wait_until="networkidle",
                    timeout=30000
                )
                await self._random_delay()

                # 2. æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼ˆå‚è€ƒ search_handler.py:69-83ï¼‰
                if not self.login_attempted:
                    if await self._check_login_page():
                        logger.warning("æ£€æµ‹åˆ°éœ€è¦ç™»å½•")
                        # è¿™é‡Œå¯ä»¥è°ƒç”¨ç™»å½•å¤„ç†é€»è¾‘
                        self.login_attempted = True
                        # å¦‚æœç™»å½•å¤±è´¥ï¼Œå¯èƒ½éœ€è¦ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•

                # 3. æ‰§è¡Œæœç´¢ï¼ˆå‚è€ƒ search_handler.py:_perform_searchï¼‰
                return await self._perform_search(isbn)

            except PlaywrightTimeoutError:
                logger.warning(f"æœç´¢è¶…æ—¶ - ç¬¬ {attempt + 1} æ¬¡å°è¯•")
                if attempt == max_retries - 1:
                    return None
                await asyncio.sleep(2)

            except Exception as e:
                logger.error(f"æœç´¢å‡ºé”™ - ç¬¬ {attempt + 1} æ¬¡å°è¯•: {e}")
                if attempt == max_retries - 1:
                    return None
                await asyncio.sleep(2)

        return None

    async def _perform_search(self, isbn: str) -> Optional[str]:
        """æ‰§è¡Œæœç´¢æ“ä½œï¼ˆå‚è€ƒ search_handler.py å†…éƒ¨æ–¹æ³•ï¼‰"""
        try:
            # æ„å»ºæœç´¢URL
            search_url = f"https://search.douban.com/book/subject_search?search_text={isbn}&cat=1001"

            await self.page.goto(search_url, wait_until="domcontentloaded", timeout=20000)
            await self._random_delay()

            # è§£ææœç´¢ç»“æœé¡µé¢
            html = await self.page.content()
            soup = BeautifulSoup(html, 'html.parser')

            # æå–ç¬¬ä¸€ä¸ªæœç´¢ç»“æœé“¾æ¥ï¼ˆå‚è€ƒæœç´¢ç»“æœè§£æé€»è¾‘ï¼‰
            result = self._parse_search_results(soup)
            return result

        except Exception as e:
            logger.error(f"æ‰§è¡Œæœç´¢å¤±è´¥: {e}")
            return None

    def _parse_search_results(self, soup: BeautifulSoup) -> Optional[str]:
        """è§£ææœç´¢ç»“æœï¼ˆä¿æŒåŸæœ‰é€»è¾‘ä¸å˜ï¼‰"""
        # å‚è€ƒ search_handler.py ä¸­çš„è§£æé€»è¾‘
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå›¾ä¹¦è¯¦æƒ…é¡µé“¾æ¥
        items = soup.select('.subject-item .pic a')
        if items:
            return items[0].get('href')

        return None

    async def _extract_details(self, url: str) -> Optional[Dict[str, Any]]:
        """å¼‚æ­¥æå–è¯¦æƒ…ï¼ˆå‚è€ƒ detail_extractor.py åŒæ­¥å®ç°ï¼‰"""
        try:
            # 1. å¤šå±‚çº§è¶…æ—¶è®¿é—®ï¼ˆå‚è€ƒ detail_extractor.py:50-66ï¼‰
            try:
                await self.page.goto(
                    url,
                    wait_until="domcontentloaded",
                    timeout=25000
                )
            except PlaywrightTimeoutError:
                logger.warning("domcontentloadedè¶…æ—¶ï¼Œå°è¯•networkidle...")
                try:
                    await self.page.goto(
                        url,
                        wait_until="networkidle",
                        timeout=20000
                    )
                except PlaywrightTimeoutError:
                    logger.warning("networkidleä¹Ÿè¶…æ—¶ï¼Œä½¿ç”¨åŸºæœ¬åŠ è½½...")
                    await self.page.goto(url, timeout=15000)

            await self._random_delay(page_type="detail")

            # 2. æ£€æŸ¥ç™»å½•é¡µé¢ï¼ˆå‚è€ƒ detail_extractor.py:68-71ï¼‰
            if await self._check_login_page():
                logger.error("è¯¦æƒ…é¡µéœ€è¦ç™»å½•è®¿é—®")
                return {}

            # 3. æå–ä¿¡æ¯ï¼ˆå‚è€ƒ detail_extractor.py:94-110ï¼‰
            html = await self.page.content()
            soup = BeautifulSoup(html, 'html.parser')

            # éªŒè¯é¡µé¢æ˜¯å¦æœ‰æ•ˆï¼ˆå‚è€ƒ detail_extractor.py:89ï¼‰
            if not self._validate_page(soup):
                return {}

            # 4. æå–å„é¡¹å­—æ®µï¼ˆä¿æŒåŸæœ‰æå–é€»è¾‘ä¸å˜ï¼‰
            return {
                'é“¾æ¥': url,
                'è¯„åˆ†': self._extract_rating(soup),
                'é¢˜å': self._extract_title(soup),
                'ä½œè€…': self._extract_author(soup),
                'å‡ºç‰ˆç¤¾': self._extract_publisher(soup),
                'å‡ºå“æ–¹': self._extract_producer(soup),
                'ä¸›ä¹¦': self._extract_series(soup),
                'å®šä»·': self._extract_price(soup),
                'ISBN': self._extract_isbn(soup),
                'é¡µæ•°': self._extract_pages(soup),
                'è£…å¸§': self._extract_binding(soup),
                'å‡ºç‰ˆå¹´': self._extract_pub_year(soup),
                'è¯„ä»·äººæ•°': self._extract_rating_count(soup),
                'å†…å®¹ç®€ä»‹': self._extract_summary(soup),
                'ä½œè€…ç®€ä»‹': self._extract_author_intro(soup),
                'ç›®å½•': self._extract_catalog(soup),
            }

        except Exception as e:
            logger.error(f"æå–è¯¦æƒ…å¤±è´¥: {e}")
            return None

    # ========== ä»¥ä¸‹æ˜¯ä¿æŒåŸæœ‰é€»è¾‘çš„è¾…åŠ©æ–¹æ³• ==========
    # è¿™äº›æ–¹æ³•éœ€è¦ä»å‚è€ƒä»£ç ä¸­å¤åˆ¶ï¼Œä¿æŒå®Œå…¨ä¸å˜

    async def _random_delay(self, page_type: str = "search"):
        """éšæœºå»¶è¿Ÿï¼ˆå‚è€ƒ base_spider.py çš„éšæœºå»¶è¿Ÿæœºåˆ¶ï¼‰"""
        import random
        delay = self.delay + random.uniform(0, 0.5)
        await asyncio.sleep(delay)

    async def _check_login_page(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•ï¼ˆå‚è€ƒ login_handler.pyï¼‰"""
        try:
            # æ£€æŸ¥é¡µé¢æ˜¯å¦åŒ…å«ç™»å½•ç›¸å…³å…ƒç´ 
            content = await self.page.content()
            if 'ç™»å½•' in content or 'login' in content.lower():
                return True
            return False
        except:
            return False

    def _validate_page(self, soup: BeautifulSoup) -> bool:
        """éªŒè¯é¡µé¢æ˜¯å¦æœ‰æ•ˆï¼ˆå‚è€ƒ detail_extractor.py:_validate_detail_pageï¼‰"""
        # æ£€æŸ¥é¡µé¢æ˜¯å¦åŒ…å«é¢„æœŸçš„å…ƒç´ 
        if soup.select('h1') or soup.select('.subject') or soup.select('#info'):
            return True
        return False

    # æ‰€æœ‰ _extract_* æ–¹æ³•éƒ½éœ€è¦ä» detail_extractor.py å¤åˆ¶
    # ä¿æŒåŸæœ‰é€»è¾‘å®Œå…¨ä¸å˜
    def _extract_rating(self, soup: BeautifulSoup) -> str:
        """æå–è¯„åˆ†"""
        # ä» detail_extractor.py å¤åˆ¶å®ç°
        pass

    def _extract_title(self, soup: BeautifulSoup) -> str:
        """æå–ä¹¦å"""
        # ä» detail_extractor.py å¤åˆ¶å®ç°
        pass

    # ... å…¶ä»– _extract_* æ–¹æ³•
```

#### 1.2 åˆ›å»ºé›†æˆå¤„ç†å™¨

**è®¾è®¡ç†å¿µ**ï¼šä¸ISBNå¼‚æ­¥å¤„ç†å™¨é›†æˆï¼ŒåŒæ­¥æ‰§è¡Œæµç¨‹

```python
# src/core/douban/douban_rating_processor.py

import pandas as pd
import asyncio
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
from datetime import datetime

from src.utils.logger import get_logger
from src.utils.config_manager import get_config_manager
from .douban_rating_processor_config import DoubanRatingConfig
from .crawler.douban_crawler_adapter import DoubanCrawlerAdapter
from .isbn_async_processor import AsyncBrowserWorker  # å¤ç”¨ISBNå¤„ç†å™¨

logger = get_logger(__name__)

class DoubanRatingProcessor:
    """è±†ç“£è¯„åˆ†å¤„ç†å™¨ - é›†æˆISBNè·å–å’Œè±†ç“£çˆ¬å–

    æ ¸å¿ƒæµç¨‹ï¼š
    1. è¯»å–Excel
    2. éå†æ¯ä¸€è¡Œï¼š
       a. å¦‚æœæ²¡æœ‰ISBNï¼Œä»FOLIOç³»ç»Ÿè·å–
       b. å¦‚æœæœ‰æœ‰æ•ˆISBNï¼Œç«‹å³æ‰§è¡Œè±†ç“£çˆ¬å–
       c. å®æ—¶å†™å…¥Excel
    3. æ‰€æœ‰æ•°æ®å¤„ç†å®Œå…³é—­æµè§ˆå™¨
    """

    def __init__(self, config: DoubanRatingConfig):
        self.config = config
        self.crawler_adapter = DoubanCrawlerAdapter(config.crawler)
        self.isbn_worker: Optional[AsyncBrowserWorker] = None

        # Excelå­—æ®µæ˜ å°„ï¼ˆå‚è€ƒdetail_extractor.pyè¿”å›çš„å­—æ®µï¼‰
        self.field_mapping = {
            'é“¾æ¥': config.fields.get('url', 'è±†ç“£é“¾æ¥'),
            'è¯„åˆ†': config.fields.get('rating', 'è±†ç“£è¯„åˆ†'),
            'é¢˜å': config.fields.get('title', 'è±†ç“£ä¹¦å'),
            'ä½œè€…': config.fields.get('author', 'è±†ç“£ä½œè€…'),
            'å‡ºç‰ˆç¤¾': config.fields.get('publisher', 'è±†ç“£å‡ºç‰ˆç¤¾'),
            'å‡ºå“æ–¹': config.fields.get('producer', 'è±†ç“£å‡ºå“æ–¹'),
            'ä¸›ä¹¦': config.fields.get('series', 'è±†ç“£ä¸›ä¹¦'),
            'å®šä»·': config.fields.get('price', 'è±†ç“£å®šä»·'),
            'ISBN': config.fields.get('isbn', 'è±†ç“£ISBN'),
            'é¡µæ•°': config.fields.get('pages', 'è±†ç“£é¡µæ•°'),
            'è£…å¸§': config.fields.get('binding', 'è±†ç“£è£…å¸§'),
            'å‡ºç‰ˆå¹´': config.fields.get('pub_year', 'è±†ç“£å‡ºç‰ˆå¹´'),
            'è¯„ä»·äººæ•°': config.fields.get('rating_count', 'è±†ç“£è¯„ä»·äººæ•°'),
            'å†…å®¹ç®€ä»‹': config.fields.get('summary', 'è±†ç“£å†…å®¹ç®€ä»‹'),
            'ä½œè€…ç®€ä»‹': config.fields.get('author_intro', 'è±†ç“£ä½œè€…ç®€ä»‹'),
            'ç›®å½•': config.fields.get('catalog', 'è±†ç“£ç›®å½•'),
        }

    async def process_excel(
        self,
        excel_file_path: str,
        barcode_column: str = "ä¹¦ç›®æ¡ç ",
        isbn_column: str = "ISBNå·",
        username: Optional[str] = None,
        password: Optional[str] = None
    ) -> Tuple[str, Dict[str, Any]]:
        """
        å¤„ç†Excelæ–‡ä»¶ - ISBNè·å– + è±†ç“£çˆ¬å–åŒæ­¥è¿›è¡Œ

        Args:
            excel_file_path: Excelæ–‡ä»¶è·¯å¾„
            barcode_column: æ¡ç åˆ—å
            isbn_column: ISBNåˆ—å
            username: FOLIOç”¨æˆ·å
            password: FOLIOå¯†ç 

        Returns:
            (è¾“å‡ºæ–‡ä»¶è·¯å¾„, ç»Ÿè®¡ä¿¡æ¯)
        """
        logger.info(f"å¼€å§‹å¤„ç†Excelæ–‡ä»¶: {excel_file_path}")

        # 1. è¯»å–Excel
        df = pd.read_excel(excel_file_path)
        total_records = len(df)

        logger.info(f"è¯»å–åˆ° {total_records} æ¡è®°å½•")

        # 2. ç¡®ä¿è±†ç“£åˆ—å­˜åœ¨
        for col_name in self.field_mapping.values():
            if col_name not in df.columns:
                df[col_name] = ""

        # 3. åˆå§‹åŒ–æµè§ˆå™¨
        await self._init_browsers(username, password)

        # 4. å¤„ç†ç»Ÿè®¡
        stats = {
            'total_records': total_records,
            'success_isbn_count': 0,  # æˆåŠŸè·å–ISBNæ•°
            'success_douban_count': 0,  # æˆåŠŸè±†ç“£çˆ¬å–æ•°
            'failed_douban_count': 0,  # è±†ç“£å¤±è´¥æ•°
            'processing_start': datetime.now(),
        }

        try:
            # 5. éå†å¤„ç†æ¯ä¸€è¡Œ
            for index, row in df.iterrows():
                try:
                    barcode = row[barcode_column]
                    current_isbn = row[isbn_column]

                    # 5.1 è·å–ISBNï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if not self._is_valid_isbn(current_isbn):
                        if self.isbn_worker:
                            new_isbn = await self.isbn_worker.get_isbn(barcode)
                            if new_isbn:
                                df.at[index, isbn_column] = new_isbn
                                stats['success_isbn_count'] += 1
                                current_isbn = new_isbn
                            else:
                                df.at[index, isbn_column] = "çˆ¬å–å¤±è´¥"
                                logger.debug(f"æ¡ç  {barcode} è·å–ISBNå¤±è´¥")
                                continue  # è·³è¿‡è±†ç“£çˆ¬å–

                    # 5.2 æ‰§è¡Œè±†ç“£çˆ¬å–ï¼ˆåªè¦æœ‰æœ‰æ•ˆISBNå°±æ‰§è¡Œï¼‰
                    if self._is_valid_isbn(current_isbn):
                        book_info = await self.crawler_adapter.crawl_by_isbn(current_isbn)

                        if book_info:
                            # 5.3 å†™å…¥è±†ç“£ä¿¡æ¯åˆ°Excel
                            for field, excel_col in self.field_mapping.items():
                                value = book_info.get(field, "")
                                df.at[index, excel_col] = value

                            stats['success_douban_count'] += 1
                            logger.debug(f"æˆåŠŸçˆ¬å–ISBN {current_isbn} çš„è±†ç“£ä¿¡æ¯")
                        else:
                            # 5.4 æ ‡è®°è±†ç“£çˆ¬å–å¤±è´¥
                            df.at[index, self.field_mapping['é¢˜å']] = "è±†ç“£çˆ¬å–å¤±è´¥"
                            stats['failed_douban_count'] += 1
                            logger.debug(f"ISBN {current_isbn} è±†ç“£çˆ¬å–å¤±è´¥")

                    # 5.5 å®æ—¶ä¿å­˜ï¼ˆæ¯10æ¡ä¿å­˜ä¸€æ¬¡ï¼‰
                    if (index + 1) % self.config.save_interval == 0:
                        await self._save_progress(df, excel_file_path, index + 1)

                    # 5.6 æ˜¾ç¤ºè¿›åº¦
                    if (index + 1) % 50 == 0 or index == total_records - 1:
                        progress = (index + 1) / total_records * 100
                        logger.info(
                            f"è¿›åº¦: {index + 1}/{total_records} ({progress:.1f}%) - "
                            f"ISBN: {stats['success_isbn_count']}, "
                            f"è±†ç“£: {stats['success_douban_count']}/{stats['failed_douban_count']}"
                        )

                except Exception as e:
                    logger.error(f"å¤„ç†ç¬¬ {index + 1} è¡Œæ—¶å‡ºé”™: {e}")
                    continue

        finally:
            # 6. å…³é—­æµè§ˆå™¨
            await self._close_browsers()

        # 7. ä¿å­˜æœ€ç»ˆç»“æœ
        output_file = self._generate_output_path(excel_file_path)
        df.to_excel(output_file, index=False)

        # 8. è®¡ç®—æœ€ç»ˆç»Ÿè®¡
        stats['processing_end'] = datetime.now()
        stats['processing_time'] = (
            stats['processing_end'] - stats['processing_start']
        ).total_seconds()
        stats['success_rate'] = (
            stats['success_douban_count'] / total_records * 100
            if total_records > 0 else 0
        )
        stats['output_file'] = str(output_file)

        logger.info(
            f"å¤„ç†å®Œæˆ - æ€»è®°å½•: {total_records}, "
            f"æˆåŠŸISBN: {stats['success_isbn_count']}, "
            f"æˆåŠŸè±†ç“£: {stats['success_douban_count']}, "
            f"å¤±è´¥è±†ç“£: {stats['failed_douban_count']}, "
            f"æˆåŠŸç‡: {stats['success_rate']:.2f}%"
        )

        return str(output_file), stats

    async def _init_browsers(self, username: Optional[str], password: Optional[str]):
        """åˆå§‹åŒ–æµè§ˆå™¨ - å¤ç”¨ISBNå¤„ç†å™¨çš„æµè§ˆå™¨"""
        try:
            # ä»é…ç½®è·å–FOLIOç™»å½•ä¿¡æ¯
            config_manager = get_config_manager()
            douban_config = config_manager.get_douban_config()

            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ç”¨æˆ·å/å¯†ç ï¼Œå…¶æ¬¡ä½¿ç”¨é…ç½®
            username = username or douban_config.get('isbn_resolver', {}).get('username')
            password = password or douban_config.get('isbn_resolver', {}).get('password')

            if not username or not password:
                raise ValueError("ç¼ºå°‘FOLIOç”¨æˆ·åæˆ–å¯†ç ")

            # å¯åŠ¨ISBNæµè§ˆå™¨ï¼ˆç”¨äºè·å–ISBNï¼‰
            self.isbn_worker = AsyncBrowserWorker(
                worker_id=0,
                username=username,
                password=password,
                base_url=douban_config.get('isbn_resolver', {}).get('base_url', '')
            )
            await self.isbn_worker.start()

            # åˆå§‹åŒ–è±†ç“£çˆ¬è™«æµè§ˆå™¨ï¼ˆä½¿ç”¨åŒä¸€ä¸ªpageå¯¹è±¡ï¼‰
            page = self.isbn_worker.page
            await self.crawler_adapter.init_browser(page)

            logger.info("æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    async def _close_browsers(self):
        """å…³é—­æ‰€æœ‰æµè§ˆå™¨"""
        try:
            if self.isbn_worker:
                await self.isbn_worker.close()
                logger.info("æµè§ˆå™¨å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­æµè§ˆå™¨å¤±è´¥: {e}")

    async def _save_progress(self, df: pd.DataFrame, original_path: str, processed_count: int):
        """ä¿å­˜è¿›åº¦åˆ°ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_path = original_path.replace(
                '.xlsx',
                f'_processing_{datetime.now().strftime("%H%M%S")}_è¿›åº¦{processed_count}.xlsx'
            )
            df.to_excel(temp_path, index=False)
            logger.debug(f"è¿›åº¦å·²ä¿å­˜: {processed_count} æ¡è®°å½•")
        except Exception as e:
            logger.error(f"ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

    def _generate_output_path(self, original_path: str) -> Path:
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„"""
        path = Path(original_path)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        output_name = f"{path.stem}_è±†ç“£ä¿¡æ¯_{timestamp}{path.suffix}"
        output_dir = path.parent / "outputs" / "douban"
        output_dir.mkdir(parents=True, exist_ok=True)

        return output_dir / output_name

    def _is_valid_isbn(self, isbn: str) -> bool:
        """æ£€æŸ¥ISBNæ˜¯å¦æœ‰æ•ˆï¼ˆéç©ºã€é'çˆ¬å–å¤±è´¥'ã€éç‰¹æ®Šå­—ç¬¦ï¼‰"""
        if not isbn or pd.isna(isbn):
            return False
        isbn_str = str(isbn).strip()
        if isbn_str in ["çˆ¬å–å¤±è´¥", "", "-", "/", "nan"]:
            return False
        # ISBNåº”è¯¥æ˜¯æ•°å­—ï¼Œå¯èƒ½åŒ…å«è¿å­—ç¬¦
        if not any(c.isdigit() for c in isbn_str):
            return False
        return True
```

### ç¬¬äºŒé˜¶æ®µï¼šé…ç½®é›†æˆï¼ˆ0.5å¤©ï¼‰

#### 2.1 åˆ›å»ºé…ç½®åŠ è½½å™¨

```python
# src/core/douban/douban_rating_processor_config.py

from dataclasses import dataclass
from typing import Dict, Any, Optional

@dataclass
class DoubanRatingConfig:
    """è±†ç“£è¯„åˆ†å¤„ç†å™¨é…ç½®"""
    enabled: bool
    base_url: str
    headless: bool
    delay: float
    login: Dict[str, Any]
    crawl: Dict[str, Any]
    fields: Dict[str, str]
    save_interval: int

    @classmethod
    def from_dict(cls, config: Dict[str, Any]) -> 'DoubanRatingConfig':
        return cls(
            enabled=config.get('enabled', True),
            base_url=config.get('base_url', 'https://book.douban.com'),
            headless=config.get('headless', False),
            delay=config.get('delay', 1.0),
            login=config.get('login', {}),
            crawl=config.get('crawl', {}),
            fields=config.get('fields', {}),
            save_interval=config.get('save_interval', 10)
        )

def load_douban_rating_config(
    username: Optional[str] = None,
    password: Optional[str] = None,
    config_name: Optional[str] = None
) -> DoubanRatingConfig:
    """åŠ è½½è±†ç“£è¯„åˆ†é…ç½®"""
    config_manager = get_config_manager()
    douban_config = config_manager.get_douban_config()

    # è·å–è±†ç“£çˆ¬è™«é…ç½®
    crawler_config = douban_config.get('douban_crawler', {})

    # å¦‚æœæŒ‡å®šäº†config_nameï¼Œä»é¢„è®¾é…ç½®åŠ è½½
    if config_name:
        preset_config = get_preset_config(config_name)
        if preset_config:
            crawler_config = preset_config

    # åˆå¹¶ç”¨æˆ·åå’Œå¯†ç 
    if username:
        crawler_config.setdefault('login', {})['username'] = username
    if password:
        crawler_config.setdefault('login', {})['password'] = password

    return DoubanRatingConfig.from_dict(crawler_config)

def get_preset_config(config_name: str) -> Optional[Dict[str, Any]]:
    """è·å–é¢„è®¾é…ç½®"""
    presets = {
        "test": {
            "enabled": True,
            "headless": True,
            "delay": 0.5,
            "save_interval": 1
        },
        "small": {
            "enabled": True,
            "headless": False,
            "delay": 1.0,
            "save_interval": 10
        },
        "production": {
            "enabled": True,
            "headless": True,
            "delay": 2.0,
            "save_interval": 20
        }
    }
    return presets.get(config_name)
```

#### 2.2 æ›´æ–°é…ç½®ç®¡ç†å™¨

```python
# src/utils/config_manager.py

def get_douban_rating_config(self) -> Dict[str, Any]:
    """è·å–è±†ç“£è¯„åˆ†é…ç½®"""
    douban_config = self.get_douban_config()
    return douban_config.get('douban_crawler', {})

# åœ¨ get_douban_config æ–¹æ³•ä¸­ç¡®ä¿åŒ…å«è±†ç“£çˆ¬è™«é…ç½®
def get_douban_config(self) -> Dict[str, Any]:
    """è·å–è±†ç“£æ¨¡å—å®Œæ•´é…ç½®"""
    config = self.get('douban', {})

    # ç¡®ä¿åŒ…å«è±†ç“£çˆ¬è™«é…ç½®
    if 'douban_crawler' not in config:
        config['douban_crawler'] = {
            'enabled': True,
            'base_url': 'https://book.douban.com',
            'headless': False,
            'delay': 1.0,
            'login': {
                'auto_login': False,
                'timeout': 30
            },
            'crawl': {
                'retry_times': 3,
                'timeout': 15,
                'enable_stealth': True
            },
            'fields': {
                'url': 'è±†ç“£é“¾æ¥',
                'rating': 'è±†ç“£è¯„åˆ†',
                'title': 'è±†ç“£ä¹¦å',
                'author': 'è±†ç“£ä½œè€…',
                'publisher': 'è±†ç“£å‡ºç‰ˆç¤¾',
                'producer': 'è±†ç“£å‡ºå“æ–¹',
                'series': 'è±†ç“£ä¸›ä¹¦',
                'price': 'è±†ç“£å®šä»·',
                'isbn': 'è±†ç“£ISBN',
                'pages': 'è±†ç“£é¡µæ•°',
                'binding': 'è±†ç“£è£…å¸§',
                'pub_year': 'è±†ç“£å‡ºç‰ˆå¹´',
                'rating_count': 'è±†ç“£è¯„ä»·äººæ•°',
                'summary': 'è±†ç“£å†…å®¹ç®€ä»‹',
                'author_intro': 'è±†ç“£ä½œè€…ç®€ä»‹',
                'catalog': 'è±†ç“£ç›®å½•'
            },
            'save_interval': 10
        }

    return config
```

### ç¬¬ä¸‰é˜¶æ®µï¼šå‘½ä»¤è¡Œé›†æˆï¼ˆ0.5å¤©ï¼‰

#### 3.1 æ·»åŠ æ–°å‘½ä»¤

åœ¨`backup/douban/douban_main.py`ä¸­æ·»åŠ è±†ç“£è¯„åˆ†å‘½ä»¤ï¼š

```python
# æ·»åŠ å¯¼å…¥
from src.core.douban.douban_rating_processor import DoubanRatingProcessor
from src.core.douban.douban_rating_processor_config import load_douban_rating_config

def douban_rating_command(args):
    """è±†ç“£è¯„åˆ†å‘½ä»¤ - ISBNè·å– + è±†ç“£çˆ¬å–åŒæ­¥æ‰§è¡Œ"""
    # 1. éªŒè¯Excelæ–‡ä»¶
    if not validate_excel_file(args.excel_file):
        return

    # 2. åŠ è½½é…ç½®
    config = load_douban_rating_config(
        username=args.username,
        password=args.password,
        config_name=args.config_name
    )

    if not config.enabled:
        print("âŒ è±†ç“£è¯„åˆ†åŠŸèƒ½æœªå¯ç”¨")
        return

    print(f"ğŸš€ è±†ç“£è¯„åˆ†åŒæ­¥å¤„ç†å¼€å§‹")
    print(f"ğŸ“„ æºæ–‡ä»¶: {args.excel_file}")
    print(f"ğŸ“Š æè¿°: ISBNè·å– + è±†ç“£çˆ¬å–åŒæ­¥æ‰§è¡Œ")
    print(f"âš™ï¸  é…ç½®æ–¹æ¡ˆ: {args.config_name or 'é»˜è®¤'}")
    print(f"ğŸ”„ ä¿å­˜é—´éš”: {config.save_interval}æ¡/æ¬¡")

    # 3. æ˜¾ç¤ºæ€§èƒ½ä¼°ç®—ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿä¿¡æ¯ï¼‰
    if not args.quiet:
        try:
            data = pd.read_excel(args.excel_file)
            data_size = len(data)
            print(f"\\nğŸ“ˆ é¢„ä¼°å¤„ç†: {data_size}æ¡è®°å½•")
            print(f"   é¢„è®¡è€—æ—¶: {data_size * 3 / 60:.1f}åˆ†é’Ÿ (3ç§’/æ¡)")
            print(f"   é¢„è®¡æˆåŠŸç‡: 85-95%")
        except:
            pass

    # 4. åˆ›å»ºå¤„ç†å™¨
    processor = DoubanRatingProcessor(config)

    try:
        # 5. æ‰§è¡Œå¤„ç†ï¼ˆå¼‚æ­¥ï¼‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        output_file, stats = loop.run_until_complete(
            processor.process_excel(
                excel_file_path=args.excel_file,
                barcode_column=args.barcode_column,
                isbn_column=args.isbn_column,
                username=args.username,
                password=args.password
            )
        )

        # 6. æ˜¾ç¤ºç»“æœ
        print(f"\\nâœ… å¤„ç†å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"\\nğŸ“ˆ å¤„ç†ç»Ÿè®¡:")
        print(f"   æ€»è®°å½•æ•°: {stats['total_records']}")
        print(f"   æˆåŠŸè·å–ISBN: {stats['success_isbn_count']}")
        print(f"   æˆåŠŸè±†ç“£çˆ¬å–: {stats['success_douban_count']}")
        print(f"   è±†ç“£å¤±è´¥: {stats['failed_douban_count']}")
        print(f"   æˆåŠŸç‡: {stats['success_rate']:.2f}%")
        print(f"   å¤„ç†æ—¶é—´: {stats['processing_time']:.2f}ç§’")
        print(f"   å¹³å‡é€Ÿåº¦: {stats['total_records'] / (stats['processing_time'] / 60):.1f}æ¡/åˆ†é’Ÿ")

    except Exception as e:
        print(f"\\nâŒ å¤„ç†å¤±è´¥: {str(e)}")
        logger.error(f"è±†ç“£è¯„åˆ†å¤„ç†å¤±è´¥: {e}")
    finally:
        loop.close()
```

#### 3.2 æ·»åŠ å‘½ä»¤è¡Œå‚æ•°

```python
# åœ¨ douban_main.py çš„ main() å‡½æ•°ä¸­æ·»åŠ å‚æ•°

parser.add_argument('command',
                   choices=['isbn', 'douban-rating', 'list', 'help'],
                   help='æ‰§è¡Œçš„å‘½ä»¤')

parser.add_argument('--excel-file',
                   help='Excelæ–‡ä»¶è·¯å¾„ (ç”¨äºISBNå¤„ç†æˆ–è±†ç“£è¯„åˆ†)')

# åŸæœ‰å‚æ•°ä¿æŒä¸å˜...

# æ–°çš„è±†ç“£è¯„åˆ†ç›¸å…³å‚æ•°
parser.add_argument('--douban-rating',
                   action='store_true',
                   help='æ‰§è¡Œè±†ç“£è¯„åˆ†åŒæ­¥å¤„ç†')

parser.add_argument('--config-name',
                   choices=['test', 'small', 'production'],
                   help='é…ç½®æ–¹æ¡ˆ (ç”¨äºè±†ç“£è¯„åˆ†)')

# åœ¨ main() å‡½æ•°ä¸­å¤„ç†æ–°å‘½ä»¤
if args.command == 'douban-rating':
    if not args.excel_file:
        print("é”™è¯¯: è¯·æä¾› --excel-file å‚æ•°")
        return
    douban_rating_command(args)
elif args.command == 'isbn':
    # åŸæœ‰ISBNå¤„ç†é€»è¾‘
elif args.command == 'list':
    # åŸæœ‰æ¨¡å—åˆ—è¡¨é€»è¾‘
elif args.command == 'help':
    # åŸæœ‰å¸®åŠ©é€»è¾‘
```

#### 3.3 æ›´æ–°å¸®åŠ©ä¿¡æ¯

```python
def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ - åŒ…å«è±†ç“£è¯„åˆ†å‘½ä»¤"""
    print("""
ğŸ¯ è±†ç“£æ¨¡å—ä¸»ç¨‹åº - å¼‚æ­¥å¤„ç†ç‰ˆæœ¬

ğŸ“‹ å¯ç”¨å‘½ä»¤:
  isbn         - æ‰§è¡ŒISBNå¼‚æ­¥è·å– (æ¨è)
  douban-rating - æ‰§è¡ŒISBNè·å– + è±†ç“£çˆ¬å–åŒæ­¥å¤„ç† (æ–°åŠŸèƒ½!)
  list         - åˆ—å‡ºæ¨¡å—çŠ¶æ€
  help         - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

ğŸ“– ISBNå¼‚æ­¥å¤„ç†ç”¨æ³•:
  python douban_main.py isbn --excel-file <æ–‡ä»¶è·¯å¾„> [é€‰é¡¹]

ğŸ¯ è±†ç“£è¯„åˆ†åŒæ­¥å¤„ç†ç”¨æ³• (æ–°):
  python douban_main.py douban-rating --excel-file <æ–‡ä»¶è·¯å¾„> [é€‰é¡¹]

ğŸ”§ ä¸»è¦é€‰é¡¹:
  --excel-file FILE       Excelæ–‡ä»¶è·¯å¾„ (å¿…éœ€)
  --barcode-column NAME   æ¡ç åˆ—å (é»˜è®¤: ä¹¦ç›®æ¡ç )
  --isbn-column NAME      ISBNåˆ—å (é»˜è®¤: ISBNå·)
  --config-name NAME      é…ç½®æ–¹æ¡ˆ (é»˜è®¤: small)
                          å¯é€‰: test/small/production
  --username USER         FOLIOç”¨æˆ·å (å¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–)
  --password PASS         FOLIOå¯†ç  (å¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–)
  --quiet                 å®‰é™æ¨¡å¼ (å‡å°‘è¾“å‡ºä¿¡æ¯)

ğŸš€ æ–°åŠŸèƒ½ - è±†ç“£è¯„åˆ†åŒæ­¥å¤„ç†:
  âœ¨ ISBNè·å–å’Œè±†ç“£çˆ¬å–åŒæ—¶è¿›è¡Œ
  âœ¨ åªè¦æœ‰æœ‰æ•ˆISBNï¼Œç«‹å³æ‰§è¡Œè±†ç“£çˆ¬å–
  âœ¨ æˆåŠŸä¸€æ¡ç«‹å³å†™å›Excel
  âœ¨ å•æµè§ˆå™¨å®ä¾‹ï¼Œé¿å…é‡å¤ç™»å½•
  âœ¨ è¿›åº¦å®æ—¶ä¿å­˜ï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤±

ğŸ’¡ é…ç½®ç¤ºä¾‹ (config/setting.yaml):
  douban:
    douban_crawler:
      enabled: true
      base_url: "https://book.douban.com"
      headless: false
      delay: 1.0
      fields:
        title: "è±†ç“£ä¹¦å"
        rating: "è±†ç“£è¯„åˆ†"
        # ... æ›´å¤šå­—æ®µ

ğŸ“ ç¤ºä¾‹:
  # è±†ç“£è¯„åˆ†åŒæ­¥å¤„ç† (æ¨è)
  python douban_main.py douban-rating --excel-file "æ•°æ®.xlsx"

  # æµ‹è¯•æ¨¡å¼ (ä»…å¤„ç†å‰5æ¡)
  python douban_main.py douban-rating --excel-file "æ•°æ®.xlsx" --config-name test

  # ç”Ÿäº§ç¯å¢ƒ (æ— å¤´æ¨¡å¼)
  python douban_main.py douban-rating --excel-file "æ•°æ®.xlsx" --config-name production
""")
```

### ç¬¬å››é˜¶æ®µï¼šæµ‹è¯•éªŒè¯ï¼ˆ1å¤©ï¼‰

#### 4.1 å•å…ƒæµ‹è¯•

```python
# tests/test_douban_rating/test_douban_rating_processor.py

import pytest
import asyncio
from pathlib import Path
from src.core.douban.douban_rating_processor import DoubanRatingProcessor
from src.core.douban.douban_rating_processor_config import DoubanRatingConfig

class TestDoubanRatingProcessor:
    """è±†ç“£è¯„åˆ†å¤„ç†å™¨æµ‹è¯•"""

    @pytest.fixture
    def test_config(self):
        """æµ‹è¯•é…ç½®"""
        return DoubanRatingConfig.from_dict({
            'enabled': True,
            'headless': True,
            'delay': 0.5,
            'fields': {
                'title': 'è±†ç“£ä¹¦å',
                'rating': 'è±†ç“£è¯„åˆ†',
                'author': 'è±†ç“£ä½œè€…'
            },
            'save_interval': 1
        })

    @pytest.mark.asyncio
    async def test_crawl_single_isbn(self, test_config):
        """æµ‹è¯•å•ISBNçˆ¬å–"""
        processor = DoubanRatingProcessor(test_config)

        # æ¨¡æ‹Ÿè±†ç“£çˆ¬å–
        book_info = await processor.crawler_adapter.crawl_by_isbn("9787567577466")

        assert book_info is not None
        assert 'é¢˜å' in book_info
        assert 'è¯„åˆ†' in book_info

    @pytest.mark.asyncio
    async def test_process_excel_small(self, test_config, tmp_path):
        """æµ‹è¯•å°æ•°æ®é‡Excelå¤„ç†"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = {
            'ä¹¦ç›®æ¡ç ': ['TEST001', 'TEST002', 'TEST003'],
            'ISBNå·': ['9787567577466', '', '9787305280818']
        }
        df = pd.DataFrame(test_data)
        test_file = tmp_path / "test_data.xlsx"
        df.to_excel(test_file, index=False)

        # å¤„ç†
        processor = DoubanRatingProcessor(test_config)

        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦mockæ‰å®é™…çš„æµè§ˆå™¨æ“ä½œ
        # æˆ–è€…ä½¿ç”¨æµ‹è¯•ç”¨çš„æ¨¡æ‹Ÿæ•°æ®

        output_file, stats = await processor.process_excel(
            str(test_file),
            barcode_column="ä¹¦ç›®æ¡ç ",
            isbn_column="ISBNå·"
        )

        assert Path(output_file).exists()
        assert stats['total_records'] == 3

    def test_is_valid_isbn(self, test_config):
        """æµ‹è¯•ISBNæœ‰æ•ˆæ€§æ£€æŸ¥"""
        processor = DoubanRatingProcessor(test_config)

        assert processor._is_valid_isbn("9787567577466") == True
        assert processor._is_valid_isbn("") == False
        assert processor._is_valid_isbn("çˆ¬å–å¤±è´¥") == False
        assert processor._is_valid_isbn("-") == False
        assert processor._is_valid_isbn("/") == False
        assert processor._is_valid_isbn("abc") == False
```

#### 4.2 é›†æˆæµ‹è¯•

```python
# tests/test_douban_rating/test_integration.py

import pytest
import pandas as pd
from pathlib import Path

@pytest.mark.integration
class TestDoubanRatingIntegration:
    """è±†ç“£è¯„åˆ†é›†æˆæµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_full_workflow_small_data(self):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµ - å°æ•°æ®é‡"""
        # 1. åˆ›å»ºæµ‹è¯•Excelæ–‡ä»¶
        test_data = {
            'ä¹¦ç›®æ¡ç ': ['TEST001', 'TEST002'],
            'ISBNå·': ['9787567577466', '9787305280818']
        }
        df = pd.DataFrame(test_data)
        test_file = Path("tests/test_data/integration_test.xlsx")
        test_file.parent.mkdir(exist_ok=True)
        df.to_excel(test_file, index=False)

        # 2. æ‰§è¡Œå¤„ç†
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦é…ç½®æµ‹è¯•ç”¨çš„FOLIOè´¦æˆ·å’Œè±†ç“£è´¦æˆ·
        # å®é™…æµ‹è¯•æ—¶å»ºè®®ä½¿ç”¨mockæˆ–ä¸“é—¨çš„æµ‹è¯•è´¦æˆ·

        # 3. éªŒè¯ç»“æœ
        assert test_file.exists()

        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        output_dir = test_file.parent / "outputs" / "douban"
        if output_dir.exists():
            output_files = list(output_dir.glob("*.xlsx"))
            assert len(output_files) > 0

            # éªŒè¯è¾“å‡ºæ•°æ®
            result_df = pd.read_excel(output_files[0])
            assert "è±†ç“£ä¹¦å" in result_df.columns
            assert "è±†ç“£è¯„åˆ†" in result_df.columns
            assert len(result_df) == 2

    @pytest.mark.asyncio
    async def test_workflow_with_isbn_fetch(self):
        """æµ‹è¯•å·¥ä½œæµ - éœ€è¦è·å–ISBN"""
        # æ¨¡æ‹Ÿæ¡ç æ²¡æœ‰ISBNçš„æƒ…å†µ
        test_data = {
            'ä¹¦ç›®æ¡ç ': ['FOLIO_BARCODE_001', 'FOLIO_BARCODE_002'],
            'ISBNå·': ['', '']  # ç©ºISBNï¼Œéœ€è¦ä»FOLIOè·å–
        }
        # æµ‹è¯•é€»è¾‘åŒä¸Šï¼Œä½†éœ€è¦mock FOLIOç³»ç»Ÿ

    @pytest.mark.skip(reason="éœ€è¦çœŸå®çš„FOLIOå’Œè±†ç“£è´¦æˆ·ï¼Œä»…æ‰‹åŠ¨æµ‹è¯•")
    @pytest.mark.asyncio
    async def test_full_manual_workflow(self):
        """å®Œæ•´æ‰‹åŠ¨æµ‹è¯• - éœ€è¦çœŸå®è´¦æˆ·"""
        pass
```

#### 4.3 æ€§èƒ½æµ‹è¯•

```python
# tests/test_douban_rating/test_performance.py

import pytest
import time
from src.core.douban.douban_rating_processor import DoubanRatingProcessor

@pytest.mark.performance
class TestDoubanRatingPerformance:
    """è±†ç“£è¯„åˆ†æ€§èƒ½æµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_processing_speed(self):
        """æµ‹è¯•å¤„ç†é€Ÿåº¦"""
        start_time = time.time()

        # æ‰§è¡Œ100æ¡æ•°æ®çš„å¤„ç†
        # (éœ€è¦mockå®é™…çš„ç½‘ç»œè¯·æ±‚)

        end_time = time.time()
        processing_time = end_time - start_time

        # é¢„æœŸï¼š100æ¡æ•°æ®åº”è¯¥åœ¨5-10åˆ†é’Ÿå†…å®Œæˆ
        assert processing_time < 600  # 10åˆ†é’Ÿ
        assert processing_time > 300  # 5åˆ†é’Ÿ

    @pytest.mark.asyncio
    async def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        # ä½¿ç”¨memory_profilerç›‘æ§å†…å­˜
        # æˆ–ä½¿ç”¨pytest-clarityç­‰å·¥å…·
        pass
```

#### 4.1 å•å…ƒæµ‹è¯•
```python
# tests/test_douban_rating/test_douban_rating_processor.py

import pytest
from src.core.douban.douban_rating_processor import DoubanRatingProcessor

class TestDoubanRatingProcessor:
    """è±†ç“£è¯„åˆ†å¤„ç†å™¨æµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_crawl_single_isbn(self):
        """æµ‹è¯•å•ISBNçˆ¬å–"""
        processor = DoubanRatingProcessor(test_config)
        result = await processor.crawler_adapter.crawl_by_isbn("9787567577466")
        assert result is not None
        assert 'title' in result

    @pytest.mark.asyncio
    async def test_process_excel(self):
        """æµ‹è¯•Excelå¤„ç†"""
        processor = DoubanRatingProcessor(test_config)
        output_file, stats = await processor.process_excel(
            "test_data.xlsx",
            barcode_column="ä¹¦ç›®æ¡ç ",
            isbn_column="ISBNå·"
        )
        assert output_file.exists()
        assert stats['total_records'] > 0
```

#### 4.2 é›†æˆæµ‹è¯•
```python
# tests/test_douban_rating/test_integration.py

@pytest.mark.integration
async def test_full_workflow():
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
    # 1. ä½¿ç”¨æµ‹è¯•Excelæ–‡ä»¶
    test_file = "tests/test_data/isbn_test_data.xlsx"

    # 2. æ‰§è¡Œå¤„ç†
    result = await main_douban_rating(
        excel_file=test_file,
        config_name="test"
    )

    # 3. éªŒè¯ç»“æœ
    assert result['output_file'].exists()
    assert "è±†ç“£ä¹¦å" in pd.read_excel(result['output_file']).columns
```

## ğŸ¯ å®æ–½æ—¶é—´è¡¨

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ | è´Ÿè´£äºº |
|------|------|----------|--------|
| 1 | ä»£ç é€‚é… - çˆ¬è™«é€‚é…å™¨ | 1å¤© | å¼€å‘å›¢é˜Ÿ |
| 2 | ä»£ç é€‚é… - é›†æˆå¤„ç†å™¨ | 1å¤© | å¼€å‘å›¢é˜Ÿ |
| 3 | é…ç½®é›†æˆ | 0.5å¤© | å¼€å‘å›¢é˜Ÿ |
| 4 | å‘½ä»¤è¡Œé›†æˆ | 0.5å¤© | å¼€å‘å›¢é˜Ÿ |
| 5 | æµ‹è¯•éªŒè¯ | 1å¤© | QAå›¢é˜Ÿ |
| **æ€»è®¡** | | **4å¤©** | |

## ğŸ“Š æ€§èƒ½é¢„æœŸ

### å¤„ç†é€Ÿåº¦ä¼°ç®—
- **ISBNè·å–**ï¼š0.7-1.3ç§’/æ¡
- **è±†ç“£çˆ¬å–**ï¼š2-5ç§’/æ¡ï¼ˆå«æœç´¢+è¯¦æƒ…æå–ï¼‰
- **æ€»ä½“ååé‡**ï¼š12-20æ¡/åˆ†é’Ÿï¼ˆå•æµè§ˆå™¨å®ä¾‹ï¼‰

### èµ„æºæ¶ˆè€—
- **å†…å­˜**ï¼š200-500MB/æµè§ˆå™¨å®ä¾‹
- **CPU**ï¼šä¸­ç­‰è´Ÿè½½
- **ç½‘ç»œ**ï¼šè½»åˆ°ä¸­ç­‰æµé‡

### ä¼˜åŒ–å»ºè®®
1. **å¤šå®ä¾‹å¹¶å‘**ï¼šå¯é…ç½®å¤šä¸ªæµè§ˆå™¨å®ä¾‹å¹¶è¡Œå¤„ç†
2. **æ™ºèƒ½å»¶è¿Ÿ**ï¼šæ ¹æ®è±†ç“£å“åº”é€Ÿåº¦åŠ¨æ€è°ƒæ•´å»¶è¿Ÿ
3. **ç¼“å­˜æœºåˆ¶**ï¼šå·²çˆ¬å–ISBNç»“æœç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚

## ğŸ” ç›‘æ§ä¸æ—¥å¿—

### å…³é”®æŒ‡æ ‡
- æ€»å¤„ç†è®°å½•æ•°
- æˆåŠŸçˆ¬å–æ•°
- è±†ç“£çˆ¬å–å¤±è´¥æ•°
- å¹³å‡å¤„ç†é€Ÿåº¦
- é”™è¯¯ç‡

### æ—¥å¿—è®°å½•
```python
# ä½¿ç”¨é¡¹ç›®ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
logger.info(f"è±†ç“£çˆ¬å–å¼€å§‹ - ISBN: {isbn}")
logger.debug(f"è±†ç“£è¯¦æƒ… - {book_info}")
logger.warning(f"è±†ç“£çˆ¬å–å¤±è´¥ - ISBN: {isbn}, åŸå› : {error}")
```

## ğŸš¨ é£é™©ä¸åº”å¯¹

### 1. åçˆ¬è™«æœºåˆ¶
**é£é™©**ï¼šè±†ç“£å¯èƒ½å°ç¦IPæˆ–è¦æ±‚éªŒè¯ç 
**åº”å¯¹**ï¼š
- å¢åŠ éšæœºå»¶è¿Ÿ
- ä½¿ç”¨ä»£ç†IPæ± 
- å®ç°éªŒè¯ç è‡ªåŠ¨è¯†åˆ«

### 2. ç™»å½•å¤±æ•ˆ
**é£é™©**ï¼šè±†ç“£ç™»å½•çŠ¶æ€è¿‡æœŸ
**åº”å¯¹**ï¼š
- å®šæœŸæ£€æŸ¥ç™»å½•çŠ¶æ€
- è‡ªåŠ¨é‡æ–°ç™»å½•
- ä¼šè¯æŒä¹…åŒ–

### 3. æ•°æ®ä¸ä¸€è‡´
**é£é™©**ï¼šExcelå†™å…¥å¤±è´¥å¯¼è‡´æ•°æ®ä¸¢å¤±
**åº”å¯¹**ï¼š
- å®æ—¶ä¿å­˜ä¸­é—´ç»“æœ
- äº‹åŠ¡æ€§å†™å…¥
- å®šæœŸå¤‡ä»½

## ğŸ“š å‚è€ƒèµ„æ–™

### 1. è±†ç“£çˆ¬è™«å‚è€ƒä»£ç ï¼ˆå®Œæ•´ç»“æ„ï¼‰
ä½äº `docs/refs/douban-spider/src/`ï¼ŒåŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š

#### 1.1 æ ¸å¿ƒæ¨¡å—
- **douban_spider.py**ï¼šä¸»çˆ¬è™«ç±»ï¼ˆ286è¡Œï¼‰
  - `DoubanBookSpider`ç±»ï¼šåè°ƒå„æ¨¡å—
  - `start_driver()`ï¼šå¯åŠ¨æµè§ˆå™¨å’Œåˆå§‹åŒ–æ¨¡å—
  - `crawl_books()`ï¼šæ‰¹é‡çˆ¬å–æ ¸å¿ƒé€»è¾‘
  - `_handle_initial_login()`ï¼šåˆå§‹ç™»å½•å¤„ç†
  - ç™»å½•çŠ¶æ€ç®¡ç†ï¼š`login_completed`å’Œ`login_attempted`

- **base_spider.py**ï¼šæµè§ˆå™¨åŸºç¡€ç®¡ç†
  - æµè§ˆå™¨å¯åŠ¨å’Œå…³é—­
  - ä»£ç†è®¾ç½®å’Œåæ£€æµ‹
  - éšæœºå»¶è¿Ÿæœºåˆ¶
  - ä¼šè¯ç®¡ç†

- **login_handler.py**ï¼šç™»å½•å¤„ç†
  - è‡ªåŠ¨ç™»å½•åŠŸèƒ½ï¼ˆç”¨æˆ·å/å¯†ç ï¼‰
  - æ‰‹åŠ¨ç™»å½•ç­‰å¾…
  - ç™»å½•çŠ¶æ€æ£€æµ‹
  - å¤šç§ç™»å½•é¡µé¢é€‚é…

- **search_handler.py**ï¼šæœç´¢åŠŸèƒ½æ¨¡å—ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
  - `SearchHandler`ç±»ï¼šISBNæœç´¢
  - `search_by_isbn()`ï¼šé€šè¿‡ISBNè·å–å›¾ä¹¦è¯¦æƒ…é¡µé“¾æ¥
  - ä¼˜åŒ–ï¼šé¿å…é‡å¤ç™»å½•ï¼Œä¿æŒæµè§ˆå™¨ä¼šè¯
  - ç™»å½•çŠ¶æ€ç®¡ç†ï¼š`login_completed`å’Œ`login_attempted`
  - æ”¯æŒURLç›´æ¥æœç´¢å’Œé¡µé¢æœç´¢ä¸¤ç§æ–¹å¼
  - å¤šå±‚çº§è¶…æ—¶å¤„ç†

- **detail_extractor.py**ï¼šè¯¦æƒ…é¡µæå–æ¨¡å—
  - `DetailExtractor`ç±»ï¼šæå–å›¾ä¹¦è¯¦ç»†ä¿¡æ¯
  - `extract_book_details()`ï¼šä»è¯¦æƒ…é¡µæå–æ‰€æœ‰å­—æ®µ
  - å¤šå±‚çº§è¶…æ—¶ç­–ç•¥ï¼ˆdomcontentloaded â†’ networkidle0 â†’ åŸºæœ¬åŠ è½½ï¼‰
  - é¡µé¢éªŒè¯å’Œé‡è½½æœºåˆ¶
  - ä½¿ç”¨BeautifulSoupè§£æHTML

- **data_manager.py**ï¼šæ•°æ®ç®¡ç†
  - å›¾ä¹¦ä¿¡æ¯å­˜å‚¨å’Œç®¡ç†
  - Excelå¯¼å‡ºåŠŸèƒ½
  - æ•°æ®å»é‡å’ŒéªŒè¯

#### 1.2 å…³é”®å®ç°ç»†èŠ‚

**æœç´¢æµç¨‹**ï¼ˆå‚è€ƒsearch_handler.py:38-93ï¼‰ï¼š
```python
def search_by_isbn(self, isbn: str) -> Optional[str]:
    # 1. æ£€æŸ¥ç™»å½•çŠ¶æ€
    if self.login_completed:
        # ç›´æ¥å¼€å§‹æœç´¢
        return self._search_by_direct_url(isbn)

    # 2. è®¿é—®è±†ç“£å›¾ä¹¦é¦–é¡µ
    self.page.goto("https://book.douban.com", ...)

    # 3. æ£€æŸ¥ç™»å½•é¡µé¢
    if self.login_handler.check_login_page(page_type="normal"):
        # å¤„ç†ç™»å½•æƒ…å†µ
        return self._handle_login_situation_optimized(isbn)

    # 4. æ‰§è¡Œæ­£å¸¸æœç´¢
    return self._perform_search(isbn)
```

**è¯¦æƒ…æå–æµç¨‹**ï¼ˆå‚è€ƒdetail_extractor.py:37-94ï¼‰ï¼š
```python
def extract_book_details(self, book_url: str) -> Dict:
    # 1. å¤šå±‚çº§è¶…æ—¶è®¿é—®
    try:
        self.page.goto(book_url, wait_until="domcontentloaded", timeout=25000)
    except PlaywrightTimeoutError:
        # å›é€€åˆ°networkidle0
        # å›é€€åˆ°åŸºæœ¬é¡µé¢åŠ è½½

    # 2. éªŒè¯é¡µé¢åŠ è½½
    if not self._validate_detail_page(soup):
        return {}

    # 3. æå–å„é¡¹ä¿¡æ¯
    return {
        'é“¾æ¥': book_url,
        'è¯„åˆ†': self._extract_rating(soup),
        'é¢˜å': self._extract_title(soup),
        'ä½œè€…': self._extract_author(soup),
        'å‡ºç‰ˆç¤¾': self._extract_publisher(soup),
        # ...
    }
```

#### 1.3 æ•°æ®å­—æ®µæ˜ å°„

å‚è€ƒdetail_extractor.py:94-110ï¼Œè±†ç“£è¿”å›å­—æ®µï¼š
```python
book_info = {
    'é“¾æ¥': book_url,
    'è¯„åˆ†': self._extract_rating(soup),
    'é¢˜å': self._extract_title(soup),
    'ä½œè€…': self._extract_author(soup),
    'å‡ºç‰ˆç¤¾': self._extract_publisher(soup),
    'å‡ºå“æ–¹': self._extract_producer(soup),
    'ä¸›ä¹¦': self._extract_series(soup),
    'å®šä»·': self._extract_price(soup),
    'ISBN': self._extract_isbn(soup),
    'é¡µæ•°': self._extract_pages(soup),
    'è£…å¸§': self._extract_binding(soup),
    'å‡ºç‰ˆå¹´': self._extract_pub_year(soup),
    'è£…å¸§': self._extract_binding(soup),
    'è¯„åˆ†': self._extract_rating(soup),
    'è¯„ä»·äººæ•°': self._extract_rating_count(soup),
    'å†…å®¹ç®€ä»‹': self._extract_summary(soup),
    'ä½œè€…ç®€ä»‹': self._extract_author_intro(soup),
    'ç›®å½•': self._extract_catalog(soup),
}
```

### 2. é¡¹ç›®ç°æœ‰å®ç°

- **ISBNå¼‚æ­¥å¤„ç†å™¨**ï¼š`src/core/douban/isbn_async_processor.py`
  - `AsyncBrowserWorker`ç±»ï¼šå¼‚æ­¥æµè§ˆå™¨å·¥ä½œå™¨
  - `get_isbn()`æ–¹æ³•ï¼šé€šè¿‡æ¡ç è·å–ISBNï¼ˆæ”¯æŒé‡è¯•ï¼‰
  - `ISBNAsyncProcessor`ç±»ï¼šåè°ƒå¤šä¸ªå·¥ä½œå™¨å¹¶å‘å¤„ç†

- **ä¸»ç¨‹åºå…¥å£**ï¼š`backup/douban/douban_main.py`
  - ISBNå¼‚æ­¥å¤„ç†å‘½ä»¤è¡Œæ¥å£
  - æ™ºèƒ½é…ç½®ç®¡ç†
  - æ€§èƒ½ä¼°ç®—å’Œç›‘æ§

### 3. é¡¹ç›®é…ç½®

**é…ç½®æ–‡ä»¶**ï¼š`config/setting.yaml`
- douban.crawlerï¼šè±†ç“£çˆ¬è™«é…ç½®
- douban.isbn_processorï¼šISBNå¤„ç†å™¨é…ç½®

## ğŸ“ åç»­ä¼˜åŒ–æ–¹å‘

1. **æ–­ç‚¹ç»­ä¼ **ï¼šæ”¯æŒä¸­æ–­åä»æŒ‡å®šä½ç½®ç»§ç»­
2. **æ•°æ®éªŒè¯**ï¼šéªŒè¯çˆ¬å–æ•°æ®çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
3. **å¤šæºæ•°æ®**ï¼šæ”¯æŒå¤šä¸ªè±†ç“£æ•°æ®æº
4. **æ™ºèƒ½é‡è¯•**ï¼šæ ¹æ®å¤±è´¥åŸå› æ™ºèƒ½é‡è¯•
5. **æ•°æ®å¯¼å‡º**ï¼šæ”¯æŒå¤šç§æ ¼å¼å¯¼å‡ºï¼ˆJSONã€CSVã€æ•°æ®åº“ï¼‰

---

**æ³¨æ„**ï¼šæœ¬é›†æˆæ–¹æ¡ˆä¸¥æ ¼ä¿æŒå‚è€ƒä»£ç çš„æ ¸å¿ƒçˆ¬å–é€»è¾‘ä¸å˜ï¼Œä»…è¿›è¡Œæ¶æ„é€‚é…å’Œé…ç½®ç»Ÿä¸€ï¼Œç¡®ä¿åŠŸèƒ½çš„ç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
