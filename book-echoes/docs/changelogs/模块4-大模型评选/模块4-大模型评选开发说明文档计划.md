# 模块4：主题推荐评选开发说明（修订版）

## 背景与目标

* 基于模块3的最终Excel结果，从`候选状态=候选`数据中按`索书号`首字母（主题大类）分组，通过两阶段大模型评选得到推荐书目。

* 两阶段：

  * 初评（分主题组、分批次）：每个主题大类在不超过 20 条的批次中调用模型，动态限定推荐数量，写回“初评\*”列。

  * 终评（全局）：将所有主题大类中初评通过的书目汇总，追加“初评理由”后再次调用模型，写回“终评\*”列。

## 模块命名与路径

* 目录：`src/core/recommendation/`

* 主要文件：

  * `controller.py`：编排初评→终评全流程

  * `theme_grouper.py`：按`索书号`首字母分组与均匀批次切分（每批≤20）

  * `prompt_builder.py`：提示词生成（初评/终评）

  * `executor.py`：封装两阶段LLM调用（依赖项目内llm客户端）

  * `excel_writer.py`：写回Excel（幂等与错误记录）

  * `config.py`：动态推荐量规则与常量

* 主程序集成：

  * 新增菜单项名称：`主题推荐评选`

  * 新增入口函数：`run_theme_recommendation()` 与 `run_theme_recommendation_full()`（对齐模块1-3风格）

  * 参考入口位置与模式：`book-echoes/main.py:231`（子流程运行模式）、`book-echoes/main.py:314`（模块3入口）、`book-echoes/main.py:343`（完整流水线）、`book-echoes/main.py:363`（菜单主入口）

  * 可选命令行子命令：`theme-recommend`（对齐 `src/core/douban/douban_main.py:432` 的命令结构风格）

## LLM 客户端与配置（本项目内实现）

> llm调用参考代码见 book-echoes\docs\refs\llm-api

* 路径：`src/utils/llm_api/`

  * `client.py`：统一LLM客户端，支持任务配置、智能重试、JSON修复

  * `retry.py`：指数退避与主备Provider切换

  * `json_utils.py`：JSON提取与修复（fenced-code、括号平衡、键名补全）

  * `prompt_loader.py`：提示词加载（md、dict）

* 独立配置文件：`config/llm.yaml`

  * 与其他配置分离，避免混用

  * 包含：`api_providers`、`tasks.theme_initial`、`tasks.theme_final`、`retry_policy`、`json_repair`

  * 动态推荐数量可配置为：`tasks.theme_initial.parameters.recommend_quota`

## 输入与输出

* 输入：模块3最终Excel（位于`runtime/outputs`），必备列：

  * `书目条码`、`索书号`、`书名`、`豆瓣副标题`、`豆瓣作者`、`豆瓣丛书`、`豆瓣内容简介`、`豆瓣作者简介`、`豆瓣目录`、`候选状态`

* 初评写回列：

  * `初评结果`（通过/未通过）、`初评分数`（1-5，一位小数）、`初评理由`、`初评淘汰原因`、`初评淘汰说明`

* 终评写回列：

  * `终评结果`（通过/未通过）、`终评分数`、`终评理由`、`终评淘汰原因`、`终评淘汰说明`

## 分组与批次规则

* 主题分组：

  * 以`索书号`首字母作为主题大类；非字母首字符可归为`Other`类别（可配置）

* 批次切分：

  * 每批最多 20 条；超过 20 的主题组，按尽可能平均的方式分批（避免尾批过小）

## 提示词构建

* 书目块格式（以`---`分隔）：

```
书目条码id:
书名:
副标题:
作者:
丛书:
内容简介:
作者简介:
目录:
```

* 动态模板：

  * “在所有符合条件的书籍中，请精中选优，最终推荐的书目数量不得超过 X 本。”

  * 推荐量 X 的规则：`>20→6；15-20→5；10-15→4；5-10→3；<5→2`（可在`config/llm_theme_recommend.yaml`或`src/core/recommendation/config.py`中配置/实现）

* 终评提示词：

  * 在初评书目块基础上，为每本书追加一行：`初评理由:`

## LLM 任务配置建议

* `config/llm_theme_recommend.yaml` 示例结构：

```
api_providers:
  text:
    primary: { base_url: ..., api_key: ..., model: ..., timeout_seconds: 60 }
    secondary: { base_url: ..., api_key: ..., model: ..., timeout_seconds: 60 }

tasks:
  theme_initial:
    provider_type: text
    prompt: { md: "prompts/theme_initial.md" }
    json_repair: { enabled: true, strict_mode: false }
    retry: { max_times: 3, base_delay: 1.0, max_delay: 8.0, jitter: true }
    parameters:
      recommend_quota: { gt20: 6, g15_20: 5, g10_15: 4, g5_10: 3, lt5: 2 }

  theme_final:
    provider_type: text
    prompt: { md: "prompts/theme_final.md" }
    json_repair: { enabled: true, strict_mode: false }
    retry: { max_times: 3, base_delay: 1.0, max_delay: 8.0, jitter: true }
```

## JSON 返回与解析

* 预期返回：

```
{
  "selected_books": [
    { "id": "书目条码", "title": "书名", "rating": "1-5一位小数", "reason": "入选理由" }
  ],
  "unselected_books": [
    {
      "category": "未入选主要原因分类",
      "explanation": "简要说明",
      "books": [ { "id": "书目条码", "title": "书名" } ]
    }
  ]
}
```

* 解析与修复：

  * 使用 `src/utils/llm_api/json_utils.py` 自动提取与修复；严格模式可在任务层开启

## Excel 写回与幂等

* 行定位：以`id=书目条码`匹配Excel行

* 幂等检查：调用前检查目标列是否已有合法值；已存在则跳过该行，避免重复执行

* 错误写回：重试失败则在`初评结果`或`终评结果`写入`ERROR: <message>`；阶段结束后集中重试错误行

* 参考现有写回能力：

  * `book-echoes/src/core/douban/database/excel_updater.py:63`（更新器初始化）

  * `book-echoes/src/core/douban/database/excel_updater.py:247`（单行更新）

  * `book-echoes/src/core/douban/database/excel_updater.py:262`（保存）

  * 可直接以`pandas`写回并统一保存，避免与其他配置项混杂

## 两阶段流程细化

* 初评（按主题分批）：

  * 读取Excel → 筛选`候选状态=候选` → 按`索书号`首字母分组 → 均匀批次切分（≤20） → 构建提示词 → 调用`tasks.theme_initial` → 解析JSON → 写回`初评*`列

* 终评（全局）：

  * 聚合初评通过书目 → 构建提示词（追加`初评理由`） → 调用`tasks.theme_final` → 解析JSON → 写回`终评*`列

## 重试与错误处理

* 统一使用 `src/utils/llm_api/retry.py` 的指数退避与主备Provider切换

* 阶段完成后对失败行统一重试；最终保留失败信息以便审计

## 日志与开发规范

* 遵循 `.rules/agents.md`：

  * 中文日志与注释、结构化与集中化日志

  * 高内聚低耦合、KISS原则

  * 测试先行，覆盖正常/边界/异常用例

## 测试计划

* 单元测试：分组/批次切分、提示词构建、JSON解析修复、写回幂等

* 集成测试：从模块3样例Excel贯通初评→终评；模拟LLM返回与错误重试场景

## 里程碑

* 里程碑1：完成分主题组的初评调用与写回

* 里程碑2：完成终评调用与写回

* 里程碑3：完善错误重试、日志与测试

## 文档存储

* 确认后保存到：`docs/changelogs/模块4-大模型评选/开发说明.md`