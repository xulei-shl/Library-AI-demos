# 模块4：三阶段评选优化开发文档

> **文档版本**: v1.0
> **创建日期**: 2025-11-17
> **适用代码**: `src/core/recommendation/`

---

## 📋 目录

1. [背景与问题分析](#背景与问题分析)
2. [当前实现状态](#当前实现状态)
3. [优化方案设计](#优化方案设计)
4. [技术实现细节](#技术实现细节)
5. [开发任务清单](#开发任务清单)
6. [测试与验证](#测试与验证)
7. [配置与部署](#配置与部署)

---

## 背景与问题分析

### 当前架构（两阶段模式）

**阶段1：主题内初评（已实现）**
- 按索书号首字母分组（如 `T/Q/P/...`）
- 每组内分批（≤20本）调用LLM
- 使用动态配额机制选出优秀书目

**阶段2：全局终评（已实现但有问题）**
- 直接对所有初评通过的书目进行终评
- ⚠️ **问题1**: 没有主题平衡机制
- ⚠️ **问题2**: 没有分批/锦标赛机制

### 核心问题诊断

#### 问题1：主题分布严重不均

**问题场景**：
```
假设初评通过了50本书：
- T类（工业技术）：25本（大主题，基数大）
- Q类（生物科学）：3本（小主题，基数小）
- P类（社会科学）：8本
- ...其他主题共14本

终评如果选Top 10：
- T类可能占6-7本（60-70%）
- 其他主题严重稀释
→ 最终书单缺乏主题多样性
```

**根本原因**：
- 当前的动态配额（见 [config.py:12-18](../../../src/core/recommendation/config.py#L12-L18)）是**主题内晋级率控制**
- 大主题即使晋级率低，绝对数量仍然碾压小主题
- 缺少**主题间平衡机制**

#### 问题2：终评缺乏公平性保障

**问题代码**：
```python
# controller.py:237
result = executor.final(selected_with_reason)
```

**问题分析**：
- 40-60本书一次性喂给LLM
- 超出Token限制风险
- 模型注意力分散，评选质量下降
- 存在"批次效应"：简单分批会导致强组淘汰优秀书目，弱组保留平庸书目

---

## 当前实现状态

### 代码结构

```
src/core/recommendation/
├── controller.py          # 流程编排（已实现两阶段）
├── executor.py            # LLM调用执行器
├── theme_grouper.py       # 主题分组与批次切分
├── prompt_builder.py      # 提示词构建
├── excel_writer.py        # Excel结果写回
└── config.py              # 配置与常量
```

### 已实现功能

#### 1. 主题分组与批次切分
**文件**: [theme_grouper.py](../../../src/core/recommendation/theme_grouper.py)

```python
def group_by_theme(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    """按索书号首字母分组"""
    # T类、Q类、P类等

def split_batches(items: List[Dict], max_batch_size: int = 20):
    """均匀批次切分（避免尾批过小）"""
```

#### 2. 动态配额机制
**文件**: [config.py](../../../src/core/recommendation/config.py)

```python
DEFAULT_QUOTA = {
    "gt20": 6,      # >20本 → 选6本
    "g15_20": 5,    # 15-20本 → 选5本
    "g10_15": 4,    # 10-15本 → 选4本
    "g5_10": 3,     # 5-10本 → 选3本
    "lt5": 2,       # <5本 → 选2本
}
```

**用途**: 控制单个批次的推荐数量

#### 3. 初评流程（完整）
**文件**: [controller.py:128-231](../../../src/core/recommendation/controller.py#L128-L231)

**关键特性**：
- ✅ 幂等检查：跳过已有初评结果的数据（[controller.py:24-37](../../../src/core/recommendation/controller.py#L24-L37)）
- ✅ 错误重试：对失败数据进行兜底重试（[controller.py:53-126](../../../src/core/recommendation/controller.py#L53-L126)）
- ✅ 进度跟踪：详细的批次进度日志

#### 4. Excel写回机制（阶段隔离原则）
**文件**: [excel_writer.py](../../../src/core/recommendation/excel_writer.py)

**设计原则**：**每个阶段只负责写入自己的列，互不干扰**

**列定义**：
```python
INITIAL_COLUMNS = [
    "初评结果", "初评分数", "初评理由", "初评淘汰原因", "初评淘汰说明"
]

RUNOFF_COLUMNS = [  # 新增
    "主题内决选结果", "主题内决选理由"
]

FINAL_COLUMNS = [
    "终评结果", "终评分数", "终评理由", "终评淘汰原因", "终评淘汰说明"
]
```

**阶段职责**：

| 阶段 | 负责列 | 写入方法 | 禁止触碰 |
|------|--------|---------|---------|
| 阶段1：初评 | `INITIAL_COLUMNS` | `write_initial()` | `RUNOFF_COLUMNS`, `FINAL_COLUMNS` |
| 阶段2：决选 | `RUNOFF_COLUMNS` | `write_runoff()`【新增】 | `INITIAL_COLUMNS`, `FINAL_COLUMNS` |
| 阶段3：终评 | `FINAL_COLUMNS` | `write_final()` | `INITIAL_COLUMNS`, `RUNOFF_COLUMNS` |

**列填充规则**：
- **初评列**：所有"候选状态=候选"的书目都会填充（通过/未通过）
- **决选列**：仅"初评结果=通过"的书目才会填充
- **终评列**：仅"主题内决选结果=晋级或自动晋级"的书目才会填充

**Excel 数据流示例**：
```
书目 A:
  候选状态=候选
  → 阶段1: 初评结果=通过, 初评理由=xxx
  → 阶段2: 主题内决选结果=晋级, 主题内决选理由=yyy
  → 阶段3: 终评结果=通过, 终评理由=zzz

书目 B:
  候选状态=候选
  → 阶段1: 初评结果=通过, 初评理由=xxx
  → 阶段2: 主题内决选结果=自动晋级
  → 阶段3: 终评结果=未通过, 终评淘汰原因=zzz

书目 C:
  候选状态=候选
  → 阶段1: 初评结果=未通过, 初评淘汰原因=xxx
  → 阶段2: （跳过，因为初评未通过）
  → 阶段3: （跳过）
```

**幂等策略**：
```python
def _has_value(self, row_index: int, column: str) -> bool:
    """检查是否已有合法值（非空且非ERROR开头）"""
    # 已有合法值则跳过写入
```

#### 5. LLM调用与重试（统一模式）
**文件**: [executor.py](../../../src/core/recommendation/executor.py)

**特性**：
- ✅ 统一LLM客户端（`UnifiedLLMClient`）
- ✅ 降级策略：LLM不可用时使用Mock数据
- ✅ JSON容错解析（支持 fenced-code 和括号修复）
- ✅ 错误结果标记（`ERROR: <message>`）

**重试机制（两层保障）**：

**第一层：LLM客户端自动重试**
- 配置位置：`config/llm.yaml` 中的 `retry` 配置
- 重试策略：指数退避（exponential backoff）
- 主备切换：primary失败后自动切换到secondary
- 示例配置：
  ```yaml
  retry:
    max_retries: 3          # 最多重试3次
    base_delay: 1.2         # 基础延迟1.2秒
    max_delay: 12           # 最大延迟12秒
    enable_provider_switch: true  # 启用主备切换
    jitter: true            # 启用抖动
  ```

**第二层：业务层兜底重试**
- 实现位置：`controller.py::_retry_failed_reviews()`
- 触发时机：每个阶段完成后检查是否有失败数据
- 失败识别：
  ```python
  def _has_failed_review(row: pd.Series) -> bool:
      """检查数据是否初评失败（非合法值都视为失败）"""
      result = row.get("初评结果", "")
      if pd.isna(result) or not str(result).strip():
          return True
      # 白名单模式：只有"通过"或"未通过"是合法值
      if str(result).strip() not in ["通过", "未通过"]:
          return True
      return False
  ```
- 重试逻辑：
  1. 扫描Excel，找出所有失败的行（结果为空、ERROR、或非法值）
  2. 按主题重新分组和分批
  3. 再次调用LLM（复用第一层的重试机制）
  4. 写回结果

**兜底重试示例（阶段1：初评）**：
```python
# controller.py
def run_theme_recommendation_initial(excel_path: str):
    # ... 正常初评流程 ...

    # 兜底重试：检查是否有ERROR或空的初评结果
    retry_count = _retry_failed_reviews(excel_path, executor, writer)
    if retry_count > 0:
        logger.info("兜底重试完成，处理了 %d 条失败数据", retry_count)

    return {"selected": selected_all}
```

---

### 🔄 统一重试模式要求

**重要原则**：**所有阶段必须遵循相同的重试模式**

| 阶段 | LLM客户端重试 | 兜底重试函数 | 失败检查字段 |
|------|--------------|------------|-------------|
| 阶段1：初评 | ✅ 已实现 | `_retry_failed_reviews()` | `初评结果` |
| 阶段2：决选 | ✅ 继承 | `_retry_failed_runoffs()`【新增】 | `主题内决选结果` |
| 阶段3：终评 | ✅ 继承 | `_retry_failed_finals()`【新增】 | `终评结果` |

**新增兜底重试函数模板**：

```python
# controller.py

def _has_failed_runoff(row: pd.Series) -> bool:
    """检查数据是否决选失败"""
    result = row.get("主题内决选结果", "")
    if pd.isna(result) or not str(result).strip():
        return True
    # 白名单：合法值为 "自动晋级", "晋级", "未晋级"
    if str(result).strip() not in ["自动晋级", "晋级", "未晋级"]:
        return True
    return False

def _retry_failed_runoffs(excel_path: str, executor, writer) -> int:
    """兜底重试：处理所有失败的主题内决选数据"""
    df = pd.read_excel(excel_path)
    # 只重试初评通过但决选失败的数据
    passed_df = df[df.get("初评结果", "") == "通过"].copy()
    failed_df = passed_df[passed_df.apply(_has_failed_runoff, axis=1)].copy()

    if len(failed_df) == 0:
        logger.info("没有需要兜底重试的决选数据")
        return 0

    logger.info("开始兜底重试决选失败数据: %d 条", len(failed_df))

    # 重新加载writer
    writer.load()

    # 按主题分组重试
    groups = group_by_theme(failed_df)
    retry_count = 0

    for theme, gdf in groups.items():
        theme_count = len(gdf)
        quota = get_theme_finalist_quota()

        if theme_count <= quota:
            # 自动晋级
            for _, row in gdf.iterrows():
                idx = writer._find_row(row.get("书目条码", ""))
                if idx != -1:
                    writer.df.at[idx, "主题内决选结果"] = "自动晋级"
                    retry_count += 1
        else:
            # 重新调用LLM
            books = [_to_book_dict(row) for _, row in gdf.iterrows()]
            result = executor.runoff(theme, books, quota)
            if result:
                updated = writer.write_runoff(result)
                retry_count += updated

    writer.save()
    logger.info("兜底重试完成: 成功更新 %d 条数据", retry_count)
    return retry_count


def _has_failed_final(row: pd.Series) -> bool:
    """检查数据是否终评失败"""
    result = row.get("终评结果", "")
    if pd.isna(result) or not str(result).strip():
        return True
    # 白名单：合法值为 "通过", "未通过"
    if str(result).strip() not in ["通过", "未通过"]:
        return True
    return False

def _retry_failed_finals(excel_path: str, executor, writer, finalists: List[Dict]) -> int:
    """兜底重试：处理所有失败的终评数据"""
    df = pd.read_excel(excel_path)
    # 只重试决选晋级但终评失败的数据
    advanced_df = df[df.get("主题内决选结果", "").isin(["晋级", "自动晋级"])].copy()
    failed_df = advanced_df[advanced_df.apply(_has_failed_final, axis=1)].copy()

    if len(failed_df) == 0:
        logger.info("没有需要兜底重试的终评数据")
        return 0

    logger.info("开始兜底重试终评失败数据: %d 条", len(failed_df))

    # 重新调用终评（根据候选数量智能选择模式）
    failed_books = [_to_book_dict(row) for _, row in failed_df.iterrows()]
    threshold = get_final_mode_threshold()

    if len(failed_books) > threshold:
        # 使用锦标赛模式重试
        # 注意：这里可能需要简化为直接终评，避免过度复杂
        result = executor.final(failed_books, quota=10)
    else:
        result = executor.final(failed_books, quota=10)

    if result:
        writer.load()
        updated = writer.write_final(result)
        writer.save()
        logger.info("兜底重试完成: 成功更新 %d 条数据", updated)
        return updated

    return 0
```

**集成到主流程**：

```python
def run_theme_runoff(excel_path: str) -> List[Dict]:
    """主题内决选"""
    # ... 正常决选流程 ...

    # 兜底重试【新增】
    retry_count = _retry_failed_runoffs(excel_path, executor, writer)
    if retry_count > 0:
        logger.info("决选兜底重试完成，处理了 %d 条失败数据", retry_count)

    return all_finalists


def run_theme_recommendation_final(excel_path: str, finalists: List[Dict], top_n: int = 10):
    """全局终评（智能模式选择）"""
    # ... 正常终评流程 ...

    # 兜底重试【新增】
    executor = RecommendationExecutor()
    writer = ExcelRecommendationWriter(excel_path)
    retry_count = _retry_failed_finals(excel_path, executor, writer, finalists)
    if retry_count > 0:
        logger.info("终评兜底重试完成，处理了 %d 条失败数据", retry_count)
```

---

## 优化方案设计

### 三阶段漏斗模型

```
候选书目（200+本）
      ↓
┌─────────────────────────────────────┐
│ 阶段1：主题内初评（海选）           │
│ - 按主题分组，每组分批（≤20本）     │
│ - 使用动态配额快速筛选               │
│ - 输出：40-60本（主题分布不均）     │
└─────────────────────────────────────┘
      ↓
┌─────────────────────────────────────┐
│ 阶段2：主题内决选（晋级赛）【新增】│
│ - 控制各主题晋级上限（如8本）       │
│ - 确保主题多样性                     │
│ - 输出：20-30本（主题均衡）         │
└─────────────────────────────────────┘
      ↓
┌─────────────────────────────────────┐
│ 阶段3：全局终评（决赛圈）【优化】   │
│ - 锦标赛模式分批评选                 │
│ - 保证公平性                         │
│ - 输出：Top 10推荐书单               │
└─────────────────────────────────────┘
```

---

## 技术实现细节

### 阶段2：主题内决选（新增功能）

#### 功能目标
- 控制各主题进入终评的数量上限
- 选出各领域的"种子选手"
- 确保主题分布均衡
- **智能触发**：仅对超过配额的主题执行决选

#### 实现方案

**新增函数**: `controller.py::run_theme_runoff()`

```python
def run_theme_runoff(excel_path: str) -> List[Dict]:
    """
    主题内决选：智能控制各主题晋级终评的数量上限

    流程：
    1. 读取初评通过的书目（初评结果='通过'）
    2. 按索书号首字母重新分组
    3. 对每个主题组：
       - 若数量 > THEME_FINALIST_QUOTA（默认8）：
         * 调用LLM进行主题内决选
         * 选出最优的quota本
         * 写回"主题内决选结果"和"主题内决选理由"
       - 若数量 <= THEME_FINALIST_QUOTA：
         * 全部自动晋级，跳过LLM调用（节省成本）
         * 在"主题内决选结果"列写入"自动晋级"
    4. 返回所有晋级终评的书目列表

    返回：晋级终评的书目列表
    """
    df = pd.read_excel(excel_path)

    # 筛选初评通过的书目
    passed_df = df[df.get("初评结果", "") == "通过"].copy()

    # 按主题分组
    groups = group_by_theme(passed_df)

    # 加载配额配置
    quota = get_theme_finalist_quota()  # 默认8

    executor = RecommendationExecutor()
    writer = ExcelRecommendationWriter(excel_path)
    writer.load()

    all_finalists = []

    logger.info("=" * 60)
    logger.info("主题内决选开始")
    logger.info("初评通过总数: %d 本", len(passed_df))
    logger.info("主题总数: %d 个", len(groups))
    logger.info("决选配额: %d 本/主题", quota)
    logger.info("-" * 60)

    for theme, gdf in groups.items():
        theme_count = len(gdf)

        if theme_count <= quota:
            # 自动晋级，不调用LLM
            logger.info("主题 [%s]: %d 本 ≤ 配额 %d，自动晋级",
                       theme, theme_count, quota)

            for _, row in gdf.iterrows():
                all_finalists.append(_to_book_dict(row))
                # 写回标记
                idx = writer._find_row(row.get("书目条码", ""))
                if idx != -1:
                    writer.df.at[idx, "主题内决选结果"] = "自动晋级"
        else:
            # 需要决选，调用LLM
            logger.info("主题 [%s]: %d 本 > 配额 %d，执行决选",
                       theme, theme_count, quota)

            books = [_to_book_dict(row) for _, row in gdf.iterrows()]
            result = executor.runoff(theme, books, quota)

            # 处理晋级书目
            for book in result.get("selected_books", []):
                matched = next((b for b in books if str(b.get("书目条码")) == str(book.get("id"))), None)
                if matched:
                    all_finalists.append(matched)
                    # 写回晋级结果
                    idx = writer._find_row(book.get("id", ""))
                    if idx != -1:
                        writer.df.at[idx, "主题内决选结果"] = "晋级"
                        writer.df.at[idx, "主题内决选理由"] = book.get("reason", "")

            # 处理未晋级书目
            for group in result.get("unselected_books", []):
                for b in group.get("books", []):
                    idx = writer._find_row(b.get("id", ""))
                    if idx != -1:
                        writer.df.at[idx, "主题内决选结果"] = "未晋级"
                        writer.df.at[idx, "主题内决选理由"] = group.get("explanation", "")

            logger.info("主题 [%s] 决选完成: 晋级 %d 本",
                       theme, len(result.get("selected_books", [])))

    writer.save()

    logger.info("=" * 60)
    logger.info("主题内决选完成: 共晋级 %d 本进入终评", len(all_finalists))
    logger.info("=" * 60)

    return all_finalists
```

#### 新增配置项

**文件**: `config.py`

```python
# 主题内决选配额（每个主题最多晋级几本进入终评）
# 这是代码层的兜底默认值，当配置文件读取失败时使用
THEME_FINALIST_QUOTA = 8

def get_theme_finalist_quota() -> int:
    """
    从配置文件加载主题决选配额

    优先级：
    1. config/llm.yaml 中的 tasks.theme_runoff.parameters.finalist_quota（可动态修改）
    2. 代码默认值 THEME_FINALIST_QUOTA（配置文件读取失败时的兜底值）

    这种设计的好处：
    - 可通过修改 yaml 文件动态调整配额，无需修改代码
    - 配置文件缺失或格式错误时不会导致程序崩溃
    """
    try:
        loader = ConfigLoader(LLM_CONFIG_PATH)
        settings = loader.load()
        # 从yaml读取，若不存在则使用代码默认值
        quota = settings.get("tasks", {}).get("theme_runoff", {}).get("finalist_quota", THEME_FINALIST_QUOTA)
        return int(quota)
    except Exception as e:
        logger.warning("加载主题决选配额失败，使用默认值 %d: %s", THEME_FINALIST_QUOTA, e)
        return THEME_FINALIST_QUOTA
```

**配置优先级说明**：

| 配置位置 | 优先级 | 用途 | 示例值 |
|---------|-------|------|--------|
| `config/llm.yaml` | 高 | 运行时可调参数，支持快速调整 | `finalist_quota: 8` |
| `config.py` | 低 | 代码兜底默认值，保证程序健壮性 | `THEME_FINALIST_QUOTA = 8` |

**使用建议**：
- ✅ 生产环境：在 `llm.yaml` 中设置，方便调整
- ✅ 测试环境：可以设置不同的值进行A/B测试（如 `finalist_quota: 5` 或 `12`）
- ✅ 容错保障：即使yaml文件损坏，程序仍能以默认值8运行

#### Prompt设计

**新增提示词**: `build_runoff_prompt()`

```python
def build_runoff_prompt(theme: str, books: List[Dict], quota: int) -> str:
    """
    构建主题内决选提示词

    示例：
    主题: T（工业技术）
    当前有 8 本候选书已通过初评，请从中评选出 **不超过 3 本** 最具代表性、
    最值得推荐的书籍。请综合考虑其深度、影响力、可读性和独特性。

    <书目块信息...>
    """
```

#### Excel写回列

**新增列**:
- `主题内决选结果`（晋级/未晋级）
- `主题内决选理由`

---

### 阶段3：全局终评（优化）

#### 方案A：锦标赛模式（推荐）

**流程**：
```
1. 随机分组：A组（14本）、B组（14本）
2. 小组赛：
   - 各组独立调用LLM评分
   - 取前50%晋级（A组前7名、B组前7名）
3. 决赛：
   - 14本晋级者进行最终评选
   - 选出Top 10
```

**优点**：
- ✅ 避免批次效应
- ✅ 公平性强
- ✅ 评选质量高

**缺点**：
- ⚠️ LLM调用次数增加（3次 vs 1次）
- ⚠️ 成本上升

**实现代码**：

```python
def run_tournament_final(excel_path: str, books: List[Dict], top_n: int = 10):
    """
    锦标赛模式终评

    参数:
        books: 主题内决选后的书目列表（20-30本）
        top_n: 最终推荐数量（默认10本）
    """
    import random

    # 1. 随机分组
    shuffled = books.copy()
    random.shuffle(shuffled)
    mid = len(shuffled) // 2
    group_a = shuffled[:mid]
    group_b = shuffled[mid:]

    executor = RecommendationExecutor()

    # 2. 小组赛
    logger.info("锦标赛-小组赛 A组: %d 本", len(group_a))
    result_a = executor.semifinal(group_a, quota=len(group_a)//2)

    logger.info("锦标赛-小组赛 B组: %d 本", len(group_b))
    result_b = executor.semifinal(group_b, quota=len(group_b)//2)

    # 3. 收集晋级者
    finalists = []
    for book in result_a.get("selected_books", []):
        matched = next((b for b in group_a if str(b["书目条码"]) == str(book["id"])), None)
        if matched:
            finalists.append({**matched, "半决赛分数": book.get("rating"), "半决赛理由": book.get("reason")})

    for book in result_b.get("selected_books", []):
        matched = next((b for b in group_b if str(b["书目条码"]) == str(book["id"])), None)
        if matched:
            finalists.append({**matched, "半决赛分数": book.get("rating"), "半决赛理由": book.get("reason")})

    # 4. 决赛
    logger.info("锦标赛-决赛: %d 本 → Top %d", len(finalists), top_n)
    final_result = executor.final(finalists, quota=top_n)

    # 5. 写回Excel
    writer = ExcelRecommendationWriter(excel_path)
    writer.load()
    writer.write_final(final_result)
    writer.save()
```

#### 方案B：直接终评（成本优化版）

**适用场景**：候选数 ≤ 30

**流程**：
```
1. 一次性调用LLM
2. 选出Top N（默认10本）
```

**优点**：
- ✅ LLM调用次数少（1次）
- ✅ 实现简单
- ✅ 成本最低

**实现代码**：

```python
def run_direct_final(excel_path: str, finalists: List[Dict], top_n: int = 10):
    """
    直接终评模式：候选数较少时一次性评选

    参数:
        finalists: 主题内决选后的书目列表（≤30本）
        top_n: 最终推荐数量（默认10本）
    """
    executor = RecommendationExecutor()
    writer = ExcelRecommendationWriter(excel_path)
    writer.load()

    logger.info("执行直接终评 | 候选数=%d | 目标Top=%d", len(finalists), top_n)

    result = executor.final(finalists, quota=top_n)
    writer.write_final(result)
    writer.save()

    logger.info("直接终评完成 | 最终入选=%d 本", len(result.get("selected_books", [])))
```

---

#### 智能模式选择（推荐方案）

**实现**：在 `controller.py` 中自动判断

```python
def run_theme_recommendation_final(excel_path: str, finalists: List[Dict], top_n: int = 10):
    """
    全局终评：根据候选数量智能选择评选模式

    决策逻辑：
    - 候选数 > FINAL_MODE_THRESHOLD（默认30）：锦标赛模式
    - 候选数 <= FINAL_MODE_THRESHOLD：直接终评
    """
    finalist_count = len(finalists)
    threshold = get_final_mode_threshold()  # 从配置加载，默认30

    logger.info("=" * 60)
    logger.info("全局终评开始")
    logger.info("终评候选数: %d 本", finalist_count)
    logger.info("模式切换阈值: %d", threshold)

    if finalist_count > threshold:
        logger.info("候选数 > %d，采用锦标赛模式（保证公平性）", threshold)
        run_tournament_final(excel_path, finalists, top_n)
    else:
        logger.info("候选数 <= %d，采用直接终评模式（节省成本）", threshold)
        run_direct_final(excel_path, finalists, top_n)

    logger.info("全局终评完成")
    logger.info("=" * 60)
```

**配置项**：

```python
# config.py
FINAL_MODE_THRESHOLD = 30  # 终评模式切换阈值

def get_final_mode_threshold() -> int:
    """从配置文件加载终评模式切换阈值"""
    try:
        loader = ConfigLoader(LLM_CONFIG_PATH)
        settings = loader.load()
        threshold = settings.get("tasks", {}).get("theme_final", {}).get("mode_threshold", FINAL_MODE_THRESHOLD)
        return int(threshold)
    except Exception:
        return FINAL_MODE_THRESHOLD
```

**决策表**：

| 候选数量 | 自动选择模式 | LLM调用次数 | 成本 | 公平性 |
|---------|-------------|------------|------|--------|
| > 30 | 锦标赛模式 | 3次 | 高 | ⭐⭐⭐⭐⭐ |
| ≤ 30 | 直接终评 | 1次 | 低 | ⭐⭐⭐⭐ |

---

## 开发任务清单

### 阶段1：配置与基础设施

- [ ] **任务1.1**: 在 `config.py` 中新增配置项
  - 位置: [config.py](../../../src/core/recommendation/config.py)
  - 新增常量:
    - `THEME_FINALIST_QUOTA = 8`（主题内决选配额）
    - `FINAL_MODE_THRESHOLD = 30`（终评模式切换阈值）
  - 新增函数:
    - `get_theme_finalist_quota()`: 加载主题决选配额
    - `get_final_mode_threshold()`: 加载终评模式阈值

- [ ] **任务1.2**: 在 `config/llm.yaml` 中新增任务配置
  ```yaml
  tasks:
    theme_runoff:  # 主题内决选
      provider_type: text
      temperature: 0.40
      prompt:
        type: langfuse
        langfuse_name: "书目主题内决选"
      parameters:
        finalist_quota: 8  # 每个主题最多晋级8本
      retry:
        max_retries: 3
      json_repair:
        enabled: true
      langfuse:
        enabled: true
        name: "llm主题决选"
        tags: ["book-echoes", "模块4", "决选"]

    theme_semifinal:  # 锦标赛半决赛
      provider_type: text
      temperature: 0.35
      prompt:
        type: langfuse
        langfuse_name: "书目半决赛评选"
      retry:
        max_retries: 3
      json_repair:
        enabled: true
      langfuse:
        enabled: true
        name: "llm半决赛"
        tags: ["book-echoes", "模块4", "锦标赛"]

    theme_final:
      # ... 原有配置 ...
      parameters:
        mode_threshold: 30  # 终评模式切换阈值
        top_n: 10
  ```

- [ ] **任务1.3**: 在 `excel_writer.py` 中新增决选列支持
  - **设计原则**：**阶段隔离** - 每个阶段只负责写入自己的列
  - 新增常量：
    ```python
    RUNOFF_COLUMNS = [
        "主题内决选结果", "主题内决选理由"
    ]
    ```
  - 修改 `load()` 方法：将 `RUNOFF_COLUMNS` 加入列初始化
  - 新增方法：
    ```python
    def write_runoff(self, result: Dict[str, Any]) -> int:
        """
        写入主题内决选结果

        重要：只写入 RUNOFF_COLUMNS，不触碰 INITIAL_COLUMNS 和 FINAL_COLUMNS

        返回：更新的行数
        """
    ```
  - **列值规范**：
    - `主题内决选结果`：`"自动晋级"` | `"晋级"` | `"未晋级"`
    - `主题内决选理由`：晋级理由或淘汰说明

### 阶段2：主题内决选实现

- [ ] **任务2.1**: 在 `prompt_builder.py` 中新增 `build_runoff_prompt()`
  - 输入: 主题名、书目列表、配额
  - 输出: 主题内决选提示词
  - 提示词要点：强调从已通过初评的书目中选出最优的quota本

- [ ] **任务2.2**: 在 `executor.py` 中新增 `runoff()` 方法
  ```python
  def runoff(self, theme: str, books: List[Dict], quota: int) -> Dict[str, Any]:
      """
      主题内决选执行器

      参数:
          theme: 主题名称（如"T"）
          books: 该主题下初评通过的书目列表
          quota: 决选配额（默认8）

      返回:
          {"selected_books": [...], "unselected_books": [...]}
      """
  ```

- [ ] **任务2.3**: 在 `controller.py` 中实现完整的 `run_theme_runoff()` 逻辑
  - 读取初评通过的书目（`初评结果='通过'`）
  - 按主题分组
  - 遍历每个主题组：
    - 若数量 > quota：调用 `executor.runoff()` 执行决选
    - 若数量 <= quota：自动晋级，跳过LLM调用
  - 写回 Excel（`主题内决选结果`、`主题内决选理由`）
  - **【重要】添加兜底重试**：调用 `_retry_failed_runoffs()` 处理失败数据
  - 返回所有晋级终评的书目列表

- [ ] **任务2.4**: 在 `controller.py` 中实现 `_has_failed_runoff()` 和 `_retry_failed_runoffs()`
  - **参考模板**：复用 `_has_failed_review()` 和 `_retry_failed_reviews()` 的模式
  - 失败检查：白名单模式，合法值为 `["自动晋级", "晋级", "未晋级"]`
  - 兜底重试逻辑：
    1. 扫描 Excel，找出决选失败的行
    2. 按主题分组
    3. 根据数量决定自动晋级或调用LLM
    4. 写回结果

- [ ] **任务2.5**: 修改 `run_theme_recommendation_full()` 集成决选阶段
  ```python
  def run_theme_recommendation_full(excel_path: str) -> None:
      # 阶段1: 初评（已实现）
      run_theme_recommendation_initial(excel_path)

      # 阶段2: 主题内决选【新增】
      finalists = run_theme_runoff(excel_path)

      # 阶段3: 全局终评（智能模式选择）【优化】
      run_theme_recommendation_final(excel_path, finalists)
  ```

### 阶段3：全局终评优化（智能模式选择）

- [ ] **任务3.1**: 在 `executor.py` 中新增 `semifinal()` 方法（锦标赛半决赛用）
  ```python
  def semifinal(self, books: List[Dict], quota: int) -> Dict[str, Any]:
      """
      锦标赛半决赛执行器

      参数:
          books: 一组书目列表
          quota: 晋级配额（通常为组内数量的50%）

      返回:
          {"selected_books": [...], "unselected_books": [...]}
      """
  ```

- [ ] **任务3.2**: 在 `controller.py` 中新增 `run_tournament_final()`
  - 实现完整的锦标赛逻辑：
    - 随机打乱候选书目
    - 分成A/B两组
    - 各组独立调用 `executor.semifinal()` 选出前50%
    - 汇总晋级者调用 `executor.final()` 进行决赛
  - 写回终评结果

- [ ] **任务3.3**: 在 `controller.py` 中新增 `run_direct_final()`
  - 直接终评模式（候选数 ≤ 30时使用）
  - 一次性调用 `executor.final()` 选出Top N
  - 写回终评结果

- [ ] **任务3.4**: 修改 `run_theme_recommendation_final()` 实现智能模式选择
  - 读取配置的阈值（默认30）
  - 根据候选数量自动选择：
    - > 阈值 → 调用 `run_tournament_final()`
    - ≤ 阈值 → 调用 `run_direct_final()`
  - 记录日志说明选择的模式和原因
  - **【重要】添加兜底重试**：调用 `_retry_failed_finals()` 处理失败数据

- [ ] **任务3.5**: 在 `controller.py` 中实现 `_has_failed_final()` 和 `_retry_failed_finals()`
  - **参考模板**：复用 `_has_failed_review()` 和 `_retry_failed_reviews()` 的模式
  - 失败检查：白名单模式，合法值为 `["通过", "未通过"]`
  - 兜底重试逻辑：
    1. 扫描 Excel，找出终评失败的行
    2. 重新调用终评（根据数量智能选择模式）
    3. 写回结果

- [ ] **任务3.6**: 在 `config.py` 中新增 `get_final_mode_threshold()` 函数
  - 从 `llm.yaml` 的 `tasks.theme_final.parameters.mode_threshold` 读取
  - 默认值 30

### 阶段4：测试与验证

- [ ] **任务4.1**: 单元测试
  - 测试 `get_theme_finalist_quota()`
  - 测试 `build_runoff_prompt()`
  - 测试决选逻辑的边界条件

- [ ] **任务4.2**: 集成测试
  - 使用真实Excel数据测试完整三阶段流程
  - 验证主题分布均衡性

- [ ] **任务4.3**: 性能测试
  - 对比两阶段 vs 三阶段的LLM调用次数
  - 评估成本增加幅度

### 阶段5：文档与部署

- [ ] **任务5.1**: 更新用户文档
  - 说明三阶段逻辑
  - 配置项说明

- [ ] **任务5.2**: 更新Langfuse Prompt
  - 创建"书目主题内决选"提示词模板
  - 创建"书目半决赛评选"提示词模板

- [ ] **任务5.3**: 更新主程序菜单（main.py）
  - **方案**：保持简洁，不增加过多菜单项
  - **调整内容**：
    ```python
    # 原菜单
    4. 模块4: 主题推荐评选（初评）
    5. 模块4: 主题推荐评选（初评→终评）
    6. 完整流程: 模块1 -> 模块2 -> 模块3 -> 模块4（初评+终评）

    # 新菜单（方案A：保持简洁）
    4. 模块4: 初评（海选阶段）
    5. 模块4: 完整评选（初评→决选→终评）
    6. 完整流程: 模块1 -> 模块2 -> 模块3 -> 模块4
    ```
  - **说明文字优化**：
    - 选项4说明：仅运行初评阶段，用于测试或分步执行
    - 选项5说明：运行完整三阶段评选流程（推荐）
    - 选项6说明：从数据采集到推荐评选的完整流程
  - **代码映射**：
    - 选项4 → `run_theme_recommendation_initial()`（保持不变）
    - 选项5 → `run_theme_recommendation_full()`（内部执行：初评→决选→终评）
    - 选项6 → 全流程（保持不变）

---

## 测试与验证

### 测试数据准备

**模拟场景**：
```
初评通过50本书：
- T类（工业技术）：20本
- Q类（生物科学）：5本
- P类（社会科学）：10本
- I类（文学）：8本
- Other类：7本
```

### 验证指标

#### 1. 主题多样性指标
```python
def calculate_theme_diversity(books: List[Dict]) -> float:
    """
    计算主题多样性（香农熵）

    返回值越大，主题分布越均衡
    """
    from collections import Counter
    import math

    themes = [normalize_theme(b.get("索书号", "")) for b in books]
    counts = Counter(themes)
    total = len(books)

    entropy = 0
    for count in counts.values():
        p = count / total
        entropy -= p * math.log2(p)

    return entropy
```

**期望结果**：
- 两阶段模式：熵 < 2.0（主题集中）
- 三阶段模式：熵 > 2.5（主题均衡）

#### 2. 评选公平性指标
```python
def calculate_fairness_score(tournament_results: List[Dict]) -> float:
    """
    计算锦标赛公平性分数

    对比直接评选 vs 锦标赛评选的结果差异
    """
    # 实现略
```

### 自动化测试脚本

**文件**: `tests/test_three_stage_recommendation.py`

```python
import pytest
from src.core.recommendation import controller

def test_theme_runoff_quota_limit():
    """测试主题内决选配额限制"""
    # 准备测试数据：T类有10本书
    # 执行决选，配额=3
    # 断言：返回的T类书目 <= 3本

def test_tournament_fairness():
    """测试锦标赛公平性"""
    # 准备测试数据：28本书
    # 执行锦标赛终评
    # 断言：各组晋级率相近

def test_theme_diversity_improvement():
    """测试主题多样性提升"""
    # 对比两阶段 vs 三阶段的主题熵
    # 断言：三阶段熵 > 两阶段熵
```

---

## 配置与部署

### 配置文件示例

**文件**: `config/llm.yaml`（完整版）

```yaml
api_providers:
  text:
    primary:
      name: "oneapi"
      api_key: env:ONEAPI_API_KEY
      base_url: "http://47.103.50.106:3000/v1"
      model: "gemini-2.5-pro"
      timeout_seconds: 120
    secondary:
      name: "cerebras"
      api_key: env:CEREBRAS_API_KEY
      base_url: "https://api.cerebras.ai/v1"
      model: "zai-glm-4.6"
      timeout_seconds: 120

tasks:
  # 阶段1：主题内初评
  theme_initial:
    provider_type: text
    temperature: 0.45
    prompt:
      type: langfuse
      langfuse_name: "书目初评"
    parameters:
      recommend_quota:
        gt20: 6
        g15_20: 5
        g10_15: 4
        g5_10: 3
        lt5: 2
    retry:
      max_retries: 3
    json_repair:
      enabled: true

  # 阶段2：主题内决选【新增】
  theme_runoff:
    provider_type: text
    temperature: 0.40
    prompt:
      type: langfuse
      langfuse_name: "书目主题内决选"
    parameters:
      finalist_quota: 3  # 每个主题最多晋级3本
    retry:
      max_retries: 3
    json_repair:
      enabled: true
    langfuse:
      enabled: true
      name: "llm主题决选"
      tags: ["book-echoes", "模块4", "决选"]

  # 阶段3a：锦标赛半决赛【可选】
  theme_semifinal:
    provider_type: text
    temperature: 0.35
    prompt:
      type: langfuse
      langfuse_name: "书目半决赛评选"
    retry:
      max_retries: 3
    json_repair:
      enabled: true

  # 阶段3b：全局终评
  theme_final:
    provider_type: text
    temperature: 0.35
    prompt:
      type: langfuse
      langfuse_name: "书目终评"
    parameters:
      final_mode: "tournament"  # tournament | batch | direct
      top_n: 10
    retry:
      max_retries: 3
    json_repair:
      enabled: true
```

### 运行模式

**完整三阶段流程**：
```python
python main.py
# 选择菜单项 "5. 初评→终评"
```

**单独运行决选阶段**：
```python
from src.core.recommendation import controller

# 前置条件：已完成初评
finalists = controller.run_theme_runoff("runtime/outputs/xxx.xlsx")
print(f"晋级终评: {len(finalists)} 本")
```

---

## 附录

### A. 代码文件对照表

| 文件 | 行号 | 功能 | 状态 |
|------|------|------|------|
| [controller.py](../../../src/core/recommendation/controller.py#L128-L231) | 128-231 | 初评流程 | ✅ 已实现 |
| [controller.py](../../../src/core/recommendation/controller.py#L233-L239) | 233-239 | 终评流程 | ⚠️ 需优化 |
| [config.py](../../../src/core/recommendation/config.py#L12-L18) | 12-18 | 动态配额 | ✅ 已实现 |
| [theme_grouper.py](../../../src/core/recommendation/theme_grouper.py#L5-L13) | 5-13 | 主题分组 | ✅ 已实现 |
| [executor.py](../../../src/core/recommendation/executor.py#L121-L156) | 121-156 | 初评执行器 | ✅ 已实现 |
| [excel_writer.py](../../../src/core/recommendation/excel_writer.py#L54-L88) | 54-88 | 初评写回 | ✅ 已实现 |

### B. 关键决策记录

| 决策点 | 方案 | 理由 |
|--------|------|------|
| 主题决选配额 | 8本/主题 | 平衡多样性与质量，避免过度限制 |
| 决选触发条件 | 主题书目数 > 配额时触发 | 节省成本，小主题自动晋级 |
| 终评模式切换 | 候选数 > 30 时锦标赛 | 自动选择，平衡成本与公平性 |
| 终评模式阈值 | 30本 | 基于Token限制和注意力分散考虑 |
| 是否写回决选列 | 必须写回 | 便于审计和追溯决选过程 |
| 配额配置位置 | llm.yaml | 统一管理LLM相关配置 |

### C. 优化方案核心优势

#### 0. 统一重试机制（稳定性保障）

**两层重试架构**：

```
┌─────────────────────────────────────────────┐
│ 第一层：LLM客户端自动重试                  │
│ - 指数退避（1.2s → 2.4s → 4.8s → 12s）      │
│ - 主备API切换（primary → secondary）        │
│ - 配置在 llm.yaml 的 retry 部分             │
└─────────────────────────────────────────────┘
          ↓ 仍然失败
┌─────────────────────────────────────────────┐
│ 第二层：业务层兜底重试                      │
│ - 阶段完成后扫描失败数据                    │
│ - 按主题/批次重新组织                       │
│ - 再次调用LLM（复用第一层重试）             │
│ - 写回结果或保留ERROR标记                   │
└─────────────────────────────────────────────┘
```

**三阶段统一实现**：

| 阶段 | 第一层（LLM自动） | 第二层（兜底重试） | 失败白名单 |
|------|------------------|-------------------|-----------|
| 阶段1：初评 | ✅ `config/llm.yaml` | ✅ `_retry_failed_reviews()` | `["通过", "未通过"]` |
| 阶段2：决选 | ✅ 继承 | `_retry_failed_runoffs()`【新增】 | `["自动晋级", "晋级", "未晋级"]` |
| 阶段3：终评 | ✅ 继承 | `_retry_failed_finals()`【新增】 | `["通过", "未通过"]` |

**实现一致性保证**：
- ✅ 所有executor方法都使用相同的错误处理逻辑
- ✅ 所有controller函数都实现兜底重试
- ✅ 所有失败检查都使用白名单模式（非法值 = 失败）

#### 1. 成本优化（智能触发）

**阶段2：主题内决选**
- ❌ 原方案：所有主题都执行决选
- ✅ 优化方案：仅对书目数 > 配额的主题执行决选
- 💰 成本节省：假设有10个主题，只有3个超过配额，节省70% LLM调用

**阶段3：全局终评**
- ❌ 原方案：固定使用锦标赛（3次LLM调用）
- ✅ 优化方案：候选数 ≤ 30 时直接终评（1次LLM调用）
- 💰 成本节省：中小规模场景下节省66%成本

#### 2. 主题多样性保障

**问题解决**：
```
两阶段模式结果（假设）：
- T类（工业技术）：6本/10本（60%）
- Q类（生物科学）：1本/10本（10%）
- 其他主题：3本/10本（30%）
→ 主题集中度过高

三阶段模式结果（预期）：
- T类：3本/10本（30%）← 决选限制
- Q类：2本/10本（20%）← 自动晋级
- P类：3本/10本（30%）← 决选限制
- 其他：2本/10本（20%）
→ 主题分布均衡
```

#### 3. 评选公平性提升

**锦标赛模式优势**（候选数 > 30时）：
- ✅ 避免批次效应
- ✅ 所有书目都有相同的晋级机会
- ✅ 决赛圈的竞争更加公平

**直接终评优势**（候选数 ≤ 30时）：
- ✅ 无需分批，注意力集中
- ✅ 成本最低
- ✅ 适合中小规模场景

#### 4. 灵活性与可配置性

**可调参数**：
- `THEME_FINALIST_QUOTA`（主题决选配额）：默认8，可根据实际情况调整
- `FINAL_MODE_THRESHOLD`（终评模式阈值）：默认30，可根据成本预算调整
- 温度参数：决选0.40，半决赛0.35，终评0.35

**适应场景**：
- 高质量优先：提高决选配额（如12本/主题）
- 成本优先：降低决选配额（如5本/主题），提高终评阈值（如50本）
- 多样性优先：降低决选配额（如3本/主题）

### D. 实施风险与缓解措施

| 风险 | 缓解措施 |
|------|---------|
| 决选逻辑复杂，容易出错 | 编写详细的单元测试，覆盖边界条件 |
| Excel列数增加，用户困惑 | 提供清晰的列说明文档 |
| LLM调用失败导致流程中断 | 继承现有的重试机制和错误标记 |
| 配置参数过多，难以理解 | 提供默认值，并在文档中说明每个参数的影响 |

### E. 参考资料

- [评选逻辑优化讨论.md](./评选逻辑优化讨论.md) - 优化建议原文
- [模块4-大模型评选开发说明文档计划.md](./模块4-大模型评选开发说明文档计划.md) - 初始设计文档
- [config/llm.yaml](../../../config/llm.yaml) - LLM配置文件

---

## 版本历史

| 版本 | 日期 | 变更说明 |
|------|------|---------|
| v1.0 | 2025-11-17 | 初始版本，基于实际代码分析编写 |
| v1.1 | 2025-11-17 | 集成用户优化建议：智能触发决选、自动选择终评模式 |

---

**文档维护者**: AI Development Team
**最后更新**: 2025-11-17

---

## 快速开始指南

### 最小改动实现方案

如果时间紧张，可以按以下优先级逐步实现：

#### 阶段1：核心功能（必须）
1. ✅ 在 `config.py` 添加 `THEME_FINALIST_QUOTA = 8` 和 `get_theme_finalist_quota()`
2. ✅ 在 `prompt_builder.py` 添加 `build_runoff_prompt()`
3. ✅ 在 `executor.py` 添加 `runoff()` 方法
4. ✅ 在 `controller.py` 添加 `run_theme_runoff()`
5. ✅ 修改 `run_theme_recommendation_full()` 集成决选

**完成后效果**：解决主题分布不均问题

#### 阶段2：智能优化（推荐）
1. ✅ 在 `config.py` 添加 `FINAL_MODE_THRESHOLD = 30` 和 `get_final_mode_threshold()`
2. ✅ 在 `controller.py` 添加 `run_direct_final()`
3. ✅ 修改 `run_theme_recommendation_final()` 实现智能模式选择

**完成后效果**：自动节省成本

#### 阶段3：完整功能（可选）
1. ⭐ 在 `executor.py` 添加 `semifinal()` 方法
2. ⭐ 在 `controller.py` 添加 `run_tournament_final()`
3. ⭐ 完善测试和文档

**完成后效果**：大规模场景下的公平性保障
