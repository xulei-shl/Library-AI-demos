# 大模型三阶段评选逻辑总结

> 基于实际代码分析，用于论文3.1和3.3小节修订

---

## 1. 三阶段评选总体流程

大模型评选模块采用**三级漏斗式筛选架构**，从候选书目池中逐步精炼出最终推荐书目。该架构的设计目标是兼顾评选质量与计算成本，通过多阶段、多层次的评估机制实现书目价值的深度挖掘。

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           三阶段评选流程总览                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  阶段1: 主题内初评（海选）                                                   │
│  ├─ 输入: 经过负向筛选后的候选书目池                                          │
│  ├─ 逻辑: 按索书号首字母分组，每批≤20本，动态配额筛选                          │
│  ├─ 阈值: >20本选6本，15-20本选5本，10-15本选4本，5-10本选3本，<5本选2本       │
│  └─ 输出: 初评通过书目 + 初评理由                                             │
│              ↓                                                               │
│  阶段2: 主题内决选（晋级赛）                                                 │
│  ├─ 输入: 初评通过的书目                                                      │
│  ├─ 逻辑: 控制各主题晋级终评的数量上限（默认8本）                              │
│  ├─ 优化: ≤配额自动晋级，>配额调用LLM决选                                     │
│  └─ 输出: 晋级终评书目 + 决选理由                                             │
│              ↓                                                               │
│  阶段3: 全局终评（决赛圈）                                                   │
│  ├─ 输入: 所有主题晋级书目                                                    │
│  ├─ 逻辑: 自适应漏斗策略（≤30本直接终评，>30本锦标赛模式）                     │
│  └─ 输出: 最终推荐书单（Top N，默认20本）                                     │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 1.1 核心设计理念

本模块的核心设计理念是将传统的"人工评审"流程进行**拟人化模拟**。在传统图书馆选书过程中，专家评审通常经历三个阶段：初步浏览筛选、重点领域深度评估、全局统筹决选。三阶段评选逻辑正是对这一流程的技术复现：

1. **初评阶段**对应专家的"快速浏览"环节，通过控制单批次处理量和动态配额，模拟专家在有限精力下进行高效筛选的过程。
2. **决选阶段**对应专家组的"组内讨论"环节，通过设定主题内晋级上限，确保各主题类别在最终评选中具有均衡的代表性和公平性。
3. **终评阶段**对应专家组的"全体会议"环节，通过自适应策略模拟专家在面对不同规模候选集时的灵活评审策略。

---

## 2. 阶段详解

### 2.1 阶段1：主题内初评（Initial Review）

#### 2.1.1 功能定位

主题内初评是整个评选流程的**第一道漏斗**，其核心职责是从大规模的候选书目池中进行初步筛选，识别出具有潜在推荐价值的书目。该阶段强调"广度覆盖"与"效率优先"，通过相对宽松的筛选标准，确保不遗漏有价值的候选书目。

#### 2.1.2 核心逻辑

**分组机制**：按索书号首字母将书目划分为不同主题类别（T-工业技术、I-文学、O-数理科学等），这一分组策略与图书馆分类法保持一致，便于后续的分类管理和比较评估。

**批次处理**：每批次处理的书目数量上限为20本（可配置），这一数值基于LLM上下文窗口大小和处理效率的综合考量。批次划分遵循`split_batches`函数实现的均匀分配算法，确保各批次数量差异不超过1本。

**动态配额**：初评阶段的推荐配额根据批次内书目总数动态调整，具体规则如下：

| 批次书目数 | 推荐配额 | 设计考量 |
|-----------|---------|---------|
| >20本 | 6本 | 基数大时可适度提高筛选标准 |
| 15-20本 | 5本 | 适中规模，保持竞争力 |
| 10-15本 | 4本 | 小规模批次需保护多样性 |
| 5-10本 | 3本 | 小批量避免过度筛选 |
| <5本 | 2本 | 极小批量需珍惜每个候选 |

#### 2.1.3 技术实现

**执行入口**：`run_theme_recommendation_initial()`（controller.py:179）

**核心执行**：`executor.initial(theme, books)`（executor.py:141）

**提示词构建**：`build_initial_prompt(theme, books)`（prompt_builder.py:17）

**LLM任务配置**：`theme_initial`（llm.yaml:40-78）

**输出字段**：`初评结果`、`初评分数`、`初评理由`、`初评淘汰原因`、`初评淘汰说明`

#### 2.1.4 幂等性与容错

系统实现了完善的幂等性检查机制，通过`_needs_initial_review()`函数（controller.py:45）过滤已有合法结果的数据，避免重复调用LLM。同时，通过`_retry_failed_reviews()`函数（controller.py:100）实现兜底重试，确保因LLM调用失败而产生ERROR状态的数据能够被重新处理。

---

### 2.2 阶段2：主题内决选（Runoff）

#### 2.2.1 功能定位

主题内决选是**平衡性控制层**，其核心职责是解决初评阶段可能产生的主题分布不均问题。通过设定各主题晋级终评的数量上限，确保最终推荐书单在主题维度上的代表性和多样性。该阶段的设计体现了"公平性优先"的核心原则。

#### 2.2.2 核心逻辑

**配额控制**：每个主题晋级终评的书目数量上限为8本（可配置）。这一数值的设定基于以下考量：假设初始候选书目覆盖10-15个主题类别，8本/主题的上限可确保终评阶段的候选书目总数控制在合理范围内（80-120本）。

**智能触发机制**：系统采用"自动晋级"策略优化LLM调用成本。当某主题初评通过的书目数量≤配额时，这些书目直接标记为"自动晋级"，无需调用LLM进行决选评估。这一设计显著降低了在候选书目分布稀疏场景下的计算成本。

**决选评估**：当某主题初评通过的书目数量>配额时，系统调用LLM进行主题内决选，从中选择最具代表性的配额数量的书目晋级终评。

#### 2.2.3 技术实现

**执行入口**：`run_theme_runoff()`（controller.py:368）

**核心执行**：`executor.runoff(theme, books, quota)`（executor.py:199）

**提示词构建**：`build_runoff_prompt(theme, books, quota)`（prompt_builder.py:37）

**LLM任务配置**：`theme_runoff`（llm.yaml:121-150）

**输出字段**：`主题内决选结果`、`主题内决选理由`

#### 2.2.4 决选结果状态

决选阶段产生三种结果状态：

| 状态 | 含义 | 触发条件 |
|-----|------|---------|
| 自动晋级 | 书目直接进入终评 | 初评通过数≤配额 |
| 晋级 | 通过LLM决选评估后进入终评 | 初评通过数>配额且入选决选推荐 |
| 未晋级 | 止步于决选阶段 | 初评通过数>配额但未入选决选推荐 |

---

### 2.3 阶段3：全局终评（Adaptive Final）

#### 2.3.1 功能定位

全局终评是**质量把控层**，其核心职责是从所有主题晋级的书目中进行最终筛选，输出符合目标数量的高质量推荐书单。该阶段强调"精确控制"与"全局最优"，通过自适应策略确保在不同规模候选集下均能获得最优评选结果。

#### 2.3.2 核心逻辑

**自适应漏斗策略**：根据晋级终评的候选书目数量，系统自动选择最优评审模式：

| 候选数 | 评审模式 | 流程说明 |
|-------|---------|---------|
| ≤30本 | 直接终评 | 一次性全局评估，简单高效 |
| >30本 | 锦标赛模式 | 分批海选+决赛，确保公平性 |

**直接终评模式**：当候选书目数量≤批次上限（默认30本）时，系统调用LLM进行一次性的全局评估，直接从候选书目中选出Top N本进入推荐书单。

**锦标赛模式**：当候选书目数量>批次上限时，系统采用两阶段筛选策略：

1. **海选阶段（Semifinal）**：将候选书目随机打乱后分批（每批≤30本），每批选出约`max_batch_size/批数`本晋级，总晋级数≈批次上限。随机打乱机制避免因书目原始排序导致的批次质量偏差。

2. **决赛阶段（Final）**：将海选晋级者（此时数量≤批次上限）合并，进行一次性全局终评，选出最终Top N本推荐书目。

#### 2.3.3 技术实现

**执行入口**：`run_adaptive_final()`（controller.py:596）

**核心执行**：
- `executor.final(books, top_n)` - 直接终评/决赛（executor.py:171）
- `executor.semifinal(books, quota)` - 锦标赛海选（executor.py:259）

**提示词构建**：
- `build_final_prompt(books, top_n)` - 终评（prompt_builder.py:23）
- `build_semifinal_prompt(books, quota)` - 半决赛（prompt_builder.py:60）

**LLM任务配置**：
- `theme_final`（llm.yaml:84-115）
- `theme_semifinal`（llm.yaml:156-179）

**输出字段**：`终评结果`、`终评分数`、`终评理由`、`终评淘汰原因`、`终评淘汰说明`

#### 2.3.4 动态批次调整

系统实现了动态批次调整机制以应对大规模候选书目场景：

- 当候选数>100本时，临时将批次上限提高至50本
- 当候选数>200本时，进一步提高至80本

这一设计确保了海选阶段的竞争不会过于激烈，避免因批次过小而产生"遗珠之憾"。

---

## 3. 配置参数说明

所有业务参数均支持通过配置文件动态调整，无需修改代码即可优化评选效果：

| 参数 | 位置 | 默认值 | 说明 |
|-----|------|-------|------|
| 初评批次大小 | tasks.theme_initial.parameters.max_batch_size | 20 | 控制单次LLM调用的书目数量 |
| 终评批次大小 | tasks.theme_final.parameters.max_batch_size | 30 | 触发锦标赛模式的阈值 |
| 终评目标数量 | tasks.theme_final.parameters.top_n | 20 | 最终推荐的Top N书目数量 |
| 主题决选配额 | tasks.theme_runoff.parameters.finalist_quota | 8 | 每个主题晋级终评的上限 |
| 推荐配额规则 | tasks.theme_initial.parameters.recommend_quota | 见上方 | 根据批次大小动态调整的初评配额 |

---

## 4. 数据流与状态变迁

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              数据状态变迁图                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  候选书目 ──→ 初评通过 ──→ 决选晋级 ──→ 终评通过 ──→ 推荐书单              │
│       │          │            │            │                               │
│       ↓          ↓            ↓            ↓                               │
│    初评未通过   决选未晋级   终评未通过                                      │
│                                                                             │
│  ────────────────────────────────────────────────────────────────────────  │
│  状态字段:                                                                   │
│  • 初评结果: "通过" / "未通过" / "ERROR:xxx"                                │
│  • 主题内决选结果: "晋级" / "未晋级" / "自动晋级" / "ERROR:xxx"            │
│  • 终评结果: "通过" / "未通过" / "ERROR:xxx"                                │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 5. 论文3.1小节修订建议

基于实际代码逻辑，论文3.1节中关于核心处理层的描述建议修订为：

> **核心处理层**是智能策展引擎的决策中枢，采用"规则筛选→价值评估→智能评选"的三阶段漏斗架构。该层首先通过借阅统计分析模块，计算图书的流通频次与读者覆盖率，依据预设的负向筛选规则完成初步降噪，生成高潜力的候选书目池。随后，系统调用外部服务接口获取图书的社会化评价数据，包括评分、标签及简介，以补充馆藏书目数据的维度缺失。在此基础上，引入基于大模型的智能评选模块。
>
> **三阶段评选架构**是该模块的核心创新：
> 1. **主题内初评（海选）**：按索书号首字母分组，每批≤20本，通过动态配额（2-6本）进行初步筛选，输出初评理由；
> 2. **主题内决选（晋级赛）**：控制各主题晋级上限（默认8本），智能触发机制在≤配额时自动晋级，>配额时调用LLM深度评估，确保主题均衡性；
> 3. **全局终评（决赛圈）**：采用自适应漏斗策略，候选数≤30本时直接终评，>30本时触发锦标赛模式，通过随机分批+全局决赛实现公平筛选。

---

## 6. 论文3.3小节大纲建议

### 6.1 拟人化评审流程

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                          三阶段评选流程图解                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    阶段1：主题内初评（海选）                          │   │
│  │  ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐      │   │
│  │  │ 主题T    │    │ 主题I    │    │ 主题O    │    │ ...      │      │   │
│  │  │ 20本/批  │    │ 18本/批  │    │ 15本/批  │    │          │      │   │
│  │  │ ↓选6本   │    │ ↓选5本   │    │ ↓选4本   │    │          │      │   │
│  │  │ 初评通过 │    │ 初评通过 │    │ 初评通过 │    │          │      │   │
│  │  └──────────┘    └──────────┘    └──────────┘    └──────────┘      │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                         │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    阶段2：主题内决选（晋级赛）                          │   │
│  │                                                                      │   │
│  │   主题T: 15本 → 决选 → 晋级8本   （自动晋级: 8本≤配额）               │   │
│  │   主题I: 25本 → 决选 → 晋级8本   （LLM决选: 25本>配额）               │   │
│  │   主题O: 6本  → 自动晋级 → 晋级6本 （≤配额直接晋级）                  │   │
│  │                                                                      │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                    ↓                                         │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                    阶段3：全局终评（决赛圈）                          │   │
│  │                                                                      │   │
│  │   场景A: 候选25本 ≤30本                                               │   │
│  │   ┌──────────────────────────────────────────────┐                  │   │
│  │   │ 直接终评 → Top 20本推荐书单                  │                  │   │
│  │   └──────────────────────────────────────────────┘                  │   │
│  │                                                                      │   │
│  │   场景B: 候选80本 >30本                                               │   │
│  │   ┌──────────────────────────────────────────────────────────────┐  │   │
│  │   │ 海选(分3批) → 每批晋级10本 → 30本幸存者                        │  │   │
│  │   │        ↓                                                        │  │   │
│  │   │ 决赛(一次性) → Top 20本推荐书单                                 │  │   │
│  │   └──────────────────────────────────────────────────────────────┘  │   │
│  │                                                                      │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 6.2 价值对齐策略

Prompt设计采用多维度价值引导策略，确保LLM理解"思想性"与"启发性"的评选标准：

**初评Prompt核心指令**：
```
"请从思想深度、启发价值、知识贡献等维度评估书目的推荐价值，
优先选择那些能够拓展读者认知边界、具有独特观点的书籍。"
```

**决选Prompt强调维度**：
```
"请综合考虑候选书籍的深度、影响力、可读性和独特性，
重点关注其在所属主题领域的代表性和推荐优先级。"
```

**终评Prompt全局视角**：
```
"请从全局推荐价值角度进行最终筛选，
考虑书籍之间的互补性、主题覆盖的完整性以及整体书单的质量上限。"
```

**关键设计原则**：
1. **维度显式化**：在Prompt中明确列出评选维度，避免LLM仅依赖"知名度"等表层特征
2. **理由强制输出**：要求LLM为每个决策提供具体理由，便于后续分析和人工复核
3. **上下文传递**：各阶段评审理由逐级传递，确保评审决策的连贯性和可追溯性

---

## 7. 附录：代码文件索引

| 文件路径 | 功能说明 |
|---------|---------|
| `src/core/recommendation/controller.py` | 评选流程控制器，实现三阶段 orchestration |
| `src/core/recommendation/executor.py` | LLM执行器，封装各阶段调用逻辑 |
| `src/core/recommendation/prompt_builder.py` | 提示词构建器，动态生成各阶段Prompt |
| `src/core/recommendation/config.py` | 配置加载器，读取业务参数 |
| `src/core/recommendation/excel_writer.py` | Excel结果写入器，管理状态字段 |
| `config/llm.yaml` | LLM任务配置，包括温度、重试等参数 |

---

> 文档生成时间：2025-12-23  
> 基于代码版本：三阶段优化完成后的稳定版本