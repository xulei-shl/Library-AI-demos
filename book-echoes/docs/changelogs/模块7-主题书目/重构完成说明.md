# 模块7重构完成说明

## 重构概述

已按照 `重构方案-三阶段解耦.md` 完成模块7的代码重构，实现了三阶段解耦架构。

## 完成的工作

### 1. 创建全文提取器模块

**目录结构:**
```
src/core/subject_bibliography/content_extractors/
├── __init__.py          # 模块初始化，注册所有提取器
├── base.py              # 抽象基类 BaseContentExtractor
├── factory.py           # 提取器工厂类 ExtractorFactory
├── pengpai.py           # 澎湃思想市场提取器 (已实现)
├── bigthink.py          # Big Think提取器 (占位实现)
└── wikipedia.py         # Wikipedia提取器 (占位实现)
```

**已实现的提取器:**
- ✅ **PengpaiExtractor**: 从HTML content中提取纯文本，使用BeautifulSoup清理标签
- ⏳ **BigThinkExtractor**: 占位实现，待后续补充无头浏览器爬取逻辑
- ⏳ **WikipediaExtractor**: 占位实现，待后续补充URL提取和爬取逻辑

### 2. 重构核心模块

#### 2.1 RSS抓取器 (`rss_fetcher.py`)
- 添加 `fetch_date` 字段，记录抓取时间

#### 2.2 存储管理器 (`storage.py`)
- 完全重写，支持三阶段独立存储
- 新增方法:
  - `save_fetch_results()` - 保存阶段1结果
  - `save_extract_results()` - 保存阶段2结果
  - `save_analyze_results()` - 保存阶段3结果
  - `load_stage_data()` - 加载指定阶段数据
  - `find_latest_stage_file()` - 查找最新阶段文件

#### 2.3 流程控制器 (`pipeline.py`)
- 完全重写，支持三阶段独立运行
- 新增方法:
  - `run_stage_fetch()` - 运行阶段1: RSS获取
  - `run_stage_extract()` - 运行阶段2: 全文解析
  - `run_stage_analyze()` - 运行阶段3: LLM评估
  - `run_all_stages()` - 运行完整流程
- 支持命令行参数: `--stage fetch|extract|analyze|all`

### 3. 更新配置文件

**config/subject_bibliography.yaml:**
- 为每个RSS源添加 `extractor` 字段，指定提取器类型
- 新增 `extraction_settings` 配置段:
  - `timeout`: 爬取超时时间
  - `retry_times`: 失败重试次数
  - `browser_headless`: 无头浏览器模式

### 4. 更新主菜单

**main.py:**
- 重构 `run_module7()` 函数，添加子菜单:
  1. 阶段1: RSS获取
  2. 阶段2: 全文解析
  3. 阶段3: LLM评估
  4. 完整流程 (1→2→3)
  5. 返回主菜单

### 5. 更新依赖

**requirements.txt:**
- 添加 `feedparser>=6.0.0` 用于RSS解析

## 数据流转

### 文件命名规范
```
runtime/outputs/subject_bibliography/
├── YYYY-MM-DD_fetch.xlsx      # 阶段1输出
├── YYYY-MM-DD_extract.xlsx    # 阶段2输出
└── YYYY-MM-DD_analyze.xlsx    # 阶段3输出(最终结果)
```

### Excel列结构演进

**阶段1输出** (7列):
```
source | title | link | published_date | fetch_date | summary | content
```

**阶段2输出** (10列):
```
source | title | link | published_date | fetch_date | summary | content | 
full_text | extract_status | extract_error
```

**阶段3输出** (16列):
```
source | title | published_date | llm_score | llm_summary | llm_logic | 
llm_tags | llm_keywords | link | fetch_date | summary | extract_status | 
extract_error | content | full_text | llm_raw_response
```

## 使用方式

### 方式1: 通过主菜单
```bash
python main.py
# 选择 9. 模块7: 主题书目每日追踪
# 然后选择具体阶段
```

### 方式2: 命令行直接运行
```bash
# 运行单个阶段
python -m src.core.subject_bibliography.pipeline --stage fetch
python -m src.core.subject_bibliography.pipeline --stage extract
python -m src.core.subject_bibliography.pipeline --stage analyze

# 运行完整流程
python -m src.core.subject_bibliography.pipeline --stage all

# 指定输入文件
python -m src.core.subject_bibliography.pipeline --stage extract --input "path/to/fetch_result.xlsx"
```

## 后续扩展

### 添加新的提取器

只需要三步：

1. **创建提取器类** (继承 `BaseContentExtractor`):
```python
# src/core/subject_bibliography/content_extractors/my_extractor.py
from .base import BaseContentExtractor

class MyExtractor(BaseContentExtractor):
    def can_handle(self, source_name: str) -> bool:
        return "我的源" in source_name
    
    def extract(self, article):
        # 实现提取逻辑
        return {
            "full_text": "...",
            "extract_status": "success",
            "extract_error": ""
        }
```

2. **注册提取器**:
```python
# src/core/subject_bibliography/content_extractors/__init__.py
from .my_extractor import MyExtractor

ExtractorFactory.register(MyExtractor)
```

3. **更新配置**:
```yaml
# config/subject_bibliography.yaml
rss_feeds:
  - name: "我的源"
    url: "https://..."
    enabled: true
    extractor: "my_extractor"
```

无需修改其他任何代码！

## 测试验证

已创建测试脚本 `tests/test_module7_refactor.py`，验证:
- ✅ 提取器注册
- ✅ 提取器选择
- ✅ 澎湃提取器功能

运行测试:
```bash
python tests/test_module7_refactor.py
```

## 优势总结

### 开发效率
- ✅ 每个阶段可独立开发和测试
- ✅ 调试时只需运行特定阶段，节省时间
- ✅ 中间结果可视化，便于排查问题

### 可维护性
- ✅ 代码职责清晰，符合单一职责原则
- ✅ 新增RSS源只需实现对应提取器
- ✅ 提取器之间互不影响，降低耦合

### 灵活性
- ✅ 可以只运行部分阶段 (如只更新全文，不重新评估)
- ✅ 支持断点续传 (从中间阶段开始)
- ✅ 便于后续扩展 (如增加数据清洗阶段)

## 注意事项

1. **BigThink和Wikipedia提取器待实现**
   - 当前为占位实现，会跳过这些源的文章
   - 后续只需更新对应的 `.py` 文件即可
   - 无需修改其他代码

2. **依赖安装**
   - 确保安装了 `feedparser>=6.0.0`
   - 如需实现BigThink提取器，需安装 `playwright` 并运行 `playwright install chromium`

3. **配置检查**
   - 确保 `config/subject_bibliography.yaml` 中的RSS源URL有效
   - 确保 `config/llm.yaml` 中配置了 `subject_bibliography_analysis` 任务
