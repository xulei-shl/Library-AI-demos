## 一、核心矛盾的重新定位

### 你的真实问题不是"做氛围推荐"，而是：

> **如何让"纯文学"这类在传统检索系统中处于结构性劣势的馆藏，通过非功利性的发现机制进入读者视野？**

这与你的其他三个模块形成了完整的**反主流推荐矩阵**：

| 模块       | 对抗的主流逻辑 | 发现机制               | 面向馆藏类型       |
| ---------- | -------------- | ---------------------- | ------------------ |
| 月份牌     | 即时热度排序   | 时间周期性重现         | 跨学科             |
| 睡美人     | 流通率筛选     | 零借阅遗珠挖掘         | 跨学科（非纯文学） |
| 主题卡     | 孤立的学科分类 | 知识网络聚类           | 学术/专业类        |
| **文学FM** | **功利性检索** | **情境化非目的性浏览** | **纯文学**         |

### 重新定义的设计目标：

**不是做"歌单推荐"，而是为纯文学构建一个"数字化的书架漫步空间"。**

---

## 二、基于学术定位的功能重构

### 2.1 "情境锚点" (Contextual Anchors)

#### 3+1维度标签体系

| 维度                        | 定位                    | 标签数量 | 设计原则                       |
| --------------------------- | ----------------------- | -------- | ------------------------------ |
| **阅读情境** `context`      | 替代场景的物理触发器    | 6个      | 必须是"可被明确识别的生活状态" |
| **文本质感** `texture`      | 替代心绪+质感的阅读体感 | 5个      | 必须是"可被客观描述的文字风格" |
| **时空氛围** `atmosphere`   | 合并心绪+时空的沉浸感   | 7个      | 必须是"可被具象化的感官意象"   |
| **母题锚点** `theme_anchor` | 保留话题但降维          | 动态     | 从豆瓣标签中提取高频词         |

#### 具体标签设计（严格控制数量）

```python
CONTEXT_TAGS = [
    "通勤碎片",  # 单次阅读15-30分钟
    "深夜独处",  # 需要安静环境的沉浸式阅读
    "周末长读",  # 连续3小时以上的投入
    "旅途伴读",  # 适合移动场景的轻量级阅读
    "疗愈时刻",  # 情绪低谷时的陪伴性阅读
    "思维漫步"   # 适合做笔记的哲思性阅读
]

TEXTURE_TAGS = [
    "冷静克制",  # 海明威式/冷硬派
    "诗意绵密",  # 普鲁斯特式/意识流
    "明快利落",  # 毛姆式/古典叙事
    "实验先锋",  # 乔伊斯式/元小说
    "口语亲近"   # 塞林格式/第一人称
]

ATMOSPHERE_TAGS = [
    "雨声与书页",   # 具象化的感官场景
    "深夜的灯光",
    "旧物与回忆",
    "陌生的城市",
    "静止的时间",
    "边缘与孤岛",
    "破碎与重建"
]
```

**设计理由**：
1. **总标签数 < 20个**：避免长尾标签的"僵尸化"
2. **每个标签都有"画面感"**：便于前端可视化
3. **可组合性**：一本书最多打3个标签（跨维度组合）

---

### 2.2 "主题书架" (Thematic Shelves)

#### 新策展逻辑

```
1个核心主题 + 8-12本书 + 1段策展导语
```

**示例**：

#### 📚 **11月书架A："暮色四合时"**

**策展导语**：
> 当天色渐暗，城市的灯次第亮起，这些文字适合在暮色中展开。它们不急于给出答案，而是陪你在白昼与黑夜的交界处，与时间对视。

**选书逻辑**：

```sql
SELECT * FROM LiteratureFM_books
WHERE atmosphere LIKE '%深夜的灯光%'
  AND texture IN ('冷静克制', '诗意绵密')
  AND context IN ('深夜独处', '思维漫步')
  AND page_count BETWEEN 150 AND 350  -- 控制阅读时长
  AND douban_rating >= 7.8
ORDER BY 
  CASE WHEN circulation_count < 5 THEN 1 ELSE 0 END DESC,  -- 优先低流通
  douban_rating DESC
LIMIT 12;
```

**典型书目**（示例）：
- 《东京一年》（蒋方舟）
- 《漫长的告别》（雷蒙德·钱德勒）
- 《看不见的城市》（卡尔维诺）
- 《步履不停》（是枝裕和）

---

### 2.3 "季节性编排" (Seasonal Curation)

而是按**季节感**编排：

```
每月1个书架 × 12个月 = 年度12个主题书架
```

**分月主题示例**（仅供参考）：

| 月份 | 季节特征  | 主题方向   |
| ---- | --------- | ---------- |
| 1月  | 冬末/新年 | 告别与重启 |
| 4月  | 春日      | 成长与流动 |
| 7月  | 盛夏      | 热烈与疏离 |
| 10月 | 秋深      | 沉淀与回望 |

---

## 三、数据处理流程的重新设计

### 3.1 预处理阶段（你已完成）

```python
# 你的筛选逻辑（保持不变）
literary_pool = df[
    (df['cleaned_call_no'].str.startswith('I')) &
    (df['douban_summary'].str.len() >= 50) &
    # ... 你的其他筛选条件
]
```

---

### 3.2 LLM标签提取的优化方案

#### 问题诊断：
你原方案的Prompt会让LLM陷入"过度解读"：
- 输入：《活着》的豆瓣简介
- 输出：`mood=治愈`（因为简介强调"生命的韧性"）
- 实际：暴击型致郁

#### 解决方案：分级标注 + 人工校验

**Step 1：粗筛（用便宜模型）**

```python
# 使用 GPT-3.5 或 Claude Haiku
COARSE_PROMPT = """
角色：你是一个文学分类助手。

任务：判断这本书是否属于以下任一类型：
1. 纯文学小说（非类型小说、非网文、非鸡汤）
2. 严肃散文/随笔（非实用类、非旅游攻略）
3. 诗歌/戏剧

输入信息：
- 书名：{title}
- 豆瓣标签：{tags}
- 中图分类：{call_no}

输出格式：JSON
{
  "is_pure_literature": true/false,
  "genre": "小说/散文/诗歌/戏剧/其他",
  "confidence": 0.0-1.0
}

约束：
- 如果confidence < 0.7，输出 is_pure_literature: false
- 网络小说、悬疑推理、言情、玄幻一律判定为 false
"""
```

**Step 2：精筛（用好模型 + 思维链）**

```python
FINE_PROMPT = """
角色：资深文学编辑，擅长用"画面感"描述阅读体验。

任务：为这本纯文学作品打上3个标签（来自预设标签库）。

输入信息：
- 书名：{title}
- 作者：{author}
- 豆瓣简介：{summary}
- 作者简介：{author_intro}

预设标签库：
{TAGS_DICT}  # 之前设计的3维标签

思考步骤（必须输出）：
1. 这本书的核心叙事方式是什么？（第一人称/全知视角/意识流...）
2. 文字的节奏感如何？（快速推进/缓慢铺陈/跳跃式...）
3. 阅读时最突出的感官意象是什么？（颜色/声音/温度...）
4. 最适合在什么状态下阅读？（需要专注/可以碎片化/需要情绪准备...）

输出格式：JSON
{
  "thinking": "你的分析过程（50-100字）",
  "tags": {
    "context": "标签名",
    "texture": "标签名",
    "atmosphere": "标签名"
  },
  "one_liner": "一句话推荐（15字内）"
}

约束：
- 每个维度只能选1个标签
- 如果某个维度不明显，可以输出 null
- one_liner 必须有画面感，不要用"深刻""动人"等空洞形容词
```

**Step 3：人工校验（关键）**

```python
# 生成校验任务
def generate_validation_tasks(tagged_books, sample_size=100):
    """
    从LLM标注结果中随机抽样，生成人工校验任务
    """
    sample = tagged_books.sample(n=sample_size)
  
    for book in sample:
        print(f"""
        ========================================
        书名：{book['title']}
        LLM给出的标签：{book['tags']}
        LLM推荐语：{book['one_liner']}
      
        请校验：
        1. 标签是否准确？(Y/N)
        2. 如果不准确，请修改：______
        3. 推荐语是否有吸引力？(1-5分)
        ========================================
        """)
  
    # 统计修正率
    correction_rate = count_corrections / sample_size
  
    if correction_rate > 0.3:
        print("警告：LLM标注错误率过高，建议调整Prompt或改用人工众包")
  
    return validation_results
```

---

### 3.3 向量化策略的调整

**问题重述**：
标准Embedding模型（如OpenAI ada-002）捕捉的是"内容语义相似性"，而非"氛围相似性"。

**解决方案：标签文本化 + 混合Embedding**

```python
def generate_vibe_text(book_metadata):
    """
    将结构化标签转化为"氛围描述文本"
    """
    tags = book_metadata['tags']
    one_liner = book_metadata['one_liner']
  
    # 构造"氛围文本"
    vibe_text = f"""
    阅读情境：{tags['context']}
    文本质感：{tags['texture']}
    时空氛围：{tags['atmosphere']}
    推荐语：{one_liner}
    """
  
    return vibe_text

# 生成向量
book['vibe_embedding'] = get_embedding(generate_vibe_text(book))

# 相似度检索
def find_similar_vibes(target_book, k=10):
    target_vec = target_book['vibe_embedding']
  
    similarities = cosine_similarity(
        target_vec,
        all_books['vibe_embedding']
    )
  
    return all_books.nlargest(k, similarities)
```

**关键点**：
- 不要对原始简介做Embedding，而是对"标签+推荐语"做Embedding
- 这样向量空间就是"氛围语义空间"而非"内容语义空间"

---

## 四、数据库设计的最终方案

### 4.1 主表设计

```sql
CREATE TABLE LiteratureFM_books (
    id INT PRIMARY KEY AUTO_INCREMENT,
    book_id INT NOT NULL,  -- 外键关联主书目表
  
    -- LLM生成字段
    llm_thinking TEXT,  -- LLM的分析过程（用于调试/校验）
    one_liner VARCHAR(50),  -- 一句话推荐
  
    -- 向量字段
    vibe_embedding_id INT,  -- 关联向量表（如果你用专门的向量数据库）
  
    -- 质量控制
    human_validated BOOLEAN DEFAULT FALSE,  -- 是否经过人工校验
    validation_score TINYINT,  -- 校验得分（1-5）
  
    -- 元数据
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME ON UPDATE CURRENT_TIMESTAMP,
  
    FOREIGN KEY (book_id) REFERENCES books(id),
    INDEX idx_book_id (book_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### 4.2 标签关系表（关键）

```sql
CREATE TABLE LiteratureFM_tags (
    id INT PRIMARY KEY AUTO_INCREMENT,
    LiteratureFM_book_id INT NOT NULL,
    dimension ENUM('context', 'texture', 'atmosphere', 'theme_anchor'),
    tag_value VARCHAR(30) NOT NULL,
  
    -- 置信度（来自LLM或人工校验）
    confidence FLOAT DEFAULT 1.0,
  
    -- 来源标识
    source ENUM('llm', 'human', 'hybrid') DEFAULT 'llm',
  
    FOREIGN KEY (LiteratureFM_book_id) REFERENCES LiteratureFM_books(id) ON DELETE CASCADE,
  
    -- 联合索引（核心查询优化）
    INDEX idx_dimension_value (dimension, tag_value),
    INDEX idx_book_dimension (LiteratureFM_book_id, dimension)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### 4.3 书架表（策展核心）

```sql
CREATE TABLE thematic_shelves (
    id INT PRIMARY KEY AUTO_INCREMENT,
  
    -- 书架元数据
    title VARCHAR(100) NOT NULL,  -- 如"暮色四合时"
    subtitle VARCHAR(200),  -- 副标题/策展导语
    cover_image_url VARCHAR(255),
  
    -- 时间控制
    publish_month TINYINT,  -- 1-12（哪个月发布）
    display_order TINYINT,  -- 当月的第几个书架（1-4）
  
    -- 生成逻辑（保存以便复现）
    selection_rules JSON,  -- 存储SQL查询条件
  
    -- 状态控制
    status ENUM('draft', 'published', 'archived') DEFAULT 'draft',
  
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  
    -- 索引
    INDEX idx_month (publish_month, status),
    UNIQUE KEY unique_month_order (publish_month, display_order)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

### 4.4 书架-书籍关系表

```sql
CREATE TABLE shelf_items (
    id INT PRIMARY KEY AUTO_INCREMENT,
    shelf_id INT NOT NULL,
    book_id INT NOT NULL,  -- 直接关联主书目表（不是LiteratureFM_books）
  
    -- 排序与展示
    position TINYINT,  -- 在书架上的位置（1-12）
    custom_reason VARCHAR(200),  -- 人工添加时的个性化理由
  
    -- 添加方式
    add_method ENUM('auto', 'manual') DEFAULT 'auto',
    added_by INT,  -- 操作员ID（如果是人工添加）
  
    -- 统计数据（用于后续分析）
    view_count INT DEFAULT 0,
    click_count INT DEFAULT 0,
  
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  
    FOREIGN KEY (shelf_id) REFERENCES thematic_shelves(id) ON DELETE CASCADE,
    FOREIGN KEY (book_id) REFERENCES books(id),
  
    -- 索引
    UNIQUE KEY unique_shelf_book (shelf_id, book_id),
    INDEX idx_position (shelf_id, position)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
```

---

## 五、自动化策展算法

### 5.1 月度书架生成流程

```python
def generate_monthly_shelves(month: int, year: int):
    """
    为指定月份生成4个主题书架
  
    Args:
        month: 1-12
        year: 年份
  
    Returns:
        List of Shelf objects
    """
  
    # 1. 加载当月主题配置
    monthly_config = SHELF_THEMES[month]  # 预定义的主题配置
  
    shelves = []
    for i, theme in enumerate(monthly_config, start=1):
        shelf = create_shelf(
            title=theme['title'],
            subtitle=theme['subtitle'],
            selection_rules=theme['rules'],
            publish_month=month,
            display_order=i
        )
        shelves.append(shelf)
  
    return shelves

def create_shelf(title, subtitle, selection_rules, publish_month, display_order):
    """
    创建单个书架
    """
    # 1. 执行SQL查询
    candidate_books = execute_selection_query(selection_rules)
  
    # 2. 排序算法
    scored_books = rank_books(candidate_books, selection_rules)
  
    # 3. 多样性过滤（避免同一作者/同一主题过度集中）
    final_books = diversity_filter(scored_books, top_k=12)
  
    # 4. 创建书架记录
    shelf = ThematicShelf.create(
        title=title,
        subtitle=subtitle,
        publish_month=publish_month,
        display_order=display_order,
        selection_rules=selection_rules,
        status='draft'  # 等待人工审核
    )
  
    # 5. 添加书目到书架
    for position, book in enumerate(final_books, start=1):
        ShelfItem.create(
            shelf_id=shelf.id,
            book_id=book.id,
            position=position,
            add_method='auto'
        )
  
    return shelf

def rank_books(books, rules):
    """
    排序算法：平衡质量、发现性、多样性
    """
    for book in books:
        # 基础分：豆瓣评分归一化
        quality_score = (book.douban_rating - 7.0) / 3.0  # 7-10分映射到0-1
      
        # 发现性分数（反向流通率）
        discovery_score = 1 / (1 + np.log1p(book.circulation_count))
      
        # 标签匹配度
        match_score = calculate_tag_match(book, rules['required_tags'])
      
        # 加权总分
        book.final_score = (
            0.3 * quality_score +
            0.4 * discovery_score +
            0.3 * match_score
        )
  
    return sorted(books, key=lambda x: x.final_score, reverse=True)

def diversity_filter(books, top_k=12):
    """
    多样性过滤：确保书架内容不过度同质化
    """
    selected = []
    author_count = {}
  
    for book in books:
        # 规则1：同一作者最多2本
        if author_count.get(book.author, 0) >= 2:
            continue
      
        # 规则2：避免连续的相同出版年代
        if len(selected) >= 2:
            if book.publish_year == selected[-1].publish_year == selected[-2].publish_year:
                continue
      
        selected.append(book)
        author_count[book.author] = author_count.get(book.author, 0) + 1
      
        if len(selected) >= top_k:
            break
  
    return selected
```

---

### 5.2 主题配置示例

```python
SHELF_THEMES = {
    11: [  # 11月
        {
            'title': '暮色四合时',
            'subtitle': '当天色渐暗，城市的灯次第亮起，这些文字适合在暮色中展开。',
            'rules': {
                'required_tags': {
                    'atmosphere': ['深夜的灯光', '静止的时间'],
                    'texture': ['冷静克制', '诗意绵密'],
                    'context': ['深夜独处', '思维漫步']
                },
                'page_range': (150, 350),
                'rating_threshold': 7.8,
                'max_circulation': 10  # 只选流通量<10的
            }
        },
        {
            'title': '碎片的诗意',
            'subtitle': '在通勤的间隙，用15分钟打开一个微型世界。',
            'rules': {
                'required_tags': {
                    'context': ['通勤碎片'],
                    'texture': ['明快利落', '口语亲近']
                },
                'page_range': (80, 180),
                'rating_threshold': 7.5,
                'genre': ['短篇小说', '散文']
            }
        },
        # ... 另外2个书架
    ],
    # ... 其他月份
}
```

---

## 九、与其他模块的差异化总结

| 维度         | 月份牌               | 睡美人               | 主题卡           | **文学FM**         |
| ------------ | -------------------- | -------------------- | ---------------- | ------------------ |
| **推荐对象** | 跨学科               | 跨学科（排除纯文学） | 学术/专业类      | **纯文学**         |
| **发现逻辑** | 时间周期性           | 零借阅遗珠           | 知识聚类         | **情境化浏览**     |
| **用户心智** | "这个时候大家都在读" | "被遗忘的宝藏"       | "系统学习某主题" | **"此刻的我需要"** |
| **更新频率** | 月度                 | 月度                 | 月度             | **月度**           |
| **推荐数量** | ≈20本                | ≈15本                | ≈10本            | **5-8本/书架**     |
| **物理隐喻** | 日历                 | 尘封的箱子           | 知识地图         | **书架漫步**       |

**核心差异**：
其他模块是"推荐书"，文学FM是**"推荐一种阅读状态"**。