# 主题评分分析器逻辑说明

本文档位于 `src/core/douban/analytics`，旨在解释 `theme_rating_analyzer.py` 和 `dynamic_threshold_filter.py` 的协同工作逻辑。其核心目标是根据豆瓣评分和索书号分类，生成一份详尽的统计分析报告，并动态筛选出具备高分潜力的候选书目。

## 1. 数据准备

此步骤由 `DynamicThresholdFilter.prepare_dataset` 方法负责，是所有分析的基础。

- **入口**: 一个包含书籍信息的 Pandas `DataFrame`，必需列包括评分、索书号和评论人数。
- **处理流程**:
  1.  **数值转换**: `rating` (评分) 和 `rating_count` (评论人数) 列通过 `pd.to_numeric(..., errors="coerce")` 转换为数值类型。无法转换的值会变为 `NaN`。
  2.  **索书号处理**:
      - 首先，对索书号进行清洗，去除空值及 `nan`/`None` 等无效占位符。
      - 接着，通过正则表达式 `[A-Za-z]` 提取字符串中第一个英文字母作为该书的分类 (`call_letter`)。
      - 如果无法提取到字母，则归类于 `未知` (`UNKNOWN_CALL_VALUE`)。
  3.  **数据筛选**: 清洗后，会移除所有 `rating` 列为 `NaN` 的记录，确保所有参与分析的书籍都至少有一个有效的评分。
- **输出**: 一个只包含 `rating`、`call_letter`、`rating_count` 三列且数据纯净的工作 `DataFrame`。

## 2. 核心分析组件

分析过程主要包含三个部分：全局评分分段统计、按索书号分类的精细统计，以及动态阈值过滤分析。

### 2.1. 整体评分分布统计

此部分由 `ThemeRatingAnalyzer._build_bucket_statistics` 实现，用于宏观了解整体评分状况。

- **评分区间 (`RatingBucket`)**: 预设了 7 个固定的评分区间，用于对书籍进行分箱统计：
  - `<7.8`
  - `7.8-8.2`
  - `8.2-8.5`
  - `8.5-8.8`
  - `8.8-9.0`
  - `9.0-9.3`
  - `>=9.3`
- **统计指标**: 对每个区间，脚本会计算：
  - **数量与占比**: 该区间内的书籍数量及其占总样本的百分比。
  - **评论人数统计**: 对区间内书籍的 `rating_count` 进行统计，计算其**平均值、中位数、最小值和最大值**。
  - **索书号分布**: 分析该区间内书籍的索书号首字母分布情况，例如 `I类 50 (25.0%)`。

### 2.2. 按索书号分类统计

此部分由 `ThemeRatingAnalyzer._build_call_letter_statistics` 实现，提供更细粒度的分类洞察。

- **分组**: 数据按 `call_letter` (包括 `未知`) 进行分组。
- **分类统计**: 对每个索书号分类，脚本会计算：
  - **分类样本量与占比**: 该分类下的书籍总数及其占总样本的百分比。
  - **分类下评论人数**: 对该分类所有书籍的 `rating_count` 进行整体统计（平均值、中位数、最小值、最大值）。
  - **分类内评分分布**: 进一步分析该分类下的书籍在上述 7 个 `RatingBucket` 中的分布情况，包括每个分段的数量和组内占比。

### 2.3. 动态阈值过滤分析

这是筛选高质量候选书目的核心逻辑，由 `DynamicThresholdFilter.analyze` 方法实现。

- **目标**: 并非使用单一固定的高分标准，而是根据不同学科分类（索书号首字母）的特性，动态计算评分和评论数的门槛，以识别“值得关注”的书籍。
- **核心配置参数** (可在 `config/setting.yaml` 中调整):
  - `min_sample_size`: 用于区分“大样本”和“小样本”分类的阈值。
  - `review_lower_percentile` / `review_upper_percentile`: 定义评论人数的“黄金区间”。例如，40%至80%表示只考虑评论数位于这个范围内的书籍，以排除评论过少（评分不具代表性）和过多（可能已是众所周知的高分书）的情况。
  - `rating_percentile_large`: 对于“大样本”分类，使用其评分的某个高百分位（如75%）作为相对评分门槛。
  - `category_min_scores`: 为每个分类（如 `I`, `K`, `T` 等）设置一个保底最低分，确保即使相对门槛较低，也不会低于该基础标准。
- **筛选逻辑**:
  1.  **确定评论数范围**: 对每个分类，根据其 `rating_count` 的分布和配置的百分位，计算出评论数的有效上下界。
  2.  **确定评分门槛 (`score_threshold`)**:
      - **小样本** (数量 < `min_sample_size`): 直接使用 `category_min_scores` 中定义的保底分。
      - **大样本**: 评分门槛为 `max(保底分, 相对评分门槛)`，其中相对评分门槛是该分类下评分的 `rating_percentile_large` 分位数。
  3.  **应用列值验证规则** (可选,通过 `column_filters` 配置):
      - 如果启用了列值验证,会对每条候选记录检查指定列的值是否满足要求。
      - 支持两种验证类型:
        - `not_empty`: 检查列值是否非空(排除 `None`、`NaN` 和空字符串)。
        - `regex`: 使用正则表达式匹配列值。
      - 只有通过所有启用的列值验证规则的记录才会被保留。
  4.  **筛选候选书目**: 同时满足以下所有条件的书籍，其索引被加入“候选池”：
      - `rating_count` 位于计算出的“黄金区间”内。
      - `rating` 高于或等于为该分类计算出的动态 `score_threshold`。
      - 通过所有启用的列值验证规则(如果配置了 `column_filters`)。

## 3. 报告生成

分析完成后，`ThemeRatingAnalyzer._write_report` 方法会生成一份 Markdown 格式的综合报告。

- **文件名**: `{源文件名}_评分分段统计_{时间戳}.md`，保存在 `runtime/outputs` 目录下。
- **报告结构**:
  1.  **总体概览**: 显示数据来源、统计时间和总样本数。
  2.  **分段详情**: 一个表格，展示“整体评分分布统计”的结果，每行对应一个 `RatingBucket`。
  3.  **动态过滤阈值参考**:
      - 首先解释动态阈值的生成规则。
      - 然后用一个表格展示每个索书号分类的分析结果，包括：样本数、样本类型（大/小）、评论数区间的具体值、最终的评分门槛、以及筛选出的候选书目数量和占比。
  4.  **索书号首字母分类**:
      - 为每个索书号分类创建一个独立章节。
      - 每个章节包含该分类的总体统计数据，以及一个详细表格，展示其内部在各个评分区间的分布情况。

## 4. 配置与扩展

- **参数配置**: `dynamic_threshold_filter` 的所有关键参数均可在 `config/setting.yaml` 文件的 `douban.analytics.theme_rating` 路径下进行修改，无需改动代码。
- **逻辑扩展**:
  - **调整评分区间**: 直接修改 `ThemeRatingAnalyzer.BUCKETS` 的定义即可。
  - **增加统计维度**: 可在 `_summarize_bucket` 等方法中添加新的统计逻辑，并相应地更新 `_write_report` 中的报告格式字符串，即可将新维度展示在报告中。