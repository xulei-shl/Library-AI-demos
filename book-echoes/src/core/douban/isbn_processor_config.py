#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ISBNå¤„ç†å™¨é…ç½®ä¼˜åŒ–

æä¾›ä¸åŒåœºæ™¯ä¸‹çš„æœ€ä¼˜é…ç½®å‚æ•°
æ”¯æŒæ™ºèƒ½å¼•ç”¨æ•´åˆï¼Œä¸config/setting.yamlé›†æˆ
"""

from typing import Dict, Any, Optional
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)


@dataclass
class ProcessingConfig:
    """å¤„ç†é…ç½®"""
    name: str
    description: str
    max_concurrent: int
    batch_size: int
    min_delay: float
    max_delay: float
    retry_times: int
    timeout: int
    browser_startup_timeout: int  # æµè§ˆå™¨å¯åŠ¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    page_navigation_timeout: int  # é¡µé¢å¯¼èˆªè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    use_case: str
    performance_estimate: str


# é¢„å®šä¹‰é…ç½®æ–¹æ¡ˆ
PROCESSING_CONFIGS = {
    "conservative": ProcessingConfig(
        name="ä¿å®ˆé…ç½®",
        description="æœ€ç¨³å®šçš„é…ç½®ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ",
        max_concurrent=3,
        batch_size=30,
        min_delay=1.0,
        max_delay=3.0,
        retry_times=3,
        timeout=20,
        browser_startup_timeout=180,  # æµè§ˆå™¨å¯åŠ¨è¶…æ—¶3åˆ†é’Ÿ
        page_navigation_timeout=180,  # é¡µé¢å¯¼èˆªè¶…æ—¶3åˆ†é’Ÿ
        use_case="ç”Ÿäº§ç¯å¢ƒï¼Œç¨³å®šçš„ç½‘ç»œç¯å¢ƒ",
        performance_estimate="3-5å€æé€Ÿï¼Œ1ä¸‡æ¡éœ€è¦6-10å°æ—¶"
    ),

    "balanced": ProcessingConfig(
        name="å¹³è¡¡é…ç½®",
        description="æ€§èƒ½å’Œç¨³å®šæ€§å¹³è¡¡ï¼Œæ¨èé»˜è®¤é€‰æ‹©",
        max_concurrent=5,
        batch_size=50,
        min_delay=0.5,
        max_delay=2.0,
        retry_times=3,
        timeout=15,
        browser_startup_timeout=180,  # æµè§ˆå™¨å¯åŠ¨è¶…æ—¶3åˆ†é’Ÿ
        page_navigation_timeout=180,  # é¡µé¢å¯¼èˆªè¶…æ—¶3åˆ†é’Ÿ
        use_case="ä¸€èˆ¬ç”Ÿäº§ç¯å¢ƒï¼Œè‰¯å¥½çš„ç½‘ç»œæ¡ä»¶",
        performance_estimate="5-8å€æé€Ÿï¼Œ1ä¸‡æ¡éœ€è¦3-6å°æ—¶"
    ),

    "aggressive": ProcessingConfig(
        name="æ¿€è¿›é…ç½®",
        description="è¿½æ±‚æœ€é«˜æ€§èƒ½ï¼Œé€‚åˆæµ‹è¯•ç¯å¢ƒ",
        max_concurrent=8,
        batch_size=100,
        min_delay=0.3,
        max_delay=1.5,
        retry_times=2,
        timeout=12,
        browser_startup_timeout=180,  # æµè§ˆå™¨å¯åŠ¨è¶…æ—¶3åˆ†é’Ÿ
        page_navigation_timeout=180,  # é¡µé¢å¯¼èˆªè¶…æ—¶3åˆ†é’Ÿ
        use_case="æµ‹è¯•ç¯å¢ƒæˆ–é«˜é€Ÿç½‘ç»œ",
        performance_estimate="8-12å€æé€Ÿï¼Œ1ä¸‡æ¡éœ€è¦2-4å°æ—¶"
    ),

    "emergency": ProcessingConfig(
        name="ç´§æ€¥é…ç½®",
        description="æœ€ä½å»¶è¿Ÿï¼Œé€‚åˆæ€¥éœ€å¤„ç†çš„å°‘é‡æ•°æ®",
        max_concurrent=10,
        batch_size=200,
        min_delay=0.1,
        max_delay=0.8,
        retry_times=1,
        timeout=10,
        browser_startup_timeout=180,  # æµè§ˆå™¨å¯åŠ¨è¶…æ—¶3åˆ†é’Ÿ
        page_navigation_timeout=180,  # é¡µé¢å¯¼èˆªè¶…æ—¶3åˆ†é’Ÿ
        use_case="å°‘é‡æ•°æ®ç´§æ€¥å¤„ç†",
        performance_estimate="10-15å€æé€Ÿï¼Œä½†æˆåŠŸç‡å¯èƒ½é™ä½"
    )
}


def load_config_from_yaml(config_dict: Dict[str, Any]) -> Optional[ProcessingConfig]:
    """
    ä»é…ç½®å­—å…¸åŠ è½½ISBNå¤„ç†å™¨é…ç½®ï¼ˆæ™ºèƒ½å¼•ç”¨æ•´åˆæ”¯æŒï¼‰

    Args:
        config_dict: é…ç½®å­—å…¸ï¼ŒåŒ…å«isbn_processoré…ç½®

    Returns:
        ProcessingConfig: å¤„ç†é…ç½®å¯¹è±¡ï¼Œå¦‚æœé…ç½®æ— æ•ˆåˆ™è¿”å›None
    """
    if not config_dict:
        logger.warning("é…ç½®å­—å…¸ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å¹³è¡¡é…ç½®")
        return get_config("balanced")

    strategy = config_dict.get('strategy', 'auto')

    try:
        if strategy == 'custom':
            custom_params = config_dict.get('custom', {})
            return create_custom_config(**custom_params)
        elif strategy == 'auto':
            # autoæ¨¡å¼éœ€è¦å¤–éƒ¨æ•°æ®é‡ä¿¡æ¯ï¼Œè¿™é‡Œè¿”å›é»˜è®¤é…ç½®
            logger.info("autoæ¨¡å¼éœ€è¦å¤–éƒ¨æ•°æ®é‡ä¿¡æ¯ï¼Œè¿”å›é»˜è®¤å¹³è¡¡é…ç½®")
            return get_config("balanced")
        else:
            logger.warning(f"æœªçŸ¥é…ç½®ç­–ç•¥: {strategy}ï¼Œä½¿ç”¨é»˜è®¤å¹³è¡¡é…ç½®")
            return get_config("balanced")
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å¹³è¡¡é…ç½®")
        return get_config("balanced")


def get_config_strategy_info() -> Dict[str, str]:
    """
    è·å–é…ç½®ç­–ç•¥è¯´æ˜ä¿¡æ¯

    Returns:
        Dict: ç­–ç•¥è¯´æ˜å­—å…¸
    """
    return {
        "custom": "ä½¿ç”¨è‡ªå®šä¹‰é…ç½® (ç”¨æˆ·åœ¨config/setting.yamlä¸­å®šä¹‰)",
        "auto": "æ ¹æ®æ•°æ®é‡è‡ªåŠ¨é€‰æ‹©é…ç½® (éœ€è¦å¤–éƒ¨æä¾›æ•°æ®é‡ä¿¡æ¯)"
    }


def validate_config_from_dict(config_dict: Dict[str, Any]) -> tuple[bool, list[str]]:
    """
    éªŒè¯é…ç½®å­—å…¸çš„æœ‰æ•ˆæ€§

    Args:
        config_dict: é…ç½®å­—å…¸

    Returns:
        tuple: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
    """
    errors = []

    if not isinstance(config_dict, dict):
        errors.append("é…ç½®å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
        return False, errors

    strategy = config_dict.get('strategy', 'auto')

    if strategy not in ['custom', 'auto']:
        errors.append(f"æœªçŸ¥ç­–ç•¥: {strategy}ï¼Œå¿…é¡»æ˜¯ custom/auto ä¹‹ä¸€")

    if strategy == 'custom':
        custom = config_dict.get('custom', {})
        if not isinstance(custom, dict):
            errors.append("customé…ç½®å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
        else:
            # éªŒè¯è‡ªå®šä¹‰å‚æ•°
            if 'max_concurrent' in custom:
                if not (1 <= custom['max_concurrent'] <= 20):
                    errors.append("max_concurrentåº”åœ¨1-20ä¹‹é—´")
            if 'batch_size' in custom:
                if not (10 <= custom['batch_size'] <= 500):
                    errors.append("batch_sizeåº”åœ¨10-500ä¹‹é—´")

    return len(errors) == 0, errors


def merge_configs(base_config: ProcessingConfig, override_config: Dict[str, Any]) -> ProcessingConfig:
    """
    åˆå¹¶é…ç½®ï¼Œç”¨override_configä¸­çš„å€¼è¦†ç›–base_configçš„å¯¹åº”å€¼

    Args:
        base_config: åŸºç¡€é…ç½®
        override_config: è¦†ç›–é…ç½®å­—å…¸

    Returns:
        ProcessingConfig: åˆå¹¶åçš„é…ç½®
    """
    if not override_config:
        return base_config

    # åˆ›å»ºæ–°é…ç½®å¯¹è±¡
    new_config = ProcessingConfig(
        name=override_config.get('name', base_config.name),
        description=override_config.get('description', base_config.description),
        max_concurrent=override_config.get('max_concurrent', base_config.max_concurrent),
        batch_size=override_config.get('batch_size', base_config.batch_size),
        min_delay=override_config.get('min_delay', base_config.min_delay),
        max_delay=override_config.get('max_delay', base_config.max_delay),
        retry_times=override_config.get('retry_times', base_config.retry_times),
        timeout=override_config.get('timeout', base_config.timeout),
        browser_startup_timeout=override_config.get('browser_startup_timeout', base_config.browser_startup_timeout),
        page_navigation_timeout=override_config.get('page_navigation_timeout', base_config.page_navigation_timeout),
        use_case=override_config.get('use_case', base_config.use_case),
        performance_estimate=override_config.get('performance_estimate', base_config.performance_estimate)
    )

    return new_config


def get_config(config_name: str = "balanced") -> ProcessingConfig:
    """
    è·å–å¤„ç†é…ç½®
    
    Args:
        config_name: é…ç½®åç§° (conservative, balanced, aggressive, emergency)
    
    Returns:
        ProcessingConfig: å¤„ç†é…ç½®å¯¹è±¡
    """
    if config_name not in PROCESSING_CONFIGS:
        raise ValueError(f"æœªçŸ¥é…ç½®: {config_name}ï¼Œå¯ç”¨é…ç½®: {list(PROCESSING_CONFIGS.keys())}")
    
    return PROCESSING_CONFIGS[config_name]


def get_config_for_data_size(data_size: int, log_selection: bool = True) -> ProcessingConfig:
    """
    æ ¹æ®æ•°æ®é‡æ¨èé…ç½®
    
    Args:
        data_size: æ•°æ®æ¡æ•°
        log_selection: æ˜¯å¦è®°å½•é€‰æ‹©æ—¥å¿—
    
    Returns:
        ProcessingConfig: æ¨èçš„é…ç½®
    """
    if data_size <= 100:
        config = PROCESSING_CONFIGS["emergency"]
        reason = "å°‘é‡æ•°æ®ï¼Œä½¿ç”¨ç´§æ€¥é…ç½®è¿½æ±‚æœ€é«˜é€Ÿåº¦"
    elif data_size <= 1000:
        config = PROCESSING_CONFIGS["aggressive"]
        reason = "ä¸­ç­‰æ•°æ®é‡ï¼Œä½¿ç”¨æ¿€è¿›é…ç½®è¿½æ±‚é«˜æ€§èƒ½"
    elif data_size <= 10000:
        config = PROCESSING_CONFIGS["balanced"]
        reason = "è¾ƒå¤§æ•°æ®é‡ï¼Œä½¿ç”¨å¹³è¡¡é…ç½®å…¼é¡¾æ€§èƒ½å’Œç¨³å®šæ€§"
    else:
        config = PROCESSING_CONFIGS["conservative"]
        reason = "å¤§é‡æ•°æ®ï¼Œä½¿ç”¨ä¿å®ˆé…ç½®ç¡®ä¿ç¨³å®šæ€§"
    
    if log_selection:
        logger.info(f"æ•°æ®é‡: {data_size} æ¡ -> é€‰æ‹©é…ç½®: {config.name} ({reason})")
    
    return config


def create_custom_config(max_concurrent: int = 5,
                        batch_size: int = 50,
                        min_delay: float = 0.5,
                        max_delay: float = 2.0,
                        retry_times: int = 3,
                        timeout: int = 15,
                        browser_startup_timeout: int = 180,
                        page_navigation_timeout: int = 180) -> ProcessingConfig:
    """
    åˆ›å»ºè‡ªå®šä¹‰é…ç½®

    Args:
        max_concurrent: æœ€å¤§å¹¶å‘æ•°
        batch_size: æ‰¹å¤„ç†å¤§å°
        min_delay: æœ€å°å»¶è¿Ÿ
        max_delay: æœ€å¤§å»¶è¿Ÿ
        retry_times: é‡è¯•æ¬¡æ•°
        timeout: è¶…æ—¶æ—¶é—´
        browser_startup_timeout: æµè§ˆå™¨å¯åŠ¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        page_navigation_timeout: é¡µé¢å¯¼èˆªè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        ProcessingConfig: è‡ªå®šä¹‰é…ç½®
    """
    return ProcessingConfig(
        name="è‡ªå®šä¹‰é…ç½®",
        description="ç”¨æˆ·è‡ªå®šä¹‰é…ç½®",
        max_concurrent=max_concurrent,
        batch_size=batch_size,
        min_delay=min_delay,
        max_delay=max_delay,
        retry_times=retry_times,
        timeout=timeout,
        browser_startup_timeout=browser_startup_timeout,
        page_navigation_timeout=page_navigation_timeout,
        use_case="ç”¨æˆ·è‡ªå®šä¹‰",
        performance_estimate="æ ¹æ®å‚æ•°è®¡ç®—"
    )


def validate_config(config: ProcessingConfig) -> tuple[bool, list[str]]:
    """
    éªŒè¯é…ç½®å‚æ•°

    Args:
        config: é…ç½®å¯¹è±¡

    Returns:
        tuple: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
    """
    errors = []

    # éªŒè¯å¹¶å‘æ•°
    if not (1 <= config.max_concurrent <= 20):
        errors.append("æœ€å¤§å¹¶å‘æ•°åº”åœ¨1-20ä¹‹é—´")

    # éªŒè¯æ‰¹å¤§å°
    if not (10 <= config.batch_size <= 500):
        errors.append("æ‰¹å¤„ç†å¤§å°åº”åœ¨10-500ä¹‹é—´")

    # éªŒè¯å»¶è¿Ÿæ—¶é—´
    if not (0.1 <= config.min_delay <= 10):
        errors.append("æœ€å°å»¶è¿Ÿåº”åœ¨0.1-10ç§’ä¹‹é—´")
    if not (0.2 <= config.max_delay <= 20):
        errors.append("æœ€å¤§å»¶è¿Ÿåº”åœ¨0.2-20ç§’ä¹‹é—´")
    if config.min_delay >= config.max_delay:
        errors.append("æœ€å°å»¶è¿Ÿåº”å°äºæœ€å¤§å»¶è¿Ÿ")

    # éªŒè¯é‡è¯•æ¬¡æ•°
    if not (1 <= config.retry_times <= 10):
        errors.append("é‡è¯•æ¬¡æ•°åº”åœ¨1-10æ¬¡ä¹‹é—´")

    # éªŒè¯è¶…æ—¶æ—¶é—´
    if not (5 <= config.timeout <= 60):
        errors.append("è¶…æ—¶æ—¶é—´åº”åœ¨5-60ç§’ä¹‹é—´")

    # éªŒè¯æµè§ˆå™¨å¯åŠ¨è¶…æ—¶æ—¶é—´
    if not (30 <= config.browser_startup_timeout <= 600):
        errors.append("æµè§ˆå™¨å¯åŠ¨è¶…æ—¶æ—¶é—´åº”åœ¨30-600ç§’ä¹‹é—´ï¼ˆ0.5-10åˆ†é’Ÿï¼‰")

    # éªŒè¯é¡µé¢å¯¼èˆªè¶…æ—¶æ—¶é—´
    if not (30 <= config.page_navigation_timeout <= 600):
        errors.append("é¡µé¢å¯¼èˆªè¶…æ—¶æ—¶é—´åº”åœ¨30-600ç§’ä¹‹é—´ï¼ˆ0.5-10åˆ†é’Ÿï¼‰")

    return len(errors) == 0, errors


def print_config_comparison():
    """æ‰“å°é…ç½®å¯¹æ¯”è¡¨"""
    print("ğŸ“‹ ISBNå¤„ç†å™¨é…ç½®å¯¹æ¯”")
    print("=" * 80)
    print(f"{'é…ç½®åç§°':<12} | {'å¹¶å‘æ•°':<6} | {'æ‰¹å¤§å°':<6} | {'å»¶è¿ŸèŒƒå›´':<12} | {'é¢„ä¼°æ€§èƒ½':<15}")
    print("-" * 80)
    
    for config in PROCESSING_CONFIGS.values():
        delay_range = f"{config.min_delay:.1f}-{config.max_delay:.1f}s"
        print(f"{config.name:<12} | {config.max_concurrent:<6} | {config.batch_size:<6} | {delay_range:<12} | {config.performance_estimate:<15}")
    
    print("-" * 80)
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("â€¢ ä¿å®ˆé…ç½®: é€‚åˆç½‘ç»œä¸ç¨³å®šæˆ–éœ€è¦é«˜æˆåŠŸç‡çš„åœºæ™¯")
    print("â€¢ å¹³è¡¡é…ç½®: æ¨èé»˜è®¤é€‰æ‹©ï¼Œæ€§èƒ½å’Œç¨³å®šæ€§å¹³è¡¡")
    print("â€¢ æ¿€è¿›é…ç½®: é€‚åˆæµ‹è¯•ç¯å¢ƒæˆ–é«˜é€Ÿç½‘ç»œ")
    print("â€¢ ç´§æ€¥é…ç½®: é€‚åˆå°‘é‡æ•°æ®ç´§æ€¥å¤„ç†")


def estimate_performance(config: ProcessingConfig, data_size: int) -> Dict[str, Any]:
    """
    ä¼°ç®—å¤„ç†æ€§èƒ½
    
    Args:
        config: é…ç½®å¯¹è±¡
        data_size: æ•°æ®æ¡æ•°
    
    Returns:
        Dict: æ€§èƒ½ä¼°ç®—ç»“æœ
    """
    # åŸºç¡€æ€§èƒ½ä¼°ç®—ï¼ˆåŸºäºåŸå§‹6.63ç§’/æ¡çš„åŸºå‡†ï¼‰
    base_time_per_item = 6.63
    
    # å¹¶å‘åŠ é€Ÿå› å­
    concurrency_factor = min(config.max_concurrent * 0.8, 8)  # å¹¶å‘æ•ˆæœé€’å‡
    
    # å»¶è¿Ÿä¼˜åŒ–å› å­
    delay_factor = (config.min_delay + config.max_delay) / 4  # å¹³å‡å»¶è¿Ÿ
    
    # è®¡ç®—ä¼˜åŒ–åçš„å•æ¡å¤„ç†æ—¶é—´
    optimized_time_per_item = base_time_per_item / concurrency_factor / (1 + delay_factor * 0.1)
    
    # æ€»å¤„ç†æ—¶é—´
    total_processing_time = data_size * optimized_time_per_item
    
    # æˆåŠŸç‡å’Œå¤±è´¥é‡è¯•å½±å“
    success_rate = 0.95  # å‡è®¾95%æˆåŠŸç‡
    retry_impact = 1 + (1 - success_rate) * config.retry_times * 0.3
    
    final_time = total_processing_time * retry_impact
    
    return {
        "data_size": data_size,
        "estimated_time_per_item": optimized_time_per_item,
        "total_time_seconds": final_time,
        "total_time_hours": final_time / 3600,
        "throughput_items_per_hour": data_size / (final_time / 3600),
        "speed_improvement": base_time_per_item / optimized_time_per_item,
        "estimated_success_rate": success_rate,
        "concurrent_bottleneck": config.max_concurrent >= 8
    }


if __name__ == "__main__":
    print("ISBNå¤„ç†å™¨é…ç½®ä¼˜åŒ–å·¥å…·")
    print("=" * 40)
    
    # æ˜¾ç¤ºé…ç½®å¯¹æ¯”
    print_config_comparison()
    
    print("\nğŸš€ æ€§èƒ½ä¼°ç®—ç¤ºä¾‹:")
    
    # ä¼°ç®—ä¸åŒæ•°æ®é‡çš„å¤„ç†æ—¶é—´
    for size in [100, 1000, 10000]:
        print(f"\nğŸ“Š æ•°æ®é‡: {size} æ¡")
        for config_name in ["balanced", "aggressive"]:
            config = get_config(config_name)
            estimate = estimate_performance(config, size)
            print(f"  {config.name}: {estimate['total_time_hours']:.1f}å°æ—¶ "
                  f"(æå‡{estimate['speed_improvement']:.1f}å€)")