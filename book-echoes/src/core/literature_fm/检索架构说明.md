# 文学情境推荐检索架构说明

> 最后更新：2025-12-31
> 模块：Module 8 - Phase 3 情境主题书架生成功能

---

## 一、整体架构

### 1.1 检索流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           输入：文学主题                                     │
│   theme_name, slogan, description, target_vibe                             │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 1: QueryTranslator - 查询意图转换                                     │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ 输出：                                                                │   │
│  │  • filter_conditions: 结构化过滤条件（SHOULD/MUST/MUST_NOT）          │   │
│  │  • search_keywords: BM25检索关键词                                   │   │
│  │  • synthetic_query: 向量检索的合成查询词                              │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
              ┌───────────────────────┼───────────────────────┐
              │                       │                       │
              ▼                       ▼                       ▼
┌─────────────────────┐   ┌─────────────────────┐   ┌─────────────────────┐
│  Step 2A: 向量检索   │   │  Step 2B: BM25检索  │   │  Step 2C: 去重检查  │
│  HybridVectorSearcher│   │  BM25Searcher       │   │  ThemeDeduplicator  │
│                     │   │                     │   │                     │
│ • synthetic_query   │   │ • search_keywords   │   │ • 历史相似主题      │
│ • filter_conditions │   │ • 随机性采样        │   │ • 排除已推荐书籍    │
│   (Pre/Post-filter) │   │   (randomness=0.15) │   │                     │
└─────────────────────┘   └─────────────────────┘   └─────────────────────┘
              │                       │                       │
              └───────────────────────┼───────────────────────┘
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 3: RRFFusion - 结果融合                                               │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ RRF算法：score(book_id) = Σ(1 / (k + rank_i))                         │   │
│  │ • k=60 (平滑常数)                                                    │   │
│  │ • 按排名融合，不依赖分数值                                            │   │
│  │ • 输出包含：rrf_score, sources, vector_rank, bm25_rank                │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 4: [可选] CrossEncoderReranker - 重排序                              │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ • 使用 Qwen/Qwen3-Reranker-8B 模型                                  │   │
│  │ • 对 query-doc 对进行精细打分                                        │   │
│  │ • 默认关闭（reranker.enabled=false）                                 │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│  Step 5: 最终处理                                                           │
│  • 取 TopK（默认30本）                                                     │
│  • 保存推荐历史到 literature_recommendation_history 表                    │
│  • ThemeExporter 导出 Excel                                               │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 二、核心组件详解

### 2.1 QueryTranslator（查询意图转换器）

**文件位置**：[query_translator.py](query_translator.py)

**功能**：将文学主题转换为结构化检索条件

**输入**：
- `theme_name`: 主题名称（如"大脑重启：格式化你的精神硬盘"）
- `slogan`: 副标题（如"当你的思绪乱成一团毛线时"）
- `description`: 情境描述（用户原始需求）
- `target_vibe`: 预期氛围

**输出**：
```json
{
  "filter_conditions": [
    {"field": "spatial_atmosphere", "values": ["荒野自然", "虚构奇境"], "operator": "SHOULD"},
    {"field": "emotional_tone", "values": ["平静淡然"], "operator": "SHOULD"},
    {"field": "spatial_atmosphere", "values": ["都市孤独"], "operator": "MUST_NOT"}
  ],
  "search_keywords": ["荒野", "星空", "海洋", "宇宙", "自然"],
  "synthetic_query": "这本书非常适合那些被信息过载压垮的读者...",
  "original_theme": {...}
}
```

**关键设计**：
- 使用 LLM（通过 UnifiedLLMClient）理解主题并生成检索条件
- 加载 `literary_tags_vocabulary.yaml` 词表作为上下文
- 验证输出格式的有效性（字段、操作符、关键词数量等）
- 失败时返回兜底结果（从描述中提取关键词）

---

### 2.2 HybridVectorSearcher（增强向量检索器）

**文件位置**：[hybrid_vector_searcher.py](hybrid_vector_searcher.py)

**功能**：向量语义检索 + 结构化过滤

**设计模式**：装饰器模式，包装基础 VectorSearcher

**核心逻辑**：

#### 2.2.1 过滤条件处理

| 操作符 | 含义 | 实现方式 |
|--------|------|----------|
| **MUST** | 必须匹配 | Pre-filter，使用 ChromaDB 的 `where` 参数 |
| **MUST_NOT** | 必须排除 | Post-filter，检索后过滤掉匹配的结果 |
| **SHOULD** | 优选匹配 | 多路检索合并：每个值独立检索，结果合并去重取最高分 |

#### 2.2.2 SHOULD 条件展开策略

```python
# 输入：SHOULD 条件
{"field": "reading_context", "values": ["A", "B"]}

# 展开为多路查询（笛卡尔积简化版）
[
    {"reading_context": "A"},
    {"reading_context": "B"}
]

# 每路独立检索，合并结果保留最高相似度
```

**关键代码位置**：[hybrid_vector_searcher.py:159-242](hybrid_vector_searcher.py#L159-L242)

---

### 2.3 VectorSearcher（基础向量检索器）

**文件位置**：[vector_searcher.py](vector_searcher.py)

**功能**：基于 ChromaDB 的语义检索

#### 2.3.1 向量生成策略

**字段加权**（构建索引文本时）：
```
高权重 (1.5x):
  - tags_json.reasoning (重复2次)
  - 各维度标签（reading_context, reading_load, text_texture, spatial_atmosphere, emotional_tone）

中权重 (1.0x):
  - douban_summary (截断500字)
  - 书名+副标题+作者

低权重 (0.5x):
  - douban_author_intro (截断200字)
  - douban_catalog (截断300字)
```

**代码位置**：[vector_searcher.py:286-390](vector_searcher.py#L286-L390)

#### 2.3.2 动态阈值机制

```python
# 计算 Top5 平均相似度
avg_similarity = mean(top_5_similarities)

# 动态阈值 = Top5平均 * 0.85，但不低于固定阈值的70%
actual_threshold = max(avg_similarity * 0.85, min_confidence * 0.7)
```

**优势**：根据查询质量自动调整，避免低质量查询返回过多噪声结果

**代码位置**：[vector_searcher.py:100-111](vector_searcher.py#L100-L111)

#### 2.3.3 查询扩展

```python
# 原始查询
"这本书暗示了辽阔的自然场景，适合想要抽离日常的读者"

# 自动扩展为多路查询
[
    "这本书暗示了辽阔的自然场景，适合想要抽离日常的读者",  # 原始
    "辽阔的自然场景，适合想要抽离日常的读者",            # 去连接词
    "辽阔的自然场景",                                    # 提取核心
    "适合想要抽离日常的读者"                            # 提取目标
]
```

**代码位置**：[vector_searcher.py:175-215](vector_searcher.py#L175-L215)

---

### 2.4 BM25Searcher（BM25全文检索器）

**文件位置**：[bm25_searcher.py](bm25_searcher.py)

**功能**：基于关键词的字面匹配检索

#### 2.4.1 索引构建

**字段权重**（在文档中重复次数）：
```python
field_weights = {
    "title": 2.0,      # 书名重复2次
    "author": 1.0,     # 作者重复1次
    "summary": 1.5     # 摘要重复1.5次
}
```

**懒加载模式**：首次调用 `search()` 时构建索引，避免初始化开销

#### 2.4.2 随机性检索（新增功能）

**配置参数**：
```yaml
# literature_fm_vector.yaml
bm25:
  randomness: 0.15   # 15% 结果来自随机采样
  score_threshold: null  # 自动推断阈值
```

**策略**：
```python
# 1. 自动推断分数阈值（取 top_k*3 的分数的50%）
score_threshold = scores[top_k*3] * 0.5

# 2. 分离主结果和随机候选池
main_count = top_k * 0.85    # 85% 高分结果
random_count = top_k * 0.15  # 15% 随机采样

# 3. 从低分候选池随机抽取
random_sample = random.sample(random_pool, random_count)
```

**代码位置**：[bm25_searcher.py:143-268](bm25_searcher.py#L143-L268)

**优势**：
- 不同主题即使使用相同关键词，随机部分也不会完全相同
- 增加推荐多样性，避免书单趋同

---

### 2.5 RRFFusion（RRF融合器）

**文件位置**：[rrf_fusion.py](rrf_fusion.py)

**功能**：使用 Reciprocal Rank Fusion 算法合并多路检索结果

#### 2.5.1 RRF 算法原理

```python
# 对于每本书，计算融合分数
rrf_score(book_id) = Σ(1 / (k + rank_i))

# 其中：
# - rank_i: 该书在第i路结果中的排名（从1开始）
# - k: 平滑常数，默认60
# - 如果某本书未在某路结果中，则贡献为0
```

**示例**：
```
书籍A：
  - 向量检索排名：第3位 → 贡献 = 1/(60+3) = 0.01587
  - BM25检索排名：第7位 → 贡献 = 1/(60+7) = 0.01493
  - RRF分数 = 0.01587 + 0.01493 = 0.03080

书籍B（仅向量检索有）：
  - 向量检索排名：第1位 → 贡献 = 1/(60+1) = 0.01639
  - BM25检索：未出现 → 贡献 = 0
  - RRF分数 = 0.01639
```

#### 2.5.2 RRF 的优势

1. **不需要归一化**：不同检索器的分数尺度不同，RRF只看排名
2. **对异常值鲁棒**：极端分数值不影响结果
3. **简单高效**：计算复杂度 O(n)

**代码位置**：[rrf_fusion.py:42-133](rrf_fusion.py#L42-L133)

---

### 2.6 CrossEncoderReranker（重排序器）

**文件位置**：[cross_encoder_reranker.py](cross_encoder_reranker.py)

**功能**：使用重排序模型对 Top 结果进行精细打分

**模型**：Qwen/Qwen3-Reranker-8B

**工作流程**：
```python
# 1. 构建文档文本（书名+作者+LLM推理+摘要）
docs = [build_doc_text(result) for result in results]

# 2. 调用 Reranker API（分批处理）
scores = call_reranker_api(query, docs, batch_size=32)

# 3. 添加分数并重新排序
for result, score in zip(results, scores):
    result["rerank_score"] = score

sorted_results = sorted(results, key=lambda x: x["rerank_score"], reverse=True)
```

**状态**：默认关闭（`reranker.enabled=false`）

**代码位置**：[cross_encoder_reranker.py:63-117](cross_encoder_reranker.py#L63-L117)

---

### 2.7 ThemeDeduplicator（去重器）

**文件位置**：[theme_deduplicator.py](theme_deduplicator.py)

**功能**：管理推荐历史，避免重复推荐

#### 2.7.1 去重策略

```python
# 1. 检查相似输入的历史推荐
similar_history = find_similar_inputs(user_input, threshold=0.8)

# 2. 检查相似条件的历史推荐
condition_history = find_similar_conditions(filter_conditions, threshold=0.8)

# 3. 排除已通过的书籍
excluded_ids = set()
for record in similar_history + condition_history:
    passed_ids = parse_book_ids(record["passed_book_ids"])
    excluded_ids.update(passed_ids)
```

#### 2.7.2 条件相似度计算

```python
# filter_conditions 格式：[{"field": "xxx", "values": [...], "operator": "MUST"}, ...]

# 按字段分组
grouped = {field: set(values) for cond in conditions}

# 计算匹配度
matches = sum(1 for field in all_fields if grouped1[field] & grouped2[field])
similarity = matches / len(all_fields)
```

**代码位置**：[theme_deduplicator.py:213-291](theme_deduplicator.py#L213-L291)

---

## 三、配置文件说明

### 3.1 literature_fm_vector.yaml

**文件位置**：`config/literature_fm_vector.yaml`

```yaml
# 数据库配置
database:
  path: "runtime/database/books_history.db"
  table: "literary_tags"

# 向量数据库配置
vector_db:
  type: "chromadb"
  persist_directory: "runtime/vector_db/literature_fm"
  collection_name: "literature_fm_contexts"
  distance_metric: "cosine"

# Embedding 模型配置
embedding:
  provider: "SiliconFlow"
  model: "Qwen/Qwen3-Embedding-8B"
  api_key: "env:ONEAPI_API_KEY"
  base_url: "http://47.103.50.106:3000/v1"
  dimensions: 4096

# BM25 检索配置
bm25:
  enabled: true
  k1: 1.5            # 词频饱和参数
  b: 0.75            # 长度归一化参数
  field_weights:     # 字段权重
    title: 2.0
    author: 1.0
    summary: 1.5
  randomness: 0.15   # 随机性因子（15%随机采样）
  score_threshold: null  # 自动推断阈值

# RRF 融合配置
rrf:
  k: 60              # 平滑常数

# 重排序配置
reranker:
  enabled: false     # 默认关闭
  model: "Qwen/Qwen3-Reranker-8B"
  top_k: 50
  batch_size: 32

# 检索策略默认值
default:
  use_vector: true
  use_bm25: true
  use_rrf: true
  min_confidence: 0.80
  vector_top_k: 50
  bm25_top_k: 50
  final_top_k: 30
```

---

## 四、关键设计决策

### 4.1 为什么使用 RRF 融合而非加权平均？

| 方案 | 优点 | 缺点 |
|------|------|------|
| **加权平均** | 实现简单 | 需要归一化分数，不同检索器分数尺度不同 |
| **RRF** | 无需归一化，对排名敏感，鲁棒性强 | 仅考虑排名，忽略分数差异 |

**选择 RRF 的原因**：
- 向量检索的相似度（0-1）和 BM25 分数（0-10+）尺度不同
- RRF 只看排名，避免分数归一化的复杂度
- 对异常值更鲁棒

---

### 4.2 为什么 BM25 需要随机性？

**问题**：
- 不同主题可能使用相同的关键词（如"星空"、"孤独"）
- BM25 只做字面匹配，容易导致书单趋同

**解决方案**：
- 85% 高分结果保证质量
- 15% 随机采样增加多样性
- 不同主题的随机部分大概率不同

---

### 4.3 为什么使用 SHOULD/MUST/MUST_NOT？

| 操作符 | 使用场景 | 示例 |
|--------|----------|------|
| **SHOULD** | 优选条件，不必全部满足 | 情境包含"深夜独处"或"雨天窗前"都可 |
| **MUST** | 必须满足的条件 | 必须"酣畅易读"（排除需要正襟危坐的） |
| **MUST_NOT** | 排除条件 | 排除"温暖治愈"（想要严肃文学的） |

**SHOULD 的多路检索策略**：
- 每个 SHOULD 值独立检索一次
- 合并结果保留最高分
- 避免漏掉仅满足部分条件的书籍

---

### 4.4 向量检索的动态阈值

**问题**：
- 固定阈值（如0.8）对高质量查询太宽松，对低质量查询太严格

**解决方案**：
```python
# 取 Top5 平均相似度
avg_top5 = mean(top_5_similarities)

# 动态阈值 = Top5平均 * 0.85
# 最低 = 固定阈值 * 0.7
actual_threshold = max(avg_top5 * 0.85, min_confidence * 0.7)
```

**效果**：
- 高质量查询（Top5平均0.90）：阈值 ≈ 0.77
- 低质量查询（Top5平均0.70）：阈值 ≈ 0.49

---

## 五、检索流程入口

### 5.1 LiteratureFMPipeline.generate_theme_shelf()

**文件位置**：[literature_fm_orchestrator.py:267-522](literature_fm_orchestrator.py#L267-L522)

**输入**：
```python
translated_queries = [
    {
        "filter_conditions": [...],
        "search_keywords": [...],
        "synthetic_query": "...",
        "original_theme": {...}
    }
]
```

**输出**：
```python
{
    "success": True,
    "themes": [...],
    "total_books": 100,
    "output_file": "runtime/outputs/theme_shelf/themes_20251230_xxx.xlsx"
}
```

**代码片段**：
```python
# 1. 初始化组件
vector_searcher = HybridVectorSearcher(base_vector_searcher)
bm25_searcher = BM25Searcher(...)
rrf_fusion = RRFFusion(k=60)
deduplicator = ThemeDeduplicator()

# 2. 处理每个主题
for query_item in translated_queries:
    # 2.1 去重检查
    excluded_ids = deduplicator.get_excluded_book_ids(...)

    # 2.2 并行双路召回
    vector_results = vector_searcher.search(...)
    bm25_results = bm25_searcher.search_with_randomness(...)

    # 2.3 RRF融合
    merged = rrf_fusion.merge(vector_results, bm25_results)

    # 2.4 [可选] 重排序
    if reranker:
        merged = reranker.rerank(...)

    # 2.5 保存推荐记录
    deduplicator.save_recommendation(...)

# 3. 导出结果
output_file = exporter.export_theme_batch(all_results)
```

---

## 六、数据流示例

### 6.1 单本书的检索结果

```json
{
  "book_id": 12345,
  "title": "边城",
  "author": "沈从文",
  "call_no": "I247.5/4023",
  "vector_score": 0.8567,
  "bm25_score": 3.4521,
  "rrf_score": 0.0312,
  "vector_rank": 5,
  "bm25_rank": 12,
  "sources": ["vector", "bm25"],
  "rerank_score": 0.9234,  // 如果启用重排序
  "tags_json": "{...}"
}
```

### 6.2 来源标识

| `source` 值 | 含义 |
|-------------|------|
| `vector` | 来自向量检索 |
| `bm25` | 来自BM25检索（高分） |
| `bm25_random` | 来自BM25随机采样（低分） |
| `["vector", "bm25"]` | 两路检索都有 |

---

## 七、扩展性设计

### 7.1 添加新的检索器

```python
# 1. 实现检索器接口
class NewSearcher:
    def search(self, query, top_k, **kwargs) -> List[Dict]:
        # 返回格式：
        return [
            {
                "book_id": 123,
                "new_score": 0.85,
                "source": "new"
            }
        ]

# 2. 在编排器中初始化
new_searcher = NewSearcher(...)

# 3. 修改 RRF 融合
merged = rrf_fusion.merge_multi(
    [vector_results, bm25_results, new_results],
    rank_keys=["vector_score", "bm25_score", "new_score"]
)
```

### 7.2 调整随机性参数

```yaml
# literature_fm_vector.yaml
bm25:
  randomness: 0.25    # 25% 随机（更激进）
  score_threshold: 1.5  # 固定阈值（不自动推断）
```

### 7.3 启用重排序

```yaml
reranker:
  enabled: true
  model: "Qwen/Qwen3-Reranker-8B"
  top_k: 50
  batch_size: 32
```

---

## 八、常见问题

### Q1: 为什么向量检索和 BM25 检索结果数量不同？

**A**:
- 向量检索：受 `min_confidence` 阈值过滤，低于阈值的结果被丢弃
- BM25检索：只排除零分结果，然后取 TopK
- 融合时按排名计算，两路结果数量可以不同

### Q2: 如何调试某本书的检索来源？

**A**: 查看输出结果中的：
- `sources`: 来自哪路检索
- `vector_rank`: 向量检索排名
- `bm25_rank`: BM25检索排名
- `rrf_score`: 融合后的分数

### Q3: 随机性会不会降低推荐质量？

**A**:
- 随机部分仅占 15%（可配置）
- 从低分候选池采样，仍有相关性
- 主结果（85%）保持高分质量
- 可通过降低 `randomness` 减少随机性

### Q4: 如何禁用某路检索？

**A**: 修改配置文件
```yaml
default:
  use_vector: false   # 禁用向量检索
  use_bm25: false     # 禁用BM25检索
```

---

## 九、文件索引

| 组件 | 文件路径 |
|------|----------|
| 编排器 | [literature_fm_orchestrator.py](literature_fm_orchestrator.py) |
| 查询转换 | [query_translator.py](query_translator.py) |
| 向量检索 | [vector_searcher.py](vector_searcher.py) |
| 增强向量检索 | [hybrid_vector_searcher.py](hybrid_vector_searcher.py) |
| BM25检索 | [bm25_searcher.py](bm25_searcher.py) |
| RRF融合 | [rrf_fusion.py](rrf_fusion.py) |
| 重排序 | [cross_encoder_reranker.py](cross_encoder_reranker.py) |
| 去重器 | [theme_deduplicator.py](theme_deduplicator.py) |
| 导出器 | [theme_exporter.py](theme_exporter.py) |
| 配置文件 | [config/literature_fm_vector.yaml](../../config/literature_fm_vector.yaml) |
| 标签词表 | [config/literary_tags_vocabulary.yaml](../../config/literary_tags_vocabulary.yaml) |
| LLM配置 | [config/llm.yaml](../../config/llm.yaml) |

---

*文档版本：v1.0*
*最后更新：2025-12-31*
