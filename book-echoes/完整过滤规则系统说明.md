# 图书推荐系统完整过滤规则系统说明

## 项目概述

本文档详细说明了图书推荐系统的完整数据过滤规则体系，包含四个核心模块的过滤机制：

- **模块1**: 月归还数据分析（借阅数据过滤）
- **模块2**: 智能降噪筛选（多维度内容过滤）
- **模块3**: 豆瓣模块（评分、评论人数、API数据筛选）
- **模块4**: 大模型评选（三级智能评选过滤）

## 整体架构

### 数据处理流程
```
原始借阅数据 → 模块1(借阅分析) → 模块2(智能筛选) → 模块3(豆瓣数据) → 模块4(大模型评选) → 最终推荐结果
```

### 过滤策略层级
1. **数据层过滤**: 借阅次数、分类、基础信息验证
2. **内容层过滤**: 题名关键词、索书号模式、列值验证
3. **质量层过滤**: 豆瓣评分、评论人数、数据完整性
4. **智能层过滤**: 大模型评估、主题匹配度、专家评选

## 模块1：月归还数据分析过滤

### 核心功能
对图书馆的月归还数据进行统计分析，过滤掉不符合推荐策略的图书类型。

### 主要过滤规则

#### 1.1 热门图书筛选（HotBooksFilter）
**目的**: 排除借阅次数过高的顶流热门图书，确保推荐多样性

**算法逻辑**:
```python
def _calculate_dynamic_threshold(self, borrowing_counts: pd.Series) -> int:
    # 1. 获取非零借阅数据
    non_zero_data = borrowing_counts[borrowing_counts > 0]
    
    # 2. 分位数方法（默认）
    if self.config['methods']['percentile']['enabled']:
        percentile = self.config['methods']['percentile']['threshold_percentile']
        threshold = np.percentile(non_zero_data, 100 - percentile)
        
        # 防止阈值过小，使用75%分位数作为后备
        if threshold < 5:
            threshold = np.percentile(non_zero_data, 75)
        
        return int(threshold)
    
    # 3. 绝对次数方法
    elif self.config['methods']['absolute_count']['enabled']:
        return self.config['methods']['absolute_count']['threshold_borrowing_count']
    
    # 4. 默认方法（排除前15%）
    else:
        threshold = np.percentile(non_zero_data, 85)
        return int(threshold)
```

**配置参数**:
- `threshold_percentile`: 分位数阈值（默认15%，即排除前15%热门图书）
- `fallback_count`: 后备阈值（当数据不足时使用）
- `enabled`: 开关控制

**输出指标**:
- `excluded_count`: 被排除的记录数
- `threshold`: 动态计算的阈值
- `excluded_ratio`: 排除比例

## 模块2：智能降噪筛选

### 核心功能
通过多维度的内容分析和模式匹配，进一步过滤不符合推荐策略的图书。

### 2.1 题名关键词筛选（TitleKeywordsFilter）

**目的**: 通过题名中的关键词识别并排除特定类型图书

**关键词分类体系**:

1. **技术类**（90个关键词）
   - 编程语言: Python, Java, JavaScript, C++, R语言, MATLAB
   - 框架工具: Django, Flask, Vue, Spring, PyTorch, TensorFlow
   - 软件工具: Photoshop, Blender, SPSS, WPS, Unity
   - 技术概念: 机器学习, 深度学习, 算法, 数据库, 微服务

2. **教辅类**（60个关键词）
   - 考试类型: 考试, 教程, 教材, 习题, 答案, 考研, 雅思, 四级
   - 学习材料: 真题, 模拟题, 考前冲刺, 辅导教材, 资格考核
   - 教育阶段: 高中, 小学, 初中, 职业学校

3. **经管类**（80个关键词）
   - 金融投资: 股票, 股市, 期货, K线, 证券, 保险, 股权, 信托
   - 财务会计: 会计, 财务, 审计, 票据, 预算, 绩效
   - 管理专业: MBA, MPA, 公司治理, 产业集群

4. **医药类**（70个关键词）
   - 医疗专业: 临床, 诊断, 诊疗, 治疗, 康复, 护理, 制药
   - 专科领域: 中医, 西医, 妇科, 儿科, 眼科, 口腔, 心血管
   - 医疗器械: 内镜, 医疗器械

5. **工具类**（150个关键词）
   - 参考资料: 资料汇编, 年鉴, 词典, 字典, 县志, 工业志
   - 操作指南: 用户手册, 入门手册, 实验指导, 实操手册
   - 版本标识: 普及版, 视频课, 高教版, 案例版, 实战版

6. **红色政治类**（25个关键词）
   - 政治理论: 一带一路, 习近平, 马克思主义, 党建
   - 组织机构: 党员, 干部, 共青团, 中国共产党

**匹配策略**:
- `contains`: 关键词出现在题名任意位置（默认）
- `starts_with`: 关键词位于题名开头
- `ends_with`: 关键词位于题名结尾
- `regex`: 使用正则表达式进行复杂匹配

### 2.2 索书号/CLC号筛选（CallNumberFilter）

**目的**: 基于中国图书馆分类法（CLC）进行精确的学科分类筛选

**保留策略（KEEP规则）**:
```regex
# 保留哲学类（D类，排除D35）
KEEP ^D[0-1](?!35).*
KEEP ^D[4-5].*
KEEP ^D61.*
KEEP ^D69.*
KEEP ^D7.*

# 保留经济类（F类）
KEEP ^F11.*
KEEP ^F129.*
KEEP ^F1[3-7](?:\d+\.?\d*|\.\d+)+9/.*
KEEP ^F2[4-9]9.(?:\d+\.?\d*|\.\d+)+9/.*

# 保留文化教育类（G类）
KEEP ^G210.9.*
KEEP ^G20.*
KEEP ^G219.19.*
KEEP ^G229.19.*

# 保留文学类（I类）
KEEP ^I0.*
KEEP ^I10.*
KEEP ^I206.7.*
KEEP ^I209.*

# 保留艺术类（J类）
KEEP ^J0.*
KEEP ^J11.*
KEEP ^J120.9.*

# 保留自然科学总论（N类）
KEEP ^N0.*
KEEP ^N49.*
KEEP ^N91.*

# 保留技术科学（TS类，排除TS1）
KEEP ^TS(?!1).*

# 保留建筑科学（TU类）
KEEP ^TU22.*
KEEP ^TU23.*
KEEP ^TU25.*

# 保留综合性图书（Z类，特定段号）
KEEP ^Z228.*
KEEP ^Z2[3-7].*
```

**排除策略（DROP规则）**:
```regex
# 排除马克思主义类
DROP ^A.*

# 排除部分哲学类
DROP ^B2.*
DROP ^B81.*
DROP ^B9[4-9].*

# 排除社会科学总论类
DROP ^C[5-8].*

# 排除非指定段号的自然科学
DROP ^N(?!(?:91|0|49)).*

# 排除其他大部分分类
DROP ^[EFGHJKOPQRUVX].*
```

**优先级逻辑**:
```python
# 仅当命中排除且未命中保留时才剔除
include_mask = self._build_mask(data, valid_columns, include_patterns, match_type)
exclude_mask = self._build_mask(data, valid_columns, exclude_patterns, match_type)
to_exclude_mask = (~include_mask) & exclude_mask
result_data = data[~to_exclude_mask]
```

### 2.3 列值筛选（ColumnValueFilter）

**目的**: 提供灵活的Excel列值验证和筛选

**支持类型**:
1. **正则表达式筛选（regex）**
   ```python
   def _regex_filter(self, text_series, pattern, action):
       if action == 'keep_only':
           return ~text_series.astype(str).str.match(pattern, na=False)
       else:  # exclude
           return text_series.astype(str).str.match(pattern, na=False)
   ```

2. **关键词排除筛选（exclude_contains）**
   ```python
   def _exclude_contains_filter(self, text_series, exclude_patterns):
       excluded_mask = pd.Series(False, index=text_series.index)
       for pattern in exclude_patterns:
           excluded_mask |= text_series.astype(str).str.contains(
               pattern, na=False, case=False
           )
       return excluded_mask
   ```

## 模块3：豆瓣模块过滤

### 核心功能
通过豆瓣API获取图书的评分、评论人数等信息，并进行质量筛选。

### 3.1 动态阈值过滤（DynamicThresholdFilter）

**目的**: 基于评论人数和评分进行智能筛选，确保推荐质量

**核心算法**:
```python
def analyze(self, dataset):
    # 1. 按索书号首字母分组
    grouped = dataset.groupby("call_letter", sort=True)
    
    for letter, group in grouped:
        # 2. 计算评论人数的黄金区间
        review_lower_bound = self._safe_quantile(
            group["rating_count"], review_lower_pct  # 40%分位数
        )
        review_upper_bound = self._safe_quantile(
            group["rating_count"], review_upper_pct  # 80%分位数
        )
        
        # 3. 计算评分门槛
        score_floor = self._get_category_floor(letter)  # 分类最低分
        if not is_small_sample:
            relative_threshold = self._safe_quantile(
                group["rating"], rating_pct_large  # 75%分位数
            )
            score_threshold = max(score_floor, relative_threshold)
        
        # 4. 应用过滤条件
        candidate_mask = pd.Series(True, index=group.index)
        candidate_mask &= group["rating_count"].ge(review_lower_bound)
        candidate_mask &= group["rating_count"].le(review_upper_bound)
        candidate_mask &= group["rating"].ge(score_threshold)
```

**分类评分门槛**:
```python
category_min_scores = {
    "I": 8.0,  # 文学类
    "K": 7.8,  # 历史地理类
    "T": 7.5,  # 工业技术类
    "E": 7.4,  # 军事类
    "B": 8.2,  # 哲学类
    "default": 7.5  # 默认门槛
}
```

**小样本处理**:
- 当样本数小于30时，使用保守的筛选策略
- 避免因样本不足导致的筛选偏差

### 3.2 列值验证过滤

**目的**: 确保豆瓣数据的完整性和质量

**配置示例**:
```yaml
column_filters:
  enabled: true
  rules:
    # 豆瓣封面图片验证
    - name: "豆瓣封面图片验证"
      enabled: true
      column: "豆瓣封面图片链接"
      filter_type: "not_empty"
      description: "排除没有封面图片的图书"
    
    # 豆瓣内容简介验证
    - name: "豆瓣内容简介验证"
      enabled: true
      column: "豆瓣内容简介"
      filter_type: "not_empty"
      description: "排除没有内容简介的图书"
    
    # ISBN格式验证
    - name: "ISBN格式验证"
      enabled: true
      column: "豆瓣ISBN"
      filter_type: "regex"
      pattern: "^\\d{10}(\\d{3})?$"
```

**验证类型**:
1. **not_empty**: 非空验证，排除空值、None、NaN和空字符串
2. **regex**: 正则表达式验证，检查格式正确性

**实现逻辑**:
```python
def _apply_column_filters(self, index) -> bool:
    for rule in rules:
        if not rule.get("enabled", False):
            continue
        
        column = rule.get("column")
        filter_type = rule.get("filter_type")
        value = self._source_df.at[index, column]
        
        if filter_type == "not_empty":
            if not self._check_not_empty(value):
                return False
        elif filter_type == "regex":
            pattern = rule.get("pattern")
            if pattern and not self._check_regex(value, pattern):
                return False
    
    return True
```

## 模块4：大模型评选过滤

### 核心功能
通过三阶段智能评选，对候选图书进行深度分析和排序。

### 4.1 三级评选机制

#### 第一阶段：初评（海选）
**目的**: 从大量候选图书中筛选出潜力图书

**流程**:
1. 按主题分组（基于索书号首字母）
2. 每组按推荐配额筛选：
   - 20本以上: 6本
   - 15-20本: 5本  
   - 10-15本: 4本
   - 5-10本: 3本
   - 5本以下: 2本

**配额配置**:
```python
DEFAULT_QUOTA = {
    "gt20": 6,
    "g15_20": 5,
    "g10_15": 4,
    "g5_10": 3,
    "lt5": 2,
}
```

**批次处理**:
```python
def even_batches(total, max_batch_size=20):
    num_batches = math.ceil(total / max_batch_size)
    base = total // num_batches
    rem = total % num_batches
    return [base + (1 if i < rem else 0) for i in range(num_batches)]
```

#### 第二阶段：决选（半决赛）
**目的**: 从初评结果中进一步筛选，提升质量

**主题内决选**:
```python
def get_theme_finalist_quota() -> int:
    try:
        loader = ConfigLoader("config/llm.yaml")
        settings = loader.load()
        quota = settings.get("tasks", {}).get("theme_runoff", {}).get("parameters", {}).get("finalist_quota", 8)
        return int(quota)
    except Exception:
        return 8  # 默认每主题8本晋级终评
```

**自适应筛选**:
- 根据实际候选数量动态调整配额
- 优先保留高质量、高相关性的图书

#### 第三阶段：终评（总决赛）
**目的**: 确定最终推荐清单

**最终推荐数量**:
```python
def get_final_top_n() -> int:
    try:
        loader = ConfigLoader("config/llm.yaml")
        settings = loader.load()
        top_n = settings.get("tasks", {}).get("theme_final", {}).get("parameters", {}).get("top_n", 10)
        return int(top_n)
    except Exception:
        return 10  # 默认推荐10本书
```

### 4.2 大模型评估过滤

**评估维度**:
1. **主题相关性**: 图书与目标主题的匹配程度
2. **内容质量**: 图书的学术价值和实用性
3. **推荐理由**: 适合推荐给读者的原因
4. **差异化**: 与其他候选图书的区别度

**结构化输出**:
```python
def _call_llm_with_structured_response(task_name, prompt, log_context):
    def _handler(response_text):
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            return self._safe_parse_json(response_text)
    return llm_call(prompt, response_handler=_handler)
```

**错误处理和重试**:
```python
def _retry_failed_reviews(excel_path, executor, writer):
    failed_books = df[df['初评状态'] == '失败']
    retry_count = 0
    for _, row in failed_books.iterrows():
        try:
            result = executor.initial(theme, books)
            writer.write_initial(result)
            retry_count += 1
        except Exception as e:
            logger.error(f"重试失败: {e}")
    return retry_count
```

## 配置管理

### 5.1 筛选器注册表（FilterRegistry）
```python
class FilterRegistry:
    _filters = {}
    
    @classmethod
    def register(cls, filter_type, filter_class):
        """注册新的筛选器类型"""
        
    @classmethod
    def create_filter(cls, filter_type, config):
        """根据类型创建筛选器实例"""
        
    @classmethod
    def get_available_filters(cls):
        """获取所有可用的筛选器类型"""
```

### 5.2 配置文件结构
```
config/
├── filters/
│   ├── title_keywords.txt      # 题名关键词
│   └── call_number_clc.txt     # 索书号模式
├── setting.yaml                # 豆瓣过滤配置
└── llm.yaml                    # 大模型评选配置
```

### 5.3 配置加载策略
1. **优先从配置文件读取**
2. **配置文件失败时使用代码默认值**
3. **支持运行时动态调整**
4. **完整的错误处理和日志记录**

## 性能优化

### 6.1 批量处理
- 所有筛选器基于pandas向量化操作
- 支持大数据量的并行处理
- 合理的批次大小控制（默认20本/批）

### 6.2 缓存机制
- 筛选模式文件一次性加载
- 中间结果缓存和复用
- 智能的内存管理

### 6.3 渐进式筛选
```python
# 链式筛选，减少内存占用
current_data = original_data
filters = [hot_filter, keyword_filter, call_filter, douban_filter]

for filter_instance in filters:
    current_data, stats = filter_instance.apply(current_data)
    logger.info(f"筛选完成，剩余 {len(current_data)} 条记录")
```

## 监控和统计

### 7.1 筛选统计
每个筛选器返回详细的统计信息：
```python
{
    'excluded_count': 被排除记录数,
    'excluded_ratio': 排除比例,
    'threshold': 使用的阈值,
    'patterns_used': 使用的模式列表,
    'status': 筛选状态
}
```

### 7.2 日志记录
```python
logger.info(f"规则A - 热门图书筛选: 排除 {excluded_count} 条记录")
logger.info(f"规则B - 题名关键词筛选: 排除 {excluded_count} 条记录") 
logger.info(f"豆瓣筛选: {candidate_count} 本图书进入候选池")
logger.info(f"终评完成: 推荐 {len(final_recommendations)} 本图书")
```

### 7.3 报告生成
```python
class RecommendationReportGenerator:
    def generate_report(self, df):
        metrics = self._collect_metrics(df)
        return self._build_report_lines(metrics)
```

## 容错机制

### 8.1 智能列名映射
```python
def _auto_map_column(self, target, available):
    mapping = {
        '索书号': ['索书号', '分类号', 'CallNumber', 'CallNo'],
        '题名': ['题名', '书名', '图书名称', 'Title'],
        '豆瓣评分': ['豆瓣评分', '评分', 'Rating'],
    }
    # 自动匹配相似列名
```

### 8.2 数据类型安全
- 强制字符串转换避免类型错误
- Na值处理和填充策略
- 异常捕获和优雅降级

### 8.3 配置容错
```python
try:
    config = load_config()
except Exception as e:
    logger.warning(f"配置加载失败，使用默认值: {e}")
    config = get_default_config()
```

## 使用示例

### 9.1 完整流程示例
```python
# 1. 加载数据
data = load_borrowing_data("data/月归还.xlsx")

# 2. 应用模块1过滤
hot_filter = HotBooksFilter(hot_config)
data, stats1 = hot_filter.apply(data)

# 3. 应用模块2过滤
keyword_filter = TitleKeywordsFilter(keyword_config)  
data, stats2 = keyword_filter.apply(data)
call_filter = CallNumberFilter(call_config)
data, stats3 = call_filter.apply(data)

# 4. 应用模块3豆瓣筛选
douban_filter = DynamicThresholdFilter()
data, stats4 = douban_filter.analyze(data)

# 5. 应用模块4大模型评选
final_results = run_theme_recommendation_full("output.xlsx")

# 6. 生成报告
generate_final_report(final_results, stats1, stats2, stats3, stats4)
```

### 9.2 单独使用筛选器
```python
from src.core.filters import FilterRegistry

# 创建筛选器链
filters = [
    FilterRegistry.create_filter('hot_books', hot_config),
    FilterRegistry.create_filter('title_keywords', keyword_config),
    FilterRegistry.create_filter('call_number', call_config),
]

# 执行筛选
current_data = original_data
all_stats = []

for filter_instance in filters:
    current_data, stats = filter_instance.apply(current_data)
    all_stats.append(stats)

print(f"最终筛选结果: {len(current_data)} 条记录")
```

## 总结

本图书推荐系统构建了一个完整的多层过滤体系：

### 核心优势
1. **模块化设计**: 每个过滤规则独立实现，便于维护和扩展
2. **智能筛选**: 结合统计数据、关键词匹配、AI评估的多维度筛选
3. **配置驱动**: 支持通过配置文件灵活调整筛选参数
4. **质量保证**: 多重验证机制确保推荐结果的质量
5. **性能优化**: 基于向量化操作，支持大数据量处理
6. **容错机制**: 完善的错误处理和恢复能力

### 过滤效果
- **模块1**: 排除15-30%的过度热门图书
- **模块2**: 排除50-70%的不相关内容
- **模块3**: 从豆瓣数据中筛选出10-20%的高质量候选
- **模块4**: 最终推荐10本最优质的图书

### 应用价值
通过这套过滤系统，图书馆可以为读者提供：
- **多样性**: 避免过度热门的重复推荐
- **相关性**: 基于内容匹配的高相关性推荐
- **质量性**: 经过多维评估的高质量推荐
- **个性化**: 基于主题的个性化推荐

这套系统不仅提高了推荐的准确性，还大大提升了用户体验，为图书馆的智能化服务提供了强有力的技术支撑。
