# 从JSON进行实体链接并抽离LLM匹配

Status: In Progress  
Date: 2025-10-04  
Owner: l2_knowledge_linking

## Objective / Summary
将实体处理流程从“Excel抽取+去重+类型判断”改为直接读取 runtime/outputs 下已生成的逐行 JSON 文件（以行编号为文件名）。对每个实体：
- 使用实体 label 调用检索（Wikipedia、Wikidata）
- 调用统一大模型模块（src/utils/llm_api.py）进行匹配判定与筛选
- 将结果写回到同一份 JSON 文件中对应实体节点：
  - Wikipedia 成功：写入 wikipedia_uri=canonicalurl、description=summary
  - Wikidata 成功：写入 wikidata_uri（拼接好的 URI）、description（完整文本）
  - 不成功：对应节点为 null
- 两个源的检索流程均附带 meta（执行时间、状态等）。已执行过且达到终态的实体默认跳过（除非 overwrite=true）

## Scope
预计新增/修改：
- 新增：src/core/l2_knowledge_linking/entity_matcher.py（封装 LLM 匹配判断）
- 复用：src/core/l2_knowledge_linking/tools/wikipedia_tool.py（Wikipedia 检索）
- 复用/补齐：src/core/l2_knowledge_linking/tools/wikidata_tool.py（若不存在则新增）
- 修改：src/core/l2_knowledge_linking/entity_processor.py（改为遍历 runtime/outputs JSON 并写回）
- 复用：src/utils/llm_api.py（统一大模型调用）
- 日志：src/utils/logger.py（如无则新增，集中化日志）
- 测试：
  - tests/core/l2_knowledge_linking/test_entity_matcher.py
  - tests/core/l2_knowledge_linking/test_entity_processor_json_flow.py

不在范围（Out of Scope）：
- Excel 实体抽取与类型判断逻辑的进一步改造
- 前端或可视化层改动

## Detailed Plan

### 数据输入
- 从 settings.outputs_dir（默认 runtime/outputs）扫描 *.json
- 每个 JSON 包含：
  - row_id: str
  - entities: list[ { label, type, sources, context_hint, _type_meta, ... } ]

### 检索与匹配
- Wikipedia：
  - 复用 src/core/l2_knowledge_linking/tools/wikipedia_tool.py 获取候选，候选字段至少包含：title、canonicalurl、summary、pageid 等。
  - 将候选 + label + type + context_hint 传入 entity_matcher.judge_best_match(...)，调用 src/utils/llm_api.py。
  - 若 matched=true：在实体下写入：
    ```
    "wikipedia": {
      "wikipedia_uri": "<canonicalurl>",
      "description": "<summary>",
      "meta": {
        "executed_at": "<ISO8601 UTC>",
        "status": "success",
        "llm": { "matched": true, "confidence": <float>, "reason": "中文理由", "selected_title": "...", "selected_id": "..." }
      }
    }
    ```
  - 若未检索到或匹配失败：节点置为 null，且在实体.metadata.wikipedia 写入：
    ```
    "metadata": {
      "wikipedia": {
        "executed_at": "<ISO8601 UTC>",
        "status": "not_found" | "not_matched" | "error",
        "error": "可选"
      }
    }
    ```

- Wikidata：
  - 复用/补齐 tools/wikidata_tool.py 获取候选，字段包含：qid、uri（https://www.wikidata.org/wiki/Qxxx）、label、fulltext/description。
  - LLM 判定同上。
  - 若成功：
    ```
    "wikidata": {
      "wikidata_uri": "https://www.wikidata.org/wiki/Qxxx",
      "description": "<完整文本>",
      "meta": {
        "executed_at": "<ISO8601 UTC>",
        "status": "success",
        "llm": { "matched": true, "confidence": <float>, "reason": "中文理由", "selected_qid": "Qxxx" }
      }
    }
    ```
  - 若未检索到或匹配失败：节点置为 null，并在实体.metadata.wikidata 记录 meta（同 Wikipedia 方案）。

说明：
- 按你的要求，“未检索到或不成功则节点为 null”；为保留审计信息，meta 平移至实体.metadata.[wikipedia|wikidata]。
- 终态定义：{"success","not_found","not_matched"}。默认 overwrite=False 时跳过已处于终态的源。

### 幂等与跳过策略
- 判断是否需要执行某源检索：
  - 若 overwrite=True，则总是执行
  - 否则检查：
    - 若实体.[wikipedia|wikidata] 非空且 meta.status == "success" → 跳过
    - 若实体.metadata.[wikipedia|wikidata].status in {"not_found","not_matched"} → 跳过
    - 其他情况执行

### 速率限制与重试
- 默认每源每秒 1 请求；对 Wikipedia 与 Wikidata 分源计算
- 对网络请求采用指数退避重试（如最多 3 次），失败则记录 error 并进入终态 "error"

### 日志
- 使用 src/utils/logger.py 的全局 logger
- 记录字段：timestamp, level, module, row_id, label, source(wikipedia|wikidata), action(search|judge|write), status, message
- 严禁记录敏感信息

### 配置（settings）
- outputs_dir: "runtime/outputs"
- overwrite: false
- rate_limit:
  - wikipedia: 1 rps
  - wikidata: 1 rps
- top_k: 5（对候选截断）
- search.providers 配置（API endpoint、语言、超时）
- llm 配置（provider、model、温度、top_p、超时、重试）

### 模块接口
- src/core/l2_knowledge_linking/entity_matcher.py
  - judge_best_match(label: str, ent_type: str, context_hint: str, candidates: list[dict], source: Literal["wikipedia","wikidata"], settings: dict) -> dict
  - 返回：
    ```
    {
      "matched": bool,
      "confidence": float,
      "reason": "中文理由",
      "selected": dict | null
    }
    ```
- src/core/l2_knowledge_linking/tools/wikipedia_tool.py
  - search_candidates(query: str, settings: dict) -> list[dict]
- src/core/l2_knowledge_linking/tools/wikidata_tool.py
  - search_candidates(query: str, settings: dict) -> list[dict]

### 文件写回
- 读取原始 JSON，更新 entities[i] 的 wikipedia / wikidata 字段或置 null，并在 metadata 下记录对应 meta（当 null 时）
- 保存至同一 JSON 文件（原地覆盖写回）

## Visualization
```mermaid
flowchart TD
  A[扫描 outputs_dir/*.json] --> B{遍历 entities[]}
  B --> C{Wikipedia 需执行? \n overwrite 或未达终态}
  C -- 否 --> E
  C -- 是 --> D[Wikipedia: 搜索候选 -> LLM判定 -> 写回节点或置null + metadata.wikipedia]
  D --> E{Wikidata 需执行? \n overwrite 或未达终态}
  E -- 否 --> G
  E -- 是 --> F[Wikidata: 搜索候选 -> LLM判定 -> 写回节点或置null + metadata.wikidata]
  D --> G
  F --> G[保存 JSON]
  G --> H{下一个实体?}
  H -- 是 --> B
  H -- 否 --> I{下一个文件?}
  I -- 是 --> A
  I -- 否 --> J[结束]
```

## Testing Strategy
- 单元测试
  - tests/core/l2_knowledge_linking/test_entity_matcher.py
    - mock src/utils/llm_api.py 输出，覆盖：
      - 匹配成功（返回 selected）
      - 不匹配（matched=false）
      - 边界：候选为空
  - tests/core/l2_knowledge_linking/test_entity_processor_json_flow.py
    - 构造临时 JSON（含样例实体）
    - mock wikipedia_tool / wikidata_tool 的 search_candidates
    - mock entity_matcher.judge_best_match
    - 断言：
      - 跳过逻辑：当 meta 为终态时不再请求
      - 写回字段命名与内容正确（wikipedia_uri/description，wikidata_uri/description）
      - 未匹配时节点为 null，且 metadata.[source] 存在并状态正确
      - overwrite=True 时会重跑并覆盖

- 非功能测试
  - 速率限制与并发：在 mock 下验证调用间隔策略（可通过计数与时间窗口模拟）
  - 错误注入：模拟超时/异常，验证写入 error、状态为 "error"

## Security Considerations
- 外部 API 的请求参数需进行最小化与编码处理，防止注入
- 不记录敏感信息到日志
- 统一通过 settings 注入 API Key（若需要），不在仓库硬编码
- 对 LLM 输出进行 JSON 解析与校验，防止格式异常导致写回失败

## Implementation Notes（将在交付时补充）
- 实际候选字段映射（Wikipedia、Wikidata）
- LLM 提示词设计与解析规范
- 任何与原计划偏差的地方