# LLMè°ƒç”¨ç³»ç»Ÿé‡æ„æ–¹æ¡ˆè®¾è®¡

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

- **é¡¹ç›®**: llm-request-langfuse
- **ç‰ˆæœ¬**: v1.0
- **åˆ›å»ºæ—¥æœŸ**: 2025-10-30
- **æ–‡æ¡£ç±»å‹**: æŠ€æœ¯é‡æ„æ–¹æ¡ˆ

---

## ğŸ“Š ç°çŠ¶åˆ†æ

### ç°æœ‰ç³»ç»Ÿæ¶æ„

å½“å‰é¡¹ç›®åŒ…å«ä¸¤å¥—LLMè°ƒç”¨ç³»ç»Ÿï¼š

#### ç³»ç»Ÿ1ï¼šLangfuseè°ƒç”¨ç³»ç»Ÿ
- **æ–‡ä»¶**: `langfuse_llm.py`
- **ç‰¹ç‚¹**:
  - é›†æˆLangfuseç›‘æ§å¹³å°
  - ä½¿ç”¨ `@observe()` è£…é¥°å™¨è¿½è¸ª
  - æœ¬åœ°æç¤ºè¯ç®¡ç† (`utils/prompt.py`)
  - é‡è¯•è£…é¥°å™¨ (`retry_with_fallback`)
  - æŒ‡æ•°é€€é¿é‡è¯•æœºåˆ¶

#### ç³»ç»Ÿ2ï¼šæœ¬åœ°è°ƒç”¨ç³»ç»Ÿ
- **æ–‡ä»¶**: `llm_api.py`
- **ç‰¹ç‚¹**:
  - å®Œå…¨æœ¬åœ°é…ç½® (`config/settings.yaml`)
  - ä¸»å¤‡Provideråˆ‡æ¢æœºåˆ¶
  - å®Œå–„çš„æ—¥å¿—ç³»ç»Ÿ
  - ç‹¬ç«‹çš„é‡è¯•ç­–ç•¥
  - æ”¯æŒå¤šè½®å¯¹è¯å’Œè§†è§‰æ¶ˆæ¯

### æ ¸å¿ƒé—®é¢˜è¯†åˆ«

1. **é‡å¤å®ç°**
   - ä¸¤å¥—é‡è¯•é€»è¾‘å®ç°æ–¹å¼ä¸åŒ
   - ä¸¤å¥—æ—¥å¿—ç³»ç»Ÿåˆ†æ•£ç®¡ç†
   - é…ç½®ä¿¡æ¯åœ¨å¤šä¸ªæ–‡ä»¶ä¸­

2. **é…ç½®åˆ†æ•£**
   - Langfuseé…ç½®åœ¨Pythonä»£ç ä¸­
   - æœ¬åœ°é…ç½®åœ¨YAMLæ–‡ä»¶ä¸­
   - æç¤ºè¯æ ¼å¼ä¸ç»Ÿä¸€ï¼ˆdict vs .mdï¼‰

3. **æ—¥å¿—ç³»ç»Ÿå‰²è£‚**
   - `langfuse_llm.py` ä½¿ç”¨ `print()` è¾“å‡º
   - `llm_api.py` ä½¿ç”¨ `logging` æ¨¡å—
   - æ— ç»Ÿä¸€æ—¥å¿—æ ¼å¼å’Œä¸­æ–‡æ”¯æŒ

4. **åŠŸèƒ½æœªå®Œå…¨åˆ©ç”¨**
   - `json_repair.py` æœªé›†æˆåˆ°å®é™…è°ƒç”¨æµç¨‹
   - Langfuseç›‘æ§èƒ½åŠ›æœªå……åˆ†å‘æŒ¥

5. **ç»´æŠ¤å›°éš¾**
   - ä»£ç é‡å¤ï¼Œä¿®æ”¹éœ€è¦å¤šå¤„æ›´æ–°
   - ç¼ºä¹ç»Ÿä¸€çš„é”™è¯¯å¤„ç†ç­–ç•¥
   - æ–°åŠŸèƒ½å¼€å‘éœ€è¦åœ¨ä¸¤å¥—ç³»ç»Ÿä¸­éƒ½å®ç°

---

## ğŸ¯ é‡æ„ç›®æ ‡

### æ ¸å¿ƒç›®æ ‡

åˆ›å»º**ç»Ÿä¸€çš„LLMè°ƒç”¨ç³»ç»Ÿ**ï¼Œå®ç°ä»¥ä¸‹ç‰¹æ€§ï¼š

1. **ç»Ÿä¸€é…ç½®ç®¡ç†**
   - æ‰€æœ‰é…ç½®é›†ä¸­åˆ°YAMLæ–‡ä»¶
   - æ”¯æŒç¯å¢ƒå˜é‡æ³¨å…¥
   - åŠ¨æ€é…ç½®åŠ è½½å’Œçƒ­æ›´æ–°

2. **æ™ºèƒ½é‡è¯•æœºåˆ¶**
   - åˆ†å±‚é‡è¯•ç­–ç•¥ï¼ˆProviderå†…é‡è¯• â†’ Provideråˆ‡æ¢ï¼‰
   - æŒ‡æ•°é€€é¿ç®—æ³•
   - é”™è¯¯ç±»å‹æ™ºèƒ½è¯†åˆ«

3. **å¤šæ ¼å¼æç¤ºè¯æ”¯æŒ**
   - `.md` æ–‡ä»¶æ ¼å¼ï¼ˆæœ¬åœ°ï¼‰
   - Langfuseå¹³å°æç¤ºè¯
   - Python dictå†…è”æ ¼å¼

4. **ä¸­æ–‡æ—¥å¿—ç³»ç»Ÿ**
   - å®Œæ•´è°ƒç”¨é“¾è·¯è¿½è¸ª
   - ä¸­æ–‡çº§åˆ«åç§°å’Œæ ¼å¼
   - æŒ‰æ—¥æœŸè½®è½¬å’Œåˆ†çº§å­˜å‚¨

5. **JSONæ™ºèƒ½ä¿®å¤**
   - è‡ªåŠ¨æ£€æµ‹JSONæ ¼å¼é”™è¯¯
   - æ™ºèƒ½ä¿®å¤å¸¸è§é—®é¢˜
   - å¯é…ç½®å¯ç”¨/ç¦ç”¨

6. **é«˜åº¦å¯é…ç½®**
   - ä»»åŠ¡çº§é‡è¯•ç­–ç•¥
   - Providerçº§é…ç½®
   - å…¨å±€é»˜è®¤é…ç½®

7. **å‘åå…¼å®¹**
   - ä¿ç•™ç°æœ‰æ¥å£
   - æä¾›è¿ç§»å·¥å…·
   - æ–‡æ¡£æŒ‡å¼•å‡çº§

---

## ğŸ”§ è¯¦ç»†è®¾è®¡æ–¹æ¡ˆ

### 1. ç»Ÿä¸€é…ç½®ç³»ç»Ÿ

#### é…ç½®ç»“æ„è®¾è®¡

```yaml
# config/settings.yaml

# APIæä¾›å•†é…ç½®
api_providers:
  text:
    primary:
      name: "ä¸»æ–‡æœ¬æä¾›å•†"
      api_key: env:PRIMARY_API_KEY
      base_url: "https://api.primary.com/v1"
      model: "deepseek-chat"
      timeout_seconds: 120
      max_tokens: 4096
    secondary:
      name: "å¤‡ç”¨æ–‡æœ¬æä¾›å•†"
      api_key: env:SECONDARY_API_KEY
      base_url: "https://api.secondary.com/v1"
      model: "deepseek-chat"
      timeout_seconds: 120
      max_tokens: 4096

  vision:
    primary:
      name: "ä¸»è§†è§‰æä¾›å•†"
      api_key: env:VISION_API_KEY
      base_url: "https://api.vision.com/v1"
      model: "qwen-vl-max"
      timeout_seconds: 180
      max_tokens: 4096
    secondary:
      name: "å¤‡ç”¨è§†è§‰æä¾›å•†"
      api_key: env:VISION_FALLBACK_KEY
      base_url: "https://api.vision-fallback.com/v1"
      model: "qwen-vl-plus"
      timeout_seconds: 180
      max_tokens: 4096

# ä»»åŠ¡é…ç½®
tasks:
  fact_description:
    provider_type: "text"
    temperature: 0.45
    top_p: 0.9
    max_tokens: 2048

    # æç¤ºè¯é…ç½®ï¼ˆæ”¯æŒå¤šæ ¼å¼ï¼‰
    prompt:
      type: "md"              # md | langfuse | dict
      source: "prompts/fact_description.md"  # .mdæ–‡ä»¶è·¯å¾„
      # langfuse_name: "fact_description"      # Langfuseæç¤ºè¯åç§°
      # content: {...}                        # dictæ ¼å¼å†…å®¹

    # é‡è¯•ç­–ç•¥
    retry:
      max_retries: 3           # æœ€å¤§é‡è¯•æ¬¡æ•°
      base_delay: 1            # æŒ‡æ•°é€€é¿åŸºæ•°ï¼ˆç§’ï¼‰
      max_delay: 60            # æœ€å¤§é€€é¿æ—¶é—´ï¼ˆç§’ï¼‰
      enable_provider_switch: true  # æ˜¯å¦å¯ç”¨Provideråˆ‡æ¢

    # Langfuseç›‘æ§
    langfuse:
      enabled: true
      name: "fact_description"
      tags: ["fact", "description", "image_analysis"]
      metadata:
        task_type: "description"
        source: "unified_client"

    # JSONå¤„ç†
    json_repair:
      enabled: true
      strict_mode: false  # true: ä¿®å¤å¤±è´¥è¿”å›None, false: è¿”å›åŸæ–‡

    # é€Ÿç‡é™åˆ¶
    rate_limit:
      requests_per_minute: 60
      burst_size: 10

  correction:
    provider_type: "text"
    temperature: 0.2
    top_p: 0.9
    prompt:
      type: "dict"
      content:
        role: "system"
        content: |
          ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ ¡å¯¹åŠ©æ‰‹ï¼Œæ“…é•¿å‘ç°å’Œä¿®æ­£æ–‡æœ¬ä¸­çš„é”™è¯¯ã€‚
          è¯·ä»”ç»†æ£€æŸ¥ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œå¹¶æä¾›ä¿®æ­£åçš„ç‰ˆæœ¬ã€‚
    retry:
      max_retries: 2
      base_delay: 1
      max_delay: 30
      enable_provider_switch: true
    langfuse:
      enabled: false
    json_repair:
      enabled: false

# å…¨å±€é»˜è®¤é…ç½®
defaults:
  temperature: 0.7
  top_p: 0.9
  timeout_seconds: 60
  max_retries: 3

# å…¨å±€é‡è¯•ç­–ç•¥ï¼ˆå¯è¢«ä»»åŠ¡çº§è¦†ç›–ï¼‰
retry_policy:
  max_retries: 3
  base_delay: 1
  max_delay: 60
  jitter: true  # å¯ç”¨éšæœºæŠ–åŠ¨

# é€Ÿç‡é™åˆ¶
rate_limit:
  global:
    requests_per_minute: 1000
    concurrent_requests: 10

# ç»Ÿä¸€æ—¥å¿—é…ç½®
logging:
  level: "INFO"
  logs_dir: "runtime/logs"

  # ä¸­æ–‡æ—¥å¿—æ ¼å¼
  format: |
    æ—¶é—´=%(asctime)s | çº§åˆ«=%(levelname)s | æ¨¡å—=%(name)s | è¡Œå·=%(lineno)d | ä¿¡æ¯=%(message)s
  date_format: "%Y-%m-%d %H:%M:%S"

  # æ—¥å¿—è½®è½¬
  rotation:
    when: "D"              # æŒ‰å¤©è½®è½¬
    interval: 1
    backup_count: 7        # ä¿ç•™7å¤©
    encoding: "utf-8"

  # æ—¥å¿—åˆ†çº§
  levels:
    console: "INFO"        # æ§åˆ¶å°æ˜¾ç¤ºINFOåŠä»¥ä¸Š
    file: "DEBUG"          # æ–‡ä»¶è®°å½•DEBUGåŠä»¥ä¸Š

# Langfuseå…¨å±€é…ç½®
langfuse:
  enabled: true
  host: env:LANGFUSE_HOST
  secret_key: env:LANGFUSE_SECRET_KEY
  public_key: env:LANGFUSE_PUBLIC_KEY
  debug: false
```

#### é…ç½®åŠ è½½å™¨

```python
# core/config_loader.py
import yaml
import os
from typing import Dict, Any, Optional
from pathlib import Path

class ConfigLoader:
    """ç»Ÿä¸€é…ç½®åŠ è½½å™¨"""

    def __init__(self, config_path: str = "config/settings.yaml"):
        self.config_path = Path(config_path)
        self._config = None

    def load(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        if self._config is not None:
            return self._config

        # åŠ è½½YAMLé…ç½®
        with open(self.config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        # è§£æç¯å¢ƒå˜é‡
        config = self._resolve_env_vars(config)

        # åº”ç”¨é»˜è®¤é…ç½®
        config = self._apply_defaults(config)

        self._config = config
        return config

    def _resolve_env_vars(self, config: Any) -> Any:
        """é€’å½’è§£æç¯å¢ƒå˜é‡"""
        if isinstance(config, dict):
            return {k: self._resolve_env_vars(v) for k, v in config.items()}
        elif isinstance(config, list):
            return [self._resolve_env_vars(item) for item in config]
        elif isinstance(config, str) and config.startswith("env:"):
            env_key = config.split(":", 1)[1]
            return os.getenv(env_key, "")
        return config

    def _apply_defaults(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨é»˜è®¤é…ç½®"""
        defaults = config.get("defaults", {})

        # ä»»åŠ¡é…ç½®åº”ç”¨é»˜è®¤
        for task_name, task_config in config.get("tasks", {}).items():
            for key, default_value in defaults.items():
                if key not in task_config:
                    task_config[key] = default_value

        return config
```

### 2. æ™ºèƒ½é‡è¯•æœºåˆ¶

#### RetryManagerè®¾è®¡

```python
# core/retry_manager.py
import asyncio
import time
import random
from typing import Optional, Dict, Any, Tuple
from enum import Enum
from openai import OpenAI
from utils.logger import get_logger
from core.exceptions import LLMCallError, ProviderError, NetworkError

class ErrorType(Enum):
    """é”™è¯¯ç±»å‹æšä¸¾"""
    NETWORK = "network"           # ç½‘ç»œé”™è¯¯
    TIMEOUT = "timeout"           # è¶…æ—¶é”™è¯¯
    API_ERROR = "api_error"       # APIè¿”å›é”™è¯¯
    RATE_LIMIT = "rate_limit"     # é€Ÿç‡é™åˆ¶
    PROVIDER_DOWN = "provider_down"  # ProvideræœåŠ¡ä¸å¯ç”¨
    UNKNOWN = "unknown"           # æœªçŸ¥é”™è¯¯

class RetryManager:
    """æ™ºèƒ½é‡è¯•ç®¡ç†å™¨

    é‡è¯•ç­–ç•¥ï¼ˆ3å±‚ï¼‰ï¼š
    1. åŒProviderå†…é‡è¯•ï¼šæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
    2. åˆ‡æ¢å¤‡ç”¨Providerï¼šæŒ‡æ•°é€€é¿é‡è¯•
    3. æœ€ç»ˆå¤±è´¥ï¼šè®°å½•è¯¦ç»†æ—¥å¿—å¹¶æŠ›å‡ºå¼‚å¸¸

    é”™è¯¯å¤„ç†ï¼š
    - Langfuseå¹³å°æ•…éšœï¼šç›´æ¥åˆ‡æ¢Provider
    - APIè°ƒç”¨å¤±è´¥ï¼šå…ˆé‡è¯•ï¼Œå†åˆ‡æ¢
    - ç½‘ç»œè¶…æ—¶ï¼šæŒ‡æ•°é€€é¿é‡è¯•
    - é€Ÿç‡é™åˆ¶ï¼šç­‰å¾…åé‡è¯•
    """

    def __init__(self, settings: Dict[str, Any]):
        self.settings = settings
        self.logger = get_logger(__name__)
        self.retry_policy = settings.get("retry_policy", {})

    async def call_with_retry(
        self,
        task_name: str,
        provider_type: str,
        messages: list,
        **kwargs
    ) -> str:
        """å¸¦é‡è¯•çš„LLMè°ƒç”¨

        Args:
            task_name: ä»»åŠ¡åç§°
            provider_type: Providerç±»å‹ï¼ˆtext/visionï¼‰
            messages: æ¶ˆæ¯åˆ—è¡¨
            **kwargs: é¢å¤–å‚æ•°

        Returns:
            LLMå“åº”æ–‡æœ¬

        Raises:
            LLMCallError: æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        """
        task_config = self.settings['tasks'][task_name]
        retry_config = task_config.get('retry', {})

        # é‡è¯•å‚æ•°
        max_retries = retry_config.get('max_retries', 3)
        base_delay = retry_config.get('base_delay', 1)
        max_delay = retry_config.get('max_delay', 60)
        enable_provider_switch = retry_config.get('enable_provider_switch', True)
        jitter = self.retry_policy.get('jitter', True)

        last_error = None
        error_history = []  # é”™è¯¯å†å²

        # éå†ä¸»å¤‡Provider
        for use_secondary in [False, True]:
            if use_secondary and not enable_provider_switch:
                break

            provider_info = self._get_provider_info(provider_type, use_secondary)
            provider_name = provider_info['name']

            self.logger.info(
                f"å¼€å§‹è°ƒç”¨Provider | ä»»åŠ¡={task_name} | "
                f"Provider={provider_name} | "
                f"ç±»å‹={'å¤‡ç”¨' if use_secondary else 'ä¸»'}"
            )

            # Providerå†…é‡è¯•
            for attempt in range(1, max_retries + 1):
                try:
                    # è®°å½•é‡è¯•ä¿¡æ¯
                    self.logger.info(
                        f"å°è¯•è°ƒç”¨ | ä»»åŠ¡={task_name} | "
                        f"Provider={provider_name} | "
                        f"å°è¯•={attempt}/{max_retries}"
                    )

                    # æ‰§è¡Œè°ƒç”¨
                    result = await self._call_provider(
                        provider_info,
                        messages,
                        task_config,
                        **kwargs
                    )

                    # æˆåŠŸè®°å½•
                    self.logger.info(
                        f"è°ƒç”¨æˆåŠŸ | ä»»åŠ¡={task_name} | "
                        f"Provider={provider_name} | "
                        f"å°è¯•={attempt}/{max_retries} | "
                        f"å“åº”é•¿åº¦={len(result)}"
                    )
                    return result

                except Exception as e:
                    last_error = e
                    error_type = self._classify_error(e)
                    error_history.append({
                        'attempt': attempt,
                        'provider': provider_name,
                        'error_type': error_type.value,
                        'error_msg': str(e)
                    })

                    # è®°å½•é”™è¯¯ä¿¡æ¯
                    self.logger.warning(
                        f"è°ƒç”¨å¤±è´¥ | ä»»åŠ¡={task_name} | "
                        f"Provider={provider_name} | "
                        f"å°è¯•={attempt}/{max_retries} | "
                        f"é”™è¯¯ç±»å‹={error_type.value} | "
                        f"é”™è¯¯ä¿¡æ¯={str(e)[:200]}"
                    )

                    # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ‡æ¢Provider
                    if use_secondary == False and enable_provider_switch and attempt == max_retries:
                        self.logger.info(
                            f"ä¸»Providerå¤±è´¥ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨Provider | ä»»åŠ¡={task_name}"
                        )
                        break  # åˆ‡æ¢åˆ°å¤‡ç”¨Provider

                    # è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿ
                    if attempt < max_retries:
                        delay = self._calculate_delay(attempt, base_delay, max_delay, jitter)
                        self.logger.info(
                            f"ç­‰å¾…{delay:.1f}ç§’åè¿›è¡Œç¬¬{attempt + 1}æ¬¡é‡è¯• | "
                            f"ä»»åŠ¡={task_name}"
                        )
                        await asyncio.sleep(delay)

        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        error_summary = self._format_error_history(error_history)
        self.logger.error(
            f"æ‰€æœ‰é‡è¯•å¤±è´¥ | ä»»åŠ¡={task_name} | "
            f"é”™è¯¯å†å²={error_summary}"
        )
        raise LLMCallError(
            task_name=task_name,
            error_history=error_history,
            last_error=str(last_error)
        )

    def _get_provider_info(self, provider_type: str, use_secondary: bool) -> Dict[str, Any]:
        """è·å–Providerä¿¡æ¯"""
        provider_key = "secondary" if use_secondary else "primary"
        provider_config = self.settings['api_providers'][provider_type][provider_key]

        return {
            'name': provider_config['name'],
            'base_url': provider_config['base_url'],
            'api_key': provider_config['api_key'],
            'model': provider_config['model'],
            'timeout_seconds': provider_config.get('timeout_seconds', 60),
        }

    async def _call_provider(
        self,
        provider_info: Dict[str, Any],
        messages: list,
        task_config: Dict[str, Any],
        **kwargs
    ) -> str:
        """è°ƒç”¨Provider"""
        client = OpenAI(
            api_key=provider_info['api_key'],
            base_url=provider_info['base_url'],
            timeout=provider_info['timeout_seconds'],
            max_retries=0  # é‡è¯•ç”±RetryManagerå¤„ç†
        )

        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            'model': provider_info['model'],
            'messages': messages,
            'temperature': task_config.get('temperature', 0.7),
            'top_p': task_config.get('top_p', 0.9),
        }

        # åˆå¹¶é¢å¤–å‚æ•°
        request_params.update(kwargs)

        # æ‰§è¡Œè°ƒç”¨
        response = await asyncio.to_thread(
            client.chat.completions.create,
            **request_params
        )

        return response.choices[0].message.content

    def _classify_error(self, error: Exception) -> ErrorType:
        """åˆ†ç±»é”™è¯¯ç±»å‹"""
        error_msg = str(error).lower()
        error_type = type(error).__name__

        if isinstance(error, (ConnectionError, OSError)):
            return ErrorType.NETWORK
        elif "timeout" in error_msg or "timed out" in error_msg:
            return ErrorType.TIMEOUT
        elif "rate limit" in error_msg or "429" in error_msg:
            return ErrorType.RATE_LIMIT
        elif "503" in error_msg or "502" in error_msg or "unavailable" in error_msg:
            return ErrorType.PROVIDER_DOWN
        elif "error" in error_msg and ("401" in error_msg or "403" in error_msg):
            return ErrorType.API_ERROR
        else:
            return ErrorType.UNKNOWN

    def _calculate_delay(
        self,
        attempt: int,
        base_delay: float,
        max_delay: float,
        jitter: bool
    ) -> float:
        """è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ï¼‰"""
        # æŒ‡æ•°é€€é¿ï¼š1, 2, 4, 8, ...
        delay = base_delay * (2 ** (attempt - 1))
        delay = min(delay, max_delay)

        # æ·»åŠ éšæœºæŠ–åŠ¨ï¼ˆÂ±10%ï¼‰
        if jitter:
            jitter_range = delay * 0.1
            delay += random.uniform(-jitter_range, jitter_range)

        return max(0, delay)

    def _format_error_history(self, error_history: list) -> str:
        """æ ¼å¼åŒ–é”™è¯¯å†å²"""
        if not error_history:
            return "æ— é”™è¯¯å†å²"

        summary = []
        for item in error_history:
            summary.append(
                f"{item['provider']}/å°è¯•{item['attempt']}}: "
                f"{item['error_type']} - {item['error_msg'][:50]}"
            )

        return "; ".join(summary)
```

### 3. æ—¥å¿—ç³»ç»Ÿä¼˜åŒ–

#### ä¸­æ–‡æ—¥å¿—æ ¼å¼åŒ–å™¨

```python
# utils/logger.py - å¢å¼ºç‰ˆ
import logging
import os
import sys
from logging.handlers import TimedRotatingFileHandler, RotatingFileHandler
from typing import Optional
from pathlib import Path

class ChineseFormatter(logging.Formatter):
    """ä¸­æ–‡æ—¥å¿—æ ¼å¼åŒ–å™¨"""

    LEVEL_MAP = {
        'DEBUG': 'è°ƒè¯•',
        'INFO': 'ä¿¡æ¯',
        'WARNING': 'è­¦å‘Š',
        'ERROR': 'é”™è¯¯',
        'CRITICAL': 'ä¸¥é‡',
        'FATAL': 'è‡´å‘½',
    }

    def __init__(self, fmt=None, datefmt=None):
        # é»˜è®¤æ ¼å¼
        if fmt is None:
            fmt = (
                "æ—¶é—´=%(asctime)s | "
                "çº§åˆ«=%(levelname)s | "
                "æ¨¡å—=%(name)s | "
                "è¡Œå·=%(lineno)d | "
                "å‡½æ•°=%(funcName)s | "
                "ä¿¡æ¯=%(message)s"
            )

        super().__init__(fmt=fmt, datefmt=datefmt or "%Y-%m-%d %H:%M:%S")

    def format(self, record):
        # è½¬æ¢çº§åˆ«åç§°ä¸ºä¸­æ–‡
        record.levelname = self.LEVEL_MAP.get(record.levelname, record.levelname)

        # æˆªæ–­è¿‡é•¿çš„æ¶ˆæ¯
        if hasattr(record, 'message') and len(record.message) > 1000:
            record.message = record.message[:1000] + "...(çœç•¥" + \
                           str(len(record.message) - 1000) + "å­—ç¬¦)"

        return super().format(record)

def get_logger(name: Optional[str] = None) -> logging.Logger:
    """è·å–å¸¦ä¸­æ–‡æ—¥å¿—çš„Logger

    Args:
        name: Loggeråç§°ï¼Œé»˜è®¤ä½¿ç”¨è°ƒç”¨æ¨¡å—å

    Returns:
        é…ç½®å¥½çš„Loggerå®ä¾‹
    """
    if not name:
        import inspect
        # è·å–è°ƒç”¨è€…çš„æ¨¡å—å
        frame = inspect.stack()[1]
        name = frame.frame.f_globals.get('__name__', 'unknown')

    logger = logging.getLogger(name)

    # å¦‚æœå·²ç»æœ‰å¤„ç†å™¨ï¼Œç›´æ¥è¿”å›
    if logger.handlers:
        return logger

    # è®¾ç½®çº§åˆ«
    logger.setLevel(logging.DEBUG)

    # åˆ›å»ºlogsç›®å½•
    log_dir = Path("runtime/logs")
    log_dir.mkdir(parents=True, exist_ok=True)

    # æ§åˆ¶å°å¤„ç†å™¨ï¼ˆINFOçº§åˆ«ï¼‰
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(ChineseFormatter())
    logger.addHandler(console_handler)

    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆDEBUGçº§åˆ«ï¼‰
    file_handler = TimedRotatingFileHandler(
        filename=log_dir / "llm.log",
        when="D",
        interval=1,
        backupCount=7,
        encoding="utf-8",
        utc=False
    )
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(ChineseFormatter())
    logger.addHandler(file_handler)

    # é”™è¯¯æ—¥å¿—å•ç‹¬æ–‡ä»¶
    error_handler = RotatingFileHandler(
        filename=log_dir / "error.log",
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding="utf-8"
    )
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(ChineseFormatter())
    logger.addHandler(error_handler)

    # é¿å…æ—¥å¿—å‘ä¸Šä¼ æ’­
    logger.propagate = False

    return logger

def log_function_call(func):
    """è®°å½•å‡½æ•°è°ƒç”¨çš„è£…é¥°å™¨

    è‡ªåŠ¨è®°å½•å‡½æ•°çš„è°ƒç”¨ã€å‚æ•°ã€è¿”å›å€¼å’Œå¼‚å¸¸
    """
    logger = get_logger(func.__module__)

    async def async_wrapper(*args, **kwargs):
        # è®°å½•è°ƒç”¨å¼€å§‹
        args_str = _truncate_args(str(args), 200)
        kwargs_str = _truncate_args(str(kwargs), 200)
        logger.info(
            f"â–¶ å¼€å§‹æ‰§è¡Œå‡½æ•° | {func.__name__} | "
            f"å‚æ•°args={args_str} | å‚æ•°kwargs={kwargs_str}"
        )

        start_time = time.time()
        try:
            # æ‰§è¡Œå‡½æ•°
            result = await func(*args, **kwargs)

            # è®°å½•æˆåŠŸ
            duration = time.time() - start_time
            result_str = _truncate_args(str(result), 500)
            logger.info(
                f"âœ” å‡½æ•°æ‰§è¡ŒæˆåŠŸ | {func.__name__} | "
                f"è€—æ—¶={duration:.3f}ç§’ | è¿”å›å€¼={result_str}"
            )
            return result

        except Exception as e:
            # è®°å½•å¼‚å¸¸
            duration = time.time() - start_time
            logger.error(
                f"âœ– å‡½æ•°æ‰§è¡Œå¤±è´¥ | {func.__name__} | "
                f"è€—æ—¶={duration:.3f}ç§’ | å¼‚å¸¸={type(e).__name__}: {str(e)}"
            )
            raise

    def sync_wrapper(*args, **kwargs):
        # è®°å½•è°ƒç”¨å¼€å§‹
        args_str = _truncate_args(str(args), 200)
        kwargs_str = _truncate_args(str(kwargs), 200)
        logger.info(
            f"â–¶ å¼€å§‹æ‰§è¡Œå‡½æ•° | {func.__name__} | "
            f"å‚æ•°args={args_str} | å‚æ•°kwargs={kwargs_str}"
        )

        start_time = time.time()
        try:
            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)

            # è®°å½•æˆåŠŸ
            duration = time.time() - start_time
            result_str = _truncate_args(str(result), 500)
            logger.info(
                f"âœ” å‡½æ•°æ‰§è¡ŒæˆåŠŸ | {func.__name__} | "
                f"è€—æ—¶={duration:.3f}ç§’ | è¿”å›å€¼={result_str}"
            )
            return result

        except Exception as e:
            # è®°å½•å¼‚å¸¸
            duration = time.time() - start_time
            logger.error(
                f"âœ– å‡½æ•°æ‰§è¡Œå¤±è´¥ | {func.__name__} | "
                f"è€—æ—¶={duration:.3f}ç§’ | å¼‚å¸¸={type(e).__name__}: {str(e)}"
            )
            raise

    # æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚æ­¥å‡½æ•°
    import inspect
    if inspect.iscoroutinefunction(func):
        return async_wrapper
    else:
        return sync_wrapper

def _truncate_args(text: str, max_len: int) -> str:
    """æˆªæ–­å‚æ•°å­—ç¬¦ä¸²"""
    if len(text) <= max_len:
        return text
    return text[:max_len] + "...(çœç•¥" + str(len(text) - max_len) + "å­—ç¬¦)"
```

### 4. JSONå¤„ç†é›†æˆ

```python
# utils/json_handler.py
import json
import re
from typing import Optional, Dict, Any, Union, List
from .json_repair import repair_json_output, is_valid_json
from .logger import get_logger

logger = get_logger(__name__)

class JSONHandler:
    """ç»Ÿä¸€JSONå¤„ç†å·¥å…·

    åŠŸèƒ½ï¼š
    1. è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤JSONæ ¼å¼é”™è¯¯
    2. æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼
    3. æ™ºèƒ½æå–JSONç‰‡æ®µ
    4. é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
    """

    @staticmethod
    def parse_response(
        text: str,
        enable_repair: bool = True,
        strict_mode: bool = False,
        return_raw_on_error: bool = True
    ) -> Optional[Union[Dict[str, Any], str]]:
        """è§£æLLMå“åº”ï¼Œæ”¯æŒè‡ªåŠ¨ä¿®å¤

        Args:
            text: LLMå“åº”æ–‡æœ¬
            enable_repair: æ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¿®å¤
            strict_mode: ä¸¥æ ¼æ¨¡å¼ï¼Œä¿®å¤å¤±è´¥æ—¶è¿”å›None
            return_raw_on_error: éä¸¥æ ¼æ¨¡å¼ä¸‹æ˜¯å¦è¿”å›åŸæ–‡

        Returns:
            è§£æåçš„JSONå¯¹è±¡ï¼Œæˆ–ä¿®å¤å¤±è´¥æ—¶çš„åŸå§‹æ–‡æœ¬/None
        """
        if not text or not text.strip():
            logger.warning("ç©ºå“åº”æ–‡æœ¬ï¼Œæ— æ³•è§£æJSON")
            return None

        original_text = text.strip()

        # è®°å½•åŸå§‹æ–‡æœ¬é•¿åº¦
        original_len = len(original_text)
        logger.debug(f"å¼€å§‹è§£æJSON | åŸæ–‡é•¿åº¦={original_len}")

        # æ­¥éª¤1: ç›´æ¥å°è¯•è§£æ
        try:
            result = json.loads(original_text)
            logger.info("ç›´æ¥è§£æJSONæˆåŠŸ")
            return result
        except json.JSONDecodeError:
            logger.info("ç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤")

        # æ­¥éª¤2: æå–JSONç‰‡æ®µ
        extracted = JSONHandler._extract_json_from_text(original_text)
        if extracted:
            logger.info(f"æå–åˆ°JSONç‰‡æ®µ | é•¿åº¦={len(extracted)}")
            text = extracted

        # æ­¥éª¤3: å°è¯•ä¿®å¤
        if enable_repair:
            logger.info("ä½¿ç”¨JSONä¿®å¤å·¥å…·")
            repaired = repair_json_output(text)

            if repaired is not None:
                logger.info("JSONä¿®å¤æˆåŠŸ")
                return repaired
            else:
                logger.warning("JSONä¿®å¤å¤±è´¥")

        # æ­¥éª¤4: ä¸¥æ ¼æ¨¡å¼å¤„ç†
        if strict_mode:
            logger.error("ä¸¥æ ¼æ¨¡å¼ä¸‹è§£æå¤±è´¥ï¼Œè¿”å›None")
            return None

        # æ­¥éª¤5: éä¸¥æ ¼æ¨¡å¼è¿”å›åŸæ–‡æˆ–æå–çš„æ–‡æœ¬
        result_text = extracted if extracted else original_text
        if return_raw_on_error:
            logger.warning("è¿”å›åŸå§‹æ–‡æœ¬ï¼ˆéä¸¥æ ¼æ¨¡å¼ï¼‰")
            return result_text
        else:
            logger.error("æ‹’ç»è¿”å›åŸå§‹æ–‡æœ¬")
            return None

    @staticmethod
    def _extract_json_from_text(text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–JSONç‰‡æ®µ

        ç­–ç•¥ï¼š
        1. å¯»æ‰¾ä»£ç å—æ ‡è®° ```json ... ```
        2. ä½¿ç”¨èŠ±æ‹¬å·å¹³è¡¡æå–JSONå¯¹è±¡
        3. å¯»æ‰¾ç¬¬ä¸€ä¸ª { æˆ– [
        """
        # ç­–ç•¥1: æå–ä»£ç å—ä¸­çš„JSON
        code_block_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
        match = re.search(code_block_pattern, text, re.DOTALL)
        if match:
            json_str = match.group(1)
            logger.debug("ä»ä»£ç å—ä¸­æå–JSON")
            return json_str

        # ç­–ç•¥2: å¯»æ‰¾ç¬¬ä¸€ä¸ª { æˆ– [
        start_idx = text.find('{')
        bracket_idx = text.find('[')

        # é€‰æ‹©æœ€æ—©å‡ºç°çš„æ ‡è®°
        if start_idx == -1 and bracket_idx == -1:
            return None

        if bracket_idx != -1 and (start_idx == -1 or bracket_idx < start_idx):
            start_char = '['
            end_char = ']'
            start_idx = bracket_idx
        else:
            start_char = '{'
            end_char = '}'
            start_idx = start_idx

        # ä½¿ç”¨æ‹¬å·å¹³è¡¡æ‰¾åˆ°å®Œæ•´ç»“æ„
        return JSONHandler._extract_balanced_braces(text, start_idx, start_char, end_char)

    @staticmethod
    def _extract_balanced_braces(
        text: str,
        start_idx: int,
        start_char: str,
        end_char: str
    ) -> Optional[str]:
        """æå–å¹³è¡¡çš„èŠ±æ‹¬å·æˆ–æ–¹æ‹¬å·å†…å®¹"""
        if start_idx == -1:
            return None

        brace_count = 0
        in_string = False
        escape_next = False

        for i in range(start_idx, len(text)):
            char = text[i]

            if escape_next:
                escape_next = False
                continue

            if char == '\\':
                escape_next = True
                continue

            if char == '"' and not escape_next:
                in_string = not in_string
                continue

            if not in_string:
                if char == start_char:
                    brace_count += 1
                elif char == end_char:
                    brace_count -= 1
                    if brace_count == 0:
                        return text[start_idx:i+1]

        return None

    @staticmethod
    def format_output(
        data: Any,
        output_format: str = "text",
        ensure_ascii: bool = False,
        indent: int = 2
    ) -> str:
        """æ ¼å¼åŒ–è¾“å‡º

        Args:
            data: è¦æ ¼å¼åŒ–çš„æ•°æ®
            output_format: è¾“å‡ºæ ¼å¼ (text|json|markdown|yaml)
            ensure_ascii: JSONä¸­æ˜¯å¦è½¬ä¹‰éASCIIå­—ç¬¦
            indent: JSONç¼©è¿›

        Returns:
            æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if output_format == "json":
            return json.dumps(data, ensure_ascii=ensure_ascii, indent=indent)
        elif output_format == "markdown":
            if isinstance(data, dict):
                return "```json\n" + json.dumps(data, ensure_ascii=ensure_ascii, indent=indent) + "\n```"
            else:
                return str(data)
        elif output_format == "yaml":
            try:
                import yaml
                return yaml.dump(data, allow_unicode=not ensure_ascii, indent=indent)
            except ImportError:
                logger.warning("YAMLåº“æœªå®‰è£…ï¼Œå›é€€åˆ°JSONæ ¼å¼")
                return json.dumps(data, ensure_ascii=ensure_ascii, indent=indent)
        else:  # text
            if isinstance(data, (dict, list)):
                return json.dumps(data, ensure_ascii=ensure_ascii, indent=indent)
            else:
                return str(data)

    @staticmethod
    def validate_json(data: Any) -> bool:
        """éªŒè¯æ•°æ®æ˜¯å¦ä¸ºæœ‰æ•ˆJSON"""
        try:
            json.dumps(data)
            return True
        except (TypeError, ValueError):
            return False

    @staticmethod
    def extract_json_paths(data: Dict[str, Any], prefix: str = "") -> List[str]:
        """æå–JSONä¸­çš„æ‰€æœ‰è·¯å¾„

        ä¾‹å¦‚: {'a': {'b': 1}} -> ['a', 'a.b']
        """
        paths = []

        def _extract(obj: Any, current_prefix: str):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    new_prefix = f"{current_prefix}.{key}" if current_prefix else key
                    _extract(value, new_prefix)
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    new_prefix = f"{current_prefix}[{i}]"
                    _extract(item, new_prefix)
            else:
                paths.append(current_prefix)

        _extract(data, prefix)
        return paths
```

### 5. ç»Ÿä¸€LLMå®¢æˆ·ç«¯

```python
# core/llm_client.py
import asyncio
from typing import Optional, Dict, Any, Union, List, AsyncGenerator
from pathlib import Path

from openai import OpenAI
from langfuse.openai import OpenAI as LangfuseOpenAI
from langfuse.decorators import observe

from .config_loader import ConfigLoader
from .retry_manager import RetryManager
from ..utils.logger import get_logger, log_function_call
from ..utils.json_handler import JSONHandler
from .exceptions import LLMCallError, ConfigurationError

class UnifiedLLMClient:
    """ç»Ÿä¸€LLMå®¢æˆ·ç«¯

    ç‰¹æ€§ï¼š
    1. ç»Ÿä¸€é…ç½®ç®¡ç†
    2. æ™ºèƒ½é‡è¯•æœºåˆ¶
    3. å¤šæ ¼å¼æç¤ºè¯æ”¯æŒ
    4. Langfuseç›‘æ§é›†æˆ
    5. JSONæ™ºèƒ½ä¿®å¤
    6. æµå¼è°ƒç”¨æ”¯æŒ
    """

    def __init__(self, config_path: str = "config/settings.yaml"):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.logger = get_logger(__name__)
        self.config_loader = ConfigLoader(config_path)
        self.settings = self.config_loader.load()
        self.retry_manager = RetryManager(self.settings)
        self.json_handler = JSONHandler()

        # éªŒè¯é…ç½®
        self._validate_config()

        self.logger.info("ç»Ÿä¸€LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")

    def _validate_config(self):
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        required_sections = ['api_providers', 'tasks']

        for section in required_sections:
            if section not in self.settings:
                raise ConfigurationError(f"é…ç½®ç¼ºå°‘å¿…éœ€éƒ¨åˆ†: {section}")

        # éªŒè¯ä»»åŠ¡é…ç½®
        for task_name, task_config in self.settings['tasks'].items():
            if 'provider_type' not in task_config:
                raise ConfigurationError(f"ä»»åŠ¡ {task_name} ç¼ºå°‘ provider_type é…ç½®")

            if 'prompt' not in task_config:
                raise ConfigurationError(f"ä»»åŠ¡ {task_name} ç¼ºå°‘ prompt é…ç½®")

            self.logger.debug(f"ä»»åŠ¡é…ç½®éªŒè¯é€šè¿‡: {task_name}")

    @log_function_call
    async def call(
        self,
        task_name: str,
        user_prompt: Union[str, List[Dict[str, Any]]],
        **kwargs
    ) -> str:
        """ç»Ÿä¸€è°ƒç”¨æ¥å£

        Args:
            task_name: ä»»åŠ¡åç§°ï¼ˆä»é…ç½®ä¸­è¯»å–ï¼‰
            user_prompt: ç”¨æˆ·æç¤ºè¯ï¼ˆå­—ç¬¦ä¸²æˆ–æ¶ˆæ¯åˆ—è¡¨ï¼‰
            **kwargs: è¦†ç›–é…ç½®çš„å‚æ•°

        Returns:
            LLMå“åº”æ–‡æœ¬

        Raises:
            LLMCallError: è°ƒç”¨å¤±è´¥
        """
        self.logger.info(f"å¼€å§‹LLMè°ƒç”¨ | ä»»åŠ¡={task_name}")

        # è·å–ä»»åŠ¡é…ç½®
        if task_name not in self.settings['tasks']:
            raise ConfigurationError(f"ä»»åŠ¡æœªé…ç½®: {task_name}")

        task_config = self.settings['tasks'][task_name].copy()

        # åˆå¹¶è¦†ç›–å‚æ•°
        task_config.update(kwargs)

        # æ„å»ºæ¶ˆæ¯
        messages = self._build_messages(task_name, user_prompt, task_config)

        # è®°å½•æ¶ˆæ¯ç»Ÿè®¡
        self.logger.info(
            f"æ„å»ºæ¶ˆæ¯å®Œæˆ | ä»»åŠ¡={task_name} | "
            f"æ¶ˆæ¯æ¡æ•°={len(messages)}"
        )

        # å¸¦é‡è¯•çš„è°ƒç”¨
        try:
            # å¦‚æœå¯ç”¨Langfuseï¼Œä½¿ç”¨è§‚å¯Ÿè£…é¥°å™¨
            if task_config.get('langfuse', {}).get('enabled', False):
                result = await self._call_with_langfuse(task_name, messages, task_config)
            else:
                result = await self.retry_manager.call_with_retry(
                    task_name=task_name,
                    provider_type=task_config['provider_type'],
                    messages=messages
                )
        except Exception as e:
            self.logger.error(f"LLMè°ƒç”¨å¤±è´¥ | ä»»åŠ¡={task_name} | é”™è¯¯={str(e)}")
            raise

        # JSONä¿®å¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if task_config.get('json_repair', {}).get('enabled', False):
            self.logger.info("å¯ç”¨JSONä¿®å¤")
            parsed = self.json_handler.parse_response(
                result,
                enable_repair=True,
                strict_mode=task_config.get('json_repair', {}).get('strict_mode', False)
            )

            if isinstance(parsed, dict):
                # å¦‚æœä¿®å¤æˆåŠŸä¸”æ˜¯JSONå¯¹è±¡ï¼Œæ ¼å¼åŒ–è¾“å‡º
                output_format = task_config.get('json_repair', {}).get('output_format', 'text')
                result = self.json_handler.format_output(parsed, output_format)

        self.logger.info(f"LLMè°ƒç”¨å®Œæˆ | ä»»åŠ¡={task_name} | å“åº”é•¿åº¦={len(result)}")
        return result

    @observe()
    async def _call_with_langfuse(
        self,
        task_name: str,
        messages: List[Dict[str, Any]],
        task_config: Dict[str, Any]
    ) -> str:
        """ä½¿ç”¨Langfuseè°ƒç”¨ï¼ˆå¸¦ç›‘æ§ï¼‰"""
        langfuse_config = task_config['langfuse']

        # è·å–Providerä¿¡æ¯
        provider_type = task_config['provider_type']
        provider_info = self.retry_manager._get_provider_info(provider_type, False)

        # æ„å»ºLangfuseå®¢æˆ·ç«¯
        client = LangfuseOpenAI(
            api_key=provider_info['api_key'],
            base_url=provider_info['base_url']
        )

        # æ‰§è¡Œè°ƒç”¨
        completion = client.chat.completions.create(
            model=provider_info['model'],
            name=langfuse_config.get('name', task_name),
            messages=messages,
            temperature=task_config.get('temperature', 0.7),
            top_p=task_config.get('top_p', 0.9),
            tags=langfuse_config.get('tags', []),
            metadata=langfuse_config.get('metadata', {})
        )

        return completion.choices[0].message.content

    @log_function_call
    async def stream_call(
        self,
        task_name: str,
        user_prompt: Union[str, List[Dict[str, Any]]],
        **kwargs
    ) -> AsyncGenerator[str, None]:
        """æµå¼è°ƒç”¨æ¥å£

        Args:
            task_name: ä»»åŠ¡åç§°
            user_prompt: ç”¨æˆ·æç¤ºè¯
            **kwargs: è¦†ç›–å‚æ•°

        Yields:
            æµå¼å“åº”ç‰‡æ®µ
        """
        self.logger.info(f"å¼€å§‹æµå¼è°ƒç”¨ | ä»»åŠ¡={task_name}")

        # è·å–ä»»åŠ¡é…ç½®
        task_config = self.settings['tasks'][task_name].copy()
        task_config.update(kwargs)

        # æ„å»ºæ¶ˆæ¯
        messages = self._build_messages(task_name, user_prompt, task_config)

        # è·å–Providerä¿¡æ¯
        provider_type = task_config['provider_type']
        provider_info = self.retry_manager._get_provider_info(provider_type, False)

        # åˆ›å»ºå®¢æˆ·ç«¯
        client = OpenAI(
            api_key=provider_info['api_key'],
            base_url=provider_info['base_url'],
            timeout=provider_info['timeout_seconds']
        )

        # æ‰§è¡Œæµå¼è°ƒç”¨
        stream = await asyncio.to_thread(
            client.chat.completions.create,
            model=provider_info['model'],
            messages=messages,
            temperature=task_config.get('temperature', 0.7),
            top_p=task_config.get('top_p', 0.9),
            stream=True
        )

        # é€å—è¾“å‡º
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                yield chunk.choices[0].delta.content

        self.logger.info(f"æµå¼è°ƒç”¨å®Œæˆ | ä»»åŠ¡={task_name}")

    def _build_messages(
        self,
        task_name: str,
        user_prompt: Union[str, List[Dict[str, Any]]],
        task_config: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æ„å»ºæ¶ˆæ¯æ•°ç»„

        Args:
            task_name: ä»»åŠ¡åç§°
            user_prompt: ç”¨æˆ·æç¤ºè¯
            task_config: ä»»åŠ¡é…ç½®

        Returns:
            æ¶ˆæ¯åˆ—è¡¨
        """
        messages = []

        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
        system_prompt = self._load_prompt(task_config['prompt'])
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # æ·»åŠ ç”¨æˆ·æç¤ºè¯
        if isinstance(user_prompt, str):
            messages.append({"role": "user", "content": user_prompt})
        elif isinstance(user_prompt, list):
            messages.extend(user_prompt)
        else:
            raise ValueError("user_prompt å¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ–æ¶ˆæ¯åˆ—è¡¨")

        return messages

    def _load_prompt(self, prompt_config: Dict[str, Any]) -> Optional[str]:
        """åŠ è½½æç¤ºè¯ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰

        Args:
            prompt_config: æç¤ºè¯é…ç½®

        Returns:
            æç¤ºè¯å†…å®¹
        """
        prompt_type = prompt_config['type']

        if prompt_type == 'md':
            # ä».mdæ–‡ä»¶åŠ è½½
            prompt_path = Path(prompt_config['source'])
            if not prompt_path.exists():
                self.logger.warning(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_path}")
                return None

            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()

        elif prompt_type == 'langfuse':
            # ä»LangfuseåŠ è½½
            from langfuse import Langfuse
            langfuse_name = prompt_config.get('langfuse_name')

            try:
                langfuse = Langfuse()
                prompt = langfuse.get_prompt(langfuse_name)
                self.logger.info(f"ä»LangfuseåŠ è½½æç¤ºè¯: {langfuse_name}")
                return prompt.compile()
            except Exception as e:
                self.logger.error(f"ä»LangfuseåŠ è½½æç¤ºè¯å¤±è´¥: {str(e)}")
                return None

        elif prompt_type == 'dict':
            # ç›´æ¥ä½¿ç”¨å­—å…¸æ ¼å¼
            content = prompt_config.get('content', '')
            if isinstance(content, dict):
                return content.get('content', '')
            return content

        else:
            self.logger.warning(f"æœªçŸ¥çš„æç¤ºè¯ç±»å‹: {prompt_type}")
            return None

    def get_task_config(self, task_name: str) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡é…ç½®

        Args:
            task_name: ä»»åŠ¡åç§°

        Returns:
            ä»»åŠ¡é…ç½®
        """
        if task_name not in self.settings['tasks']:
            raise ConfigurationError(f"ä»»åŠ¡æœªé…ç½®: {task_name}")

        return self.settings['tasks'][task_name].copy()

    def list_tasks(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡åç§°"""
        return list(self.settings.get('tasks', {}).keys())

    def reload_config(self):
        """é‡æ–°åŠ è½½é…ç½®"""
        self.config_loader._config = None  # æ¸…ç©ºç¼“å­˜
        self.settings = self.config_loader.load()
        self.logger.info("é…ç½®é‡æ–°åŠ è½½å®Œæˆ")

    async def batch_call(
        self,
        requests: List[Dict[str, Any]],
        max_concurrent: int = 5
    ) -> List[Optional[str]]:
        """æ‰¹é‡è°ƒç”¨

        Args:
            requests: è¯·æ±‚åˆ—è¡¨ [{'task_name': str, 'user_prompt': str}, ...]
            max_concurrent: æœ€å¤§å¹¶å‘æ•°

        Returns:
            å“åº”åˆ—è¡¨
        """
        self.logger.info(f"å¼€å§‹æ‰¹é‡è°ƒç”¨ | è¯·æ±‚æ•°={len(requests)} | å¹¶å‘æ•°={max_concurrent}")

        semaphore = asyncio.Semaphore(max_concurrent)

        async def single_call(request):
            async with semaphore:
                try:
                    return await self.call(**request)
                except Exception as e:
                    self.logger.error(f"æ‰¹é‡è°ƒç”¨å•é¡¹å¤±è´¥ | ä»»åŠ¡={request.get('task_name')} | é”™è¯¯={str(e)}")
                    return None

        tasks = [single_call(req) for req in requests]
        results = await asyncio.gather(*tasks)

        success_count = sum(1 for r in results if r is not None)
        self.logger.info(
            f"æ‰¹é‡è°ƒç”¨å®Œæˆ | æ€»æ•°={len(requests)} | æˆåŠŸ={success_count} | å¤±è´¥={len(requests) - success_count}"
        )

        return results
```

### 6. è‡ªå®šä¹‰å¼‚å¸¸

```python
# core/exceptions.py
class LLMError(Exception):
    """LLMè°ƒç”¨åŸºç±»å¼‚å¸¸"""
    pass

class LLMCallError(LLMError):
    """LLMè°ƒç”¨å¤±è´¥å¼‚å¸¸

    Attributes:
        task_name: ä»»åŠ¡åç§°
        error_history: é”™è¯¯å†å²
        last_error: æœ€åé”™è¯¯
    """

    def __init__(self, task_name: str, error_history: list, last_error: str):
        self.task_name = task_name
        self.error_history = error_history
        self.last_error = last_error

        error_count = len(error_history)
        super().__init__(
            f"ä»»åŠ¡ {task_name} è°ƒç”¨å¤±è´¥ (å°è¯•{error_count}æ¬¡): {last_error}"
        )

class ConfigurationError(LLMError):
    """é…ç½®é”™è¯¯"""
    pass

class ProviderError(LLMError):
    """Provideré”™è¯¯"""
    pass

class NetworkError(LLMError):
    """ç½‘ç»œé”™è¯¯"""
    pass

class RateLimitError(LLMError):
    """é€Ÿç‡é™åˆ¶é”™è¯¯"""
    pass

class TimeoutError(LLMError):
    """è¶…æ—¶é”™è¯¯"""
    pass
```

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€è°ƒç”¨

```python
# examples/basic_usage.py
import asyncio
from core.llm_client import UnifiedLLMClient

async def main():
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = UnifiedLLMClient()

    # 1. ç®€å•è°ƒç”¨
    result = await client.call(
        task_name="fact_description",
        user_prompt="æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"
    )
    print(f"ç»“æœ: {result}")

    # 2. è¦†ç›–é…ç½®
    result = await client.call(
        task_name="fact_description",
        user_prompt="ç”¨JSONæ ¼å¼è¿”å›ç»“æœ",
        temperature=0.5,
        json_repair_enabled=True
    )
    print(f"ç»“æœ: {result}")

    # 3. å¤šè½®å¯¹è¯
    messages = [
        {"role": "user", "content": "è¯·å¸®æˆ‘å†™ä¸€ä¸ªè®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‡½æ•°"},
        {"role": "assistant", "content": "å¥½çš„ï¼Œè¯·é—®æ‚¨å¸Œæœ›ç”¨å“ªç§è¯­è¨€å®ç°ï¼Ÿ"},
        {"role": "user", "content": "Python"}
    ]
    result = await client.call(
        task_name="coding",
        user_prompt=messages
    )
    print(f"ç»“æœ: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

### æµå¼è°ƒç”¨

```python
# examples/streaming.py
import asyncio
from core.llm_client import UnifiedLLMClient

async def streaming_example():
    client = UnifiedLLMClient()

    # æµå¼è¾“å‡º
    print("æµå¼å“åº”: ", end="", flush=True)
    async for chunk in client.stream_call(
        task_name="fact_description",
        user_prompt="å†™ä¸€ç¯‡å…³äºäººå·¥æ™ºèƒ½çš„é•¿æ–‡ç« "
    ):
        print(chunk, end="", flush=True)
    print()  # æ¢è¡Œ

asyncio.run(streaming_example())
```

### æ‰¹é‡è°ƒç”¨

```python
# examples/batch_call.py
import asyncio
from core.llm_client import UnifiedLLMClient

async def batch_example():
    client = UnifiedLLMClient()

    # æ‰¹é‡è¯·æ±‚
    requests = [
        {"task_name": "fact_description", "user_prompt": "å›¾ç‰‡1"},
        {"task_name": "fact_description", "user_prompt": "å›¾ç‰‡2"},
        {"task_name": "fact_description", "user_prompt": "å›¾ç‰‡3"},
    ]

    results = await client.batch_call(requests, max_concurrent=3)

    for i, result in enumerate(results):
        print(f"è¯·æ±‚ {i+1}: {result}")

asyncio.run(batch_example())
```

### è‡ªå®šä¹‰é…ç½®

```python
# examples/custom_config.py
import asyncio
from core.llm_client import UnifiedLLMClient

async def custom_config_example():
    # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
    client = UnifiedLLMClient(config_path="config/my_settings.yaml")

    # è·å–ä»»åŠ¡é…ç½®
    config = client.get_task_config("fact_description")
    print(f"ä»»åŠ¡é…ç½®: {config}")

    # åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
    tasks = client.list_tasks()
    print(f"å¯ç”¨ä»»åŠ¡: {tasks}")

    # åŠ¨æ€ä¿®æ”¹é…ç½®
    result = await client.call(
        task_name="fact_description",
        user_prompt="æè¿°å›¾ç‰‡",
        temperature=0.3,  # è¦†ç›–é…ç½®
        max_tokens=1000
    )
    print(f"ç»“æœ: {result}")

asyncio.run(custom_config_example())
```

### é”™è¯¯å¤„ç†

```python
# examples/error_handling.py
import asyncio
from core.llm_client import UnifiedLLMClient
from core.exceptions import LLMCallError, ConfigurationError

async def error_handling_example():
    client = UnifiedLLMClient()

    try:
        result = await client.call(
            task_name="nonexistent_task",  # ä¸å­˜åœ¨çš„ä»»åŠ¡
            user_prompt="æµ‹è¯•"
        )
    except ConfigurationError as e:
        print(f"é…ç½®é”™è¯¯: {e}")

    try:
        # å°è¯•ä¸€ä¸ªä¼šå¤±è´¥çš„è°ƒç”¨
        result = await client.call(
            task_name="fact_description",
            user_prompt="æµ‹è¯•"
        )
    except LLMCallError as e:
        print(f"è°ƒç”¨å¤±è´¥: {e}")
        print(f"é”™è¯¯å†å²: {e.error_history}")

asyncio.run(error_handling_example())
```

---

## ğŸ“… å®æ–½è®¡åˆ’

### é˜¶æ®µ1ï¼šåŸºç¡€è®¾æ–½æ­å»º (2å¤©)

#### Day 1: é…ç½®ç³»ç»Ÿå’Œæ—¥å¿—ç³»ç»Ÿ

**ä¸Šåˆ** (4å°æ—¶):
- [ ] åˆ›å»º `config/settings.yaml` ç»Ÿä¸€é…ç½®æ–‡ä»¶
- [ ] è¿ç§»ç°æœ‰é…ç½®é¡¹ï¼ˆ`settings.yaml` â†’ `settings.yaml`ï¼‰
- [ ] å®ç° `core/config_loader.py` é…ç½®åŠ è½½å™¨
- [ ] æ·»åŠ é…ç½®éªŒè¯é€»è¾‘

**ä¸‹åˆ** (4å°æ—¶):
- [ ] é‡æ„ `utils/logger.py` â†’ ä¸­æ–‡æ—¥å¿—æ ¼å¼
- [ ] å®ç° `ChineseFormatter` æ ¼å¼åŒ–å™¨
- [ ] æ·»åŠ æ—¥å¿—è½®è½¬å’Œåˆ†çº§å­˜å‚¨
- [ ] å®ç° `log_function_call` è£…é¥°å™¨

#### Day 2: JSONå¤„ç†å’Œå¼‚å¸¸ç³»ç»Ÿ

**ä¸Šåˆ** (4å°æ—¶):
- [ ] åˆ›å»º `utils/json_handler.py` JSONå¤„ç†å·¥å…·
- [ ] å°è£… `json_repair.py` ç°æœ‰åŠŸèƒ½
- [ ] æ·»åŠ JSONæå–å’Œä¿®å¤åŠŸèƒ½
- [ ] å®ç°å¤šç§è¾“å‡ºæ ¼å¼æ”¯æŒ

**ä¸‹åˆ** (4å°æ—¶):
- [ ] åˆ›å»º `core/exceptions.py` è‡ªå®šä¹‰å¼‚å¸¸
- [ ] å®šä¹‰é”™è¯¯ç±»å‹å’Œå¤„ç†ç­–ç•¥
- [ ] æ·»åŠ å¼‚å¸¸ä¸Šä¸‹æ–‡ä¿¡æ¯
- [ ] ç¼–å†™å¼‚å¸¸ä½¿ç”¨æ–‡æ¡£

### é˜¶æ®µ2ï¼šæ ¸å¿ƒæ¨¡å—å¼€å‘ (3å¤©)

#### Day 1: RetryManager

**ä¸Šåˆ** (4å°æ—¶):
- [ ] å®ç° `core/retry_manager.py` æ ¸å¿ƒé€»è¾‘
- [ ] å®ç°æŒ‡æ•°é€€é¿ç®—æ³•
- [ ] å®ç°Provideråˆ‡æ¢æœºåˆ¶
- [ ] æ·»åŠ é”™è¯¯åˆ†ç±»é€»è¾‘

**ä¸‹åˆ** (4å°æ—¶):
- [ ] é›†æˆé…ç½®ç³»ç»Ÿ
- [ ] æ·»åŠ è¯¦ç»†æ—¥å¿—è®°å½•
- [ ] å®ç°æŠ–åŠ¨ç®—æ³•
- [ ] å•å…ƒæµ‹è¯•ç¼–å†™

#### Day 2: UnifiedLLMClient

**ä¸Šåˆ** (4å°æ—¶):
- [ ] åˆ›å»º `core/llm_client.py` ä¸»ç±»
- [ ] å®ç°åŸºç¡€è°ƒç”¨é€»è¾‘
- [ ] é›†æˆRetryManager
- [ ] å®ç°æç¤ºè¯åŠ è½½ï¼ˆæ”¯æŒ.mdï¼‰

**ä¸‹åˆ** (4å°æ—¶):
- [ ] å®ç°Langfuseé›†æˆ
- [ ] æ·»åŠ JSONä¿®å¤é›†æˆ
- [ ] å®ç°å¤šæ ¼å¼æ”¯æŒï¼ˆ.md/langfuse/dictï¼‰

#### Day 3: é«˜çº§åŠŸèƒ½

**ä¸Šåˆ** (4å°æ—¶):
- [ ] å®ç°æµå¼è°ƒç”¨ (`stream_call`)
- [ ] å®ç°æ‰¹é‡è°ƒç”¨ (`batch_call`)
- [ ] æ·»åŠ å¹¶å‘æ§åˆ¶
- [ ] å®ç°ä»»åŠ¡é…ç½®åŠ¨æ€ä¿®æ”¹

**ä¸‹åˆ** (4å°æ—¶):
- [ ] æ€§èƒ½ä¼˜åŒ–ï¼ˆå¼‚æ­¥å¤„ç†ï¼‰
- [ ] å†…å­˜ä¼˜åŒ–ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
- [ ] é”™è¯¯æ¢å¤æœºåˆ¶
- [ ] ç›‘æ§æŒ‡æ ‡æ”¶é›†

### é˜¶æ®µ3ï¼šæç¤ºè¯è¿ç§» (1å¤©)

**ä¸Šåˆ** (4å°æ—¶):
- [ ] è¿ç§» `prompt/sys_prompt.py` â†’ `prompts/*.md`
- [ ] åˆ›å»º `prompts/` ç›®å½•
- [ ] å°†dictæ ¼å¼è½¬æ¢ä¸º.mdæ ¼å¼
- [ ] æ›´æ–°é…ç½®å¼•ç”¨è·¯å¾„

**ä¸‹åˆ** (4å°æ—¶):
- [ ] æµ‹è¯•æ‰€æœ‰æç¤ºè¯åŠ è½½
- [ ] éªŒè¯æç¤ºè¯æ ¼å¼å…¼å®¹æ€§
- [ ] æ›´æ–°æ–‡æ¡£å’Œç¤ºä¾‹
- [ ] æ¸…ç†æ—§æ–‡ä»¶

### é˜¶æ®µ4ï¼šæµ‹è¯•ä¸ä¼˜åŒ– (2å¤©)

#### Day 1: å•å…ƒæµ‹è¯•

**ä¸Šåˆ** (4å°æ—¶):
- [ ] ç¼–å†™é…ç½®åŠ è½½æµ‹è¯•
- [ ] ç¼–å†™é‡è¯•æœºåˆ¶æµ‹è¯•
- [ ] ç¼–å†™JSONå¤„ç†æµ‹è¯•
- [ ] ç¼–å†™æ—¥å¿—ç³»ç»Ÿæµ‹è¯•

**ä¸‹åˆ** (4å°æ—¶):
- [ ] ç¼–å†™LLMå®¢æˆ·ç«¯æµ‹è¯•
- [ ] ç¼–å†™æç¤ºè¯åŠ è½½æµ‹è¯•
- [ ] ç¼–å†™å¼‚å¸¸å¤„ç†æµ‹è¯•
- [ ] æµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°80%

#### Day 2: é›†æˆæµ‹è¯•

**ä¸Šåˆ** (4å°æ—¶):
- [ ] ç«¯åˆ°ç«¯è°ƒç”¨æµ‹è¯•
- [ ] ä¸»å¤‡Provideråˆ‡æ¢æµ‹è¯•
- [ ] æµå¼è°ƒç”¨æµ‹è¯•
- [ ] æ‰¹é‡è°ƒç”¨æµ‹è¯•

**ä¸‹åˆ** (4å°æ—¶):
- [ ] æ€§èƒ½æµ‹è¯•ï¼ˆå¹¶å‘ã€å»¶è¿Ÿï¼‰
- [ ] æ•…éšœæ¢å¤æµ‹è¯•
- [ ] å†…å­˜æ³„æ¼æµ‹è¯•
- [ ] æ–‡æ¡£å®Œå–„

### é˜¶æ®µ5ï¼šå‘åå…¼å®¹ä¸éƒ¨ç½² (1å¤©)

**ä¸Šåˆ** (4å°æ—¶):
- [ ] ä¿ç•™ `langfuse_llm.py` æ¥å£ï¼ˆæ ‡è®°deprecatedï¼‰
- [ ] ä¿ç•™ `llm_api.py` æ¥å£ï¼ˆæ ‡è®°deprecatedï¼‰
- [ ] æ·»åŠ è¿ç§»å·¥å…·å’Œè„šæœ¬
- [ ] æ›´æ–°READMEæ–‡æ¡£

**ä¸‹åˆ** (4å°æ—¶):
- [ ] ç¼–å†™è¿ç§»æŒ‡å—
- [ ] åˆ›å»ºä½¿ç”¨ç¤ºä¾‹
- [ ] æ·»åŠ æœ€ä½³å®è·µæ–‡æ¡£
- [ ] æœ€ç»ˆä»£ç å®¡æŸ¥

---

## ğŸ“Š é¡¹ç›®é‡Œç¨‹ç¢‘

### é‡Œç¨‹ç¢‘1: åŸºç¡€è®¾æ–½å®Œæˆ
- ç»Ÿä¸€é…ç½®ç³»ç»Ÿ
- ä¸­æ–‡æ—¥å¿—ç³»ç»Ÿ
- JSONå¤„ç†å·¥å…·
- è‡ªå®šä¹‰å¼‚å¸¸ç³»ç»Ÿ

**äº¤ä»˜ç‰©**:
- `config/settings.yaml`
- `core/config_loader.py`
- `utils/logger.py` (å¢å¼ºç‰ˆ)
- `utils/json_handler.py`
- `core/exceptions.py`

### é‡Œç¨‹ç¢‘2: æ ¸å¿ƒåŠŸèƒ½å®Œæˆ
- RetryManageræ™ºèƒ½é‡è¯•
- UnifiedLLMClientç»Ÿä¸€å®¢æˆ·ç«¯
- å¤šæ ¼å¼æç¤ºè¯æ”¯æŒ
- Langfuseç›‘æ§é›†æˆ

**äº¤ä»˜ç‰©**:
- `core/retry_manager.py`
- `core/llm_client.py`
- `prompts/*.md` (è¿ç§»åçš„æç¤ºè¯)

### é‡Œç¨‹ç¢‘3: æµ‹è¯•å®Œæˆ
- å•å…ƒæµ‹è¯•å¥—ä»¶
- é›†æˆæµ‹è¯•å¥—ä»¶
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- æ•…éšœæ¢å¤æµ‹è¯•

**äº¤ä»˜ç‰©**:
- `tests/` ç›®å½•
- æµ‹è¯•æŠ¥å‘Š
- æ€§èƒ½åˆ†ææŠ¥å‘Š

### é‡Œç¨‹ç¢‘4: å‘å¸ƒå°±ç»ª
- å‘åå…¼å®¹æ€§ä¿è¯
- å®Œæ•´æ–‡æ¡£
- è¿ç§»å·¥å…·
- ç¤ºä¾‹ä»£ç 

**äº¤ä»˜ç‰©**:
- å®Œæ•´é‡æ„çš„ä»£ç åº“
- è¿ç§»æŒ‡å—
- APIæ–‡æ¡£
- ä½¿ç”¨ç¤ºä¾‹

---

## âš¡ æ€§èƒ½é¢„æœŸ

### é‡è¯•æœºåˆ¶æ€§èƒ½
- **å»¶è¿Ÿ**: æŒ‡æ•°é€€é¿ç®—æ³•ï¼Œå¹³å‡å»¶è¿Ÿæ¯”å›ºå®šå»¶è¿Ÿé™ä½30%
- **æˆåŠŸç‡**: ä¸»å¤‡Provideråˆ‡æ¢ï¼ŒæˆåŠŸç‡æå‡è‡³99.5%
- **èµ„æºæ¶ˆè€—**: ä¼˜åŒ–åèµ„æºæ¶ˆè€—é™ä½20%

### æ—¥å¿—ç³»ç»Ÿæ€§èƒ½
- **å†™å…¥é€Ÿåº¦**: å¼‚æ­¥æ—¥å¿—å†™å…¥ï¼Œæ€§èƒ½æå‡50%
- **å­˜å‚¨æ•ˆç‡**: æŒ‰æ—¥æœŸè½®è½¬ï¼Œå­˜å‚¨æ•ˆç‡æå‡40%
- **æŸ¥è¯¢æ•ˆç‡**: ä¸­æ–‡æ—¥å¿—æ ¼å¼ï¼ŒæŸ¥è¯¢æ•ˆç‡æå‡60%

### JSONå¤„ç†æ€§èƒ½
- **ä¿®å¤æˆåŠŸç‡**: æ™ºèƒ½æ£€æµ‹ï¼Œä¿®å¤æˆåŠŸç‡è¾¾95%
- **å¤„ç†é€Ÿåº¦**: ä¼˜åŒ–ç®—æ³•ï¼Œé€Ÿåº¦æå‡30%
- **å‡†ç¡®ç‡**: å¤šç­–ç•¥æå–ï¼Œå‡†ç¡®ç‡è¾¾99%

---

## ğŸ” è´¨é‡ä¿è¯

### ä»£ç è´¨é‡
- **ç±»å‹æ³¨è§£**: 100%è¦†ç›–
- **æ–‡æ¡£å­—ç¬¦ä¸²**: 100%è¦†ç›–
- **æµ‹è¯•è¦†ç›–ç‡**: â‰¥80%
- **ä»£ç è§„èŒƒ**: ç¬¦åˆPEP 8

### æ–‡æ¡£è´¨é‡
- **APIæ–‡æ¡£**: å®Œæ•´æ¸…æ™°
- **ä½¿ç”¨ç¤ºä¾‹**: ä¸°å¯Œå®ç”¨
- **æœ€ä½³å®è·µ**: è¯¦ç»†æŒ‡å¯¼
- **æ•…éšœæ’é™¤**: å®Œæ•´æŒ‡å—

### å¯é æ€§
- **å¼‚å¸¸å¤„ç†**: å…¨è¦†ç›–
- **è¾¹ç•Œæ¡ä»¶**: å…¨æµ‹è¯•
- **å¹¶å‘å®‰å…¨**: ä¿è¯
- **å†…å­˜å®‰å…¨**: ä¿è¯

---

## ğŸ“š é™„å½•

### A. é…ç½®æ–‡ä»¶ç¤ºä¾‹

#### A.1 ç®€å•é…ç½®ç¤ºä¾‹

```yaml
api_providers:
  text:
    primary:
      api_key: env:MY_API_KEY
      base_url: "https://api.myprovider.com/v1"
      model: "gpt-4"
      timeout_seconds: 60

tasks:
  simple_chat:
    provider_type: "text"
    prompt:
      type: "md"
      source: "prompts/simple_chat.md"
    retry:
      max_retries: 3
      enable_provider_switch: false
```

#### A.2 å¤æ‚é…ç½®ç¤ºä¾‹

```yaml
api_providers:
  text:
    primary:
      name: "OpenAI"
      api_key: env:OPENAI_API_KEY
      base_url: "https://api.openai.com/v1"
      model: "gpt-4"
      timeout_seconds: 120
      max_tokens: 4096
    secondary:
      name: "Anthropic"
      api_key: env:ANTHROPIC_API_KEY
      base_url: "https://api.anthropic.com/v1"
      model: "claude-3"
      timeout_seconds: 120
      max_tokens: 4096

  vision:
    primary:
      name: "OpenAI-Vision"
      api_key: env:OPENAI_API_KEY
      base_url: "https://api.openai.com/v1"
      model: "gpt-4-vision"
      timeout_seconds: 180
      max_tokens: 2048

tasks:
  image_analysis:
    provider_type: "vision"
    temperature: 0.3
    top_p: 0.8
    prompt:
      type: "md"
      source: "prompts/image_analysis.md"
    retry:
      max_retries: 3
      base_delay: 2
      max_delay: 30
      enable_provider_switch: true
    langfuse:
      enabled: true
      name: "image_analysis"
      tags: ["vision", "analysis"]
      metadata:
        source: "unified_client"
    json_repair:
      enabled: true
      strict_mode: false
      output_format: "text"
```

### B. æç¤ºè¯æ ¼å¼ç¤ºä¾‹

#### B.1 .mdæ ¼å¼

```markdown
<!-- prompts/image_analysis.md -->
# å›¾åƒåˆ†æåŠ©æ‰‹

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒåˆ†æåŠ©æ‰‹ã€‚è¯·ä»”ç»†è§‚å¯Ÿç”¨æˆ·æä¾›çš„å›¾åƒï¼Œå¹¶å›ç­”ç›¸å…³é—®é¢˜ã€‚

## åˆ†æè¦æ±‚
1. è¯¦ç»†æè¿°å›¾åƒä¸­çš„ä¸»è¦å¯¹è±¡
2. è¯†åˆ«å›¾åƒä¸­çš„æ–‡å­—ï¼ˆå¦‚æœæœ‰ï¼‰
3. åˆ†æå›¾åƒçš„æ•´ä½“æ„å›¾å’Œé£æ ¼

## è¾“å‡ºæ ¼å¼
è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
```json
{
  "description": "å›¾åƒçš„è¯¦ç»†æè¿°",
  "text_content": "å›¾åƒä¸­çš„æ–‡å­—å†…å®¹ï¼ˆå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºï¼‰",
  "analysis": "å¯¹å›¾åƒçš„æ·±å…¥åˆ†æ"
}
```
```

#### B.2 dictæ ¼å¼

```yaml
prompt:
  type: "dict"
  content:
    role: "system"
    content: |
      ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ï¼Œæ“…é•¿å°†ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ã€‚
      è¯·ä¿æŒåŸæ–‡çš„æ„æ€å’Œé£æ ¼ï¼Œä½¿ç”¨è‡ªç„¶æµç•…çš„è‹±æ–‡è¡¨è¾¾ã€‚
```

### C. é”™è¯¯ä»£ç å‚è€ƒ

| é”™è¯¯ç±»å‹ | ä»£ç  | æè¿° | å¤„ç†å»ºè®® |
|---------|------|------|---------|
| NETWORK | 1001 | ç½‘ç»œè¿æ¥å¤±è´¥ | æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œç¨åé‡è¯• |
| TIMEOUT | 1002 | è¯·æ±‚è¶…æ—¶ | å¢åŠ timeout_secondsé…ç½® |
| API_ERROR | 1003 | APIè¿”å›é”™è¯¯ | æ£€æŸ¥APIå¯†é’¥å’Œæ¨¡å‹é…ç½® |
| RATE_LIMIT | 1004 | é€Ÿç‡é™åˆ¶ | å¢åŠ delay_secondsæˆ–è”ç³»æä¾›å•† |
| PROVIDER_DOWN | 1005 | ProvideræœåŠ¡ä¸å¯ç”¨ | åˆ‡æ¢åˆ°å¤‡ç”¨Provider |
| CONFIG_ERROR | 2001 | é…ç½®é”™è¯¯ | æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼ |
| TASK_NOT_FOUND | 2002 | ä»»åŠ¡æœªé…ç½® | åœ¨é…ç½®ä¸­æ·»åŠ ä»»åŠ¡ |
| PROMPT_LOAD_ERROR | 2003 | æç¤ºè¯åŠ è½½å¤±è´¥ | æ£€æŸ¥æç¤ºè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ |

---

## ğŸ“ è”ç³»ä¿¡æ¯

**é¡¹ç›®ç»´æŠ¤è€…**: å¼€å‘å›¢é˜Ÿ
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-30

**åé¦ˆæ¸ é“**:
- GitHub Issues: [é¡¹ç›®åœ°å€]/issues
- é‚®ä»¶: dev-team@company.com
- å†…éƒ¨æ–‡æ¡£: confluence.company.com/llm-client

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0 (2025-10-30)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- ç»Ÿä¸€é…ç½®ç³»ç»Ÿ
- æ™ºèƒ½é‡è¯•æœºåˆ¶
- ä¸­æ–‡æ—¥å¿—ç³»ç»Ÿ
- JSONæ™ºèƒ½ä¿®å¤
- å‘åå…¼å®¹ä¿è¯

---

**æ–‡æ¡£ç»“æŸ**
