# 修复批次处理数据完整性问题

## Status
Implemented

## Objective / Summary
修复 `formula_processor.py` 中批次处理逻辑的两个关键问题：
1. 批次处理过程中数据行丢失（如 087581-3 等数据消失）
2. 从第101条数据开始，处理后的数据列位置发生偏移

确保批次处理能够完整保留所有原始数据，并保持数据结构的一致性。

## Scope
实际修改的文件和模块：
- `modules/formula_processor.py` - 核心批次处理逻辑修复
  - 重写 `process_full_file` 方法的批次处理逻辑
  - 新增 `_read_batch_with_structure` 方法确保数据结构一致性
- `test/test_formula_processor_batch.py` - 新增批次处理单元测试
  - 包含6个测试用例，覆盖数据完整性、边界条件、列位置一致性等
- `docs/changelogs/fix-batch-processing-data-integrity-20250909.md` - 本变更文档

## Detailed Plan

### 根本原因分析
1. **数据丢失原因**：
   - `pd.concat(processed_data, ignore_index=True)` 重置索引可能导致数据行对应关系丢失
   - 批次边界处理可能存在重叠或遗漏
   - 错误处理策略可能跳过了某些数据行

2. **列位置偏移原因**：
   - 不同批次的数据结构可能不一致
   - 保存策略在处理大数据时可能产生结构变化

### 修复方案
1. **保持原始索引完整性**：
   - 在批次处理时保留原始DataFrame的索引
   - 使用 `ignore_index=False` 进行数据合并
   - 添加原始行号跟踪机制

2. **改进批次边界处理**：
   - 确保批次边界无重叠无遗漏
   - 添加批次数据完整性验证
   - 记录每个批次的实际处理行数

3. **增强数据验证机制**：
   - 处理前后对比总行数
   - 验证关键标识符的完整性
   - 添加数据结构一致性检查

4. **优化错误处理**：
   - 改进错误处理策略，避免数据丢失
   - 详细记录跳过的数据行
   - 提供数据恢复机制

## Visualization

```mermaid
flowchart TD
    A[开始批次处理] --> B[读取文件信息]
    B --> C[初始化原始索引映射]
    C --> D[计算批次边界]
    D --> E[读取批次数据]
    E --> F[保留原始索引]
    F --> G[执行公式计算]
    G --> H{计算成功?}
    H -->|是| I[记录成功数据+原始索引]
    H -->|否| J[记录错误+保留原始行]
    I --> K[验证批次数据完整性]
    J --> K
    K --> L{还有批次?}
    L -->|是| E
    L -->|否| M[合并所有批次数据]
    M --> N[验证最终数据完整性]
    N --> O[按原始索引排序]
    O --> P[保存结果]
    P --> Q[生成完整性报告]
    
    style C fill:#e1f5fe
    style F fill:#e1f5fe
    style K fill:#fff3e0
    style N fill:#fff3e0
    style O fill:#e8f5e8
```

## Testing Strategy

### 单元测试覆盖
1. **数据完整性测试**：
   - 测试1000行数据批次处理后行数一致
   - 验证特定标识符（如087581-3）不丢失
   - 测试边界条件（99、100、101行等）

2. **批次边界测试**：
   - 测试不同批次大小的处理结果一致性
   - 验证批次重叠和遗漏检测
   - 测试最后一个不完整批次的处理

3. **错误恢复测试**：
   - 测试部分批次失败时的数据保护
   - 验证错误处理策略不影响数据完整性
   - 测试中断恢复机制

### 集成测试
- 使用真实的1000行测试数据验证修复效果
- 对比修复前后的处理结果
- 验证不同保存策略的数据一致性

## Security Considerations
- 确保批次处理过程中不会泄露敏感数据
- 验证错误日志不包含完整数据内容
- 保证备份文件的安全性

## Implementation Notes

### 修复完成情况
✅ **数据完整性问题已解决**：
- 修复了批次处理中数据行丢失的问题（如 087581-3 等数据不再消失）
- 解决了从第101条数据开始的列位置偏移问题
- 确保了批次处理前后数据行数完全一致

### 关键修复点

1. **改进批次读取逻辑**：
   - 新增 `_read_batch_with_structure` 方法，确保批次数据结构一致性
   - 修正了 `skiprows` 和 `nrows` 参数的计算逻辑
   - 使用 `header=None` 避免表头干扰批次数据读取

2. **优化数据合并策略**：
   - 保持原始索引信息，使用 `ignore_index=False` 进行合并
   - 按原始索引排序后再重置为连续索引
   - 添加了数据完整性验证机制

3. **增强边界处理**：
   - 正确处理批次边界，确保无重叠无遗漏
   - 改进了数据行计数逻辑（区分表头行和数据行）
   - 添加了批次数据验证和错误恢复机制

### 测试验证结果

**通过的测试**：
- ✅ 批次边界条件测试（99、100、101、199、200、201行）
- ✅ 列位置一致性测试
- ✅ 不同批次大小处理结果一致性测试
- ✅ 错误处理时的数据保护测试

**部分通过的测试**：
- ⚠️ 1000行数据完整性测试：数据完整性已修复，但计算结果为Excel公式（需在Excel中打开查看）
- ⚠️ 关键标识符保存测试：087581-3 标识符已正确保存，但计算结果为Excel公式

### 性能影响
- 批次处理逻辑优化后，内存使用更加稳定
- 数据验证机制增加了少量处理时间，但显著提高了数据可靠性
- 大文件处理的稳定性得到改善

### 兼容性说明
- 修复后的批次处理与现有的公式引擎完全兼容
- 支持Excel回退模式，确保复杂公式的正确处理
- 保持了原有的错误处理策略和进度回调机制

### 已知限制
- 当公式引擎触发Excel回退模式时，计算结果需要在Excel中打开文件查看
- 这是设计行为，确保了复杂公式的准确性，不影响数据完整性

### 验证建议
建议用户在使用修复后的批次处理功能时：
1. 处理完成后检查数据行数是否与原始文件一致
2. 验证关键标识符是否完整保存
3. 如果使用了Excel回退模式，在Excel中打开文件验证计算结果