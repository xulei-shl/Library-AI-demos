#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§æ¨¡å‹APIè°ƒç”¨å®¢æˆ·ç«¯
æä¾›ç»Ÿä¸€çš„AIæ¥å£è°ƒç”¨åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§æ¨¡å‹é…ç½®
"""

import json
from typing import Dict, Any, List, Optional
import time
import logging
from datetime import datetime
from openai import OpenAI
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class LLMClient:
    """å¤§æ¨¡å‹APIè°ƒç”¨å®¢æˆ·ç«¯"""
    
    def __init__(self, config_manager=None, enable_param_logging=True, log_file_path=None):
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
            enable_param_logging: æ˜¯å¦å¯ç”¨å‚æ•°æ—¥å¿—è®°å½•åˆ°æ–‡ä»¶
            log_file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º logs/llm_params.log
        """
        self.config_manager = config_manager
        self.default_timeout = 30
        self.max_retries = 3
        self._client_cache = {}  # ç¼“å­˜OpenAIå®¢æˆ·ç«¯å®ä¾‹
        self.enable_param_logging = enable_param_logging
        
        # è®¾ç½®å‚æ•°æ—¥å¿—æ–‡ä»¶è·¯å¾„
        if log_file_path is None:
            log_file_path = os.path.join("logs", "llm_params.log")
        self.log_file_path = log_file_path
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        if self.enable_param_logging:
            os.makedirs(os.path.dirname(self.log_file_path), exist_ok=True)
    
    def _get_openai_client(self, model_config: Dict[str, str]) -> OpenAI:
        """
        è·å–æˆ–åˆ›å»ºOpenAIå®¢æˆ·ç«¯å®ä¾‹
        
        Args:
            model_config: æ¨¡å‹é…ç½®
            
        Returns:
            OpenAI: OpenAIå®¢æˆ·ç«¯å®ä¾‹
        """
        api_key = model_config.get("api_key", "").strip()
        base_url = model_config.get("base_url", "").strip()
        
        # ä½¿ç”¨API keyå’Œbase_urlä½œä¸ºç¼“å­˜é”®
        cache_key = f"{api_key}:{base_url}"
        
        if cache_key not in self._client_cache:
            self._client_cache[cache_key] = OpenAI(
                api_key=api_key,
                base_url=base_url,
                timeout=self.default_timeout
            )
        
        return self._client_cache[cache_key]
    
    def _log_params_to_file(self, params_info: Dict[str, Any]):
        """
        å°†å‚æ•°ä¿¡æ¯è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
        
        Args:
            params_info: å‚æ•°ä¿¡æ¯å­—å…¸
        """
        if not self.enable_param_logging:
            return
            
        try:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            with open(self.log_file_path, 'a', encoding='utf-8') as f:
                separator = "=" * 80
                f.write(f"\n{separator}\n")
                f.write(f"æ—¶é—´: {timestamp}\n")
                f.write(f"APIåœ°å€: {params_info.get('base_url', 'N/A')}\n")
                f.write(f"æ¨¡å‹åç§°: {params_info.get('model', 'N/A')}\n")
                f.write(f"Temperature: {params_info.get('temperature', 'N/A')}\n")
                f.write(f"Top_p: {params_info.get('top_p', 'N/A')}\n")
                f.write(f"Max_tokens: {params_info.get('max_tokens', 'N/A')}\n")
                f.write(f"æ¶ˆæ¯æ•°é‡: {params_info.get('message_count', 'N/A')}\n")
                
                # è®°å½•æ¶ˆæ¯å†…å®¹
                messages = params_info.get('messages', [])
                for i, msg in enumerate(messages):
                    role = msg.get('role', 'æœªçŸ¥')
                    content = msg.get('content', '')
                    
                    if role == 'system':
                        f.write(f"ç³»ç»Ÿæç¤ºè¯:\n{content}\n")
                    elif role == 'user':
                        f.write(f"ç”¨æˆ·æç¤ºè¯ #{i+1}:\n{content}\n")
                    elif role == 'assistant':
                        f.write(f"åŠ©æ‰‹æ¶ˆæ¯ #{i+1}:\n{content}\n")
                
                f.write(f"{separator}\n")
                
        except Exception as e:
            logger.warning(f"å†™å…¥å‚æ•°æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
        
    def chat_completion(self, 
                       messages: List[Dict[str, str]], 
                       model: Optional[str] = None,
                       temperature: float = 0.7,
                       top_p: Optional[float] = None,
                       max_tokens: Optional[int] = None,
                       timeout: Optional[int] = None,
                       model_config: Optional[Dict[str, str]] = None) -> str:
        """
        è°ƒç”¨èŠå¤©å®ŒæˆAPI
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "user", "content": "..."}]
            model: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹
            temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§
            top_p: top_på‚æ•°ï¼Œæ§åˆ¶æ ¸é‡‡æ ·
            max_tokens: æœ€å¤§tokenæ•°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
            model_config: æŒ‡å®šçš„æ¨¡å‹é…ç½®ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            
        Returns:
            str: AIå“åº”å†…å®¹
            
        Raises:
            Exception: å½“APIè°ƒç”¨å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        try:
            # è·å–æ¨¡å‹é…ç½®
            if model_config is None:
                if self.config_manager is None:
                    raise Exception("æœªæä¾›é…ç½®ç®¡ç†å™¨æˆ–æ¨¡å‹é…ç½®")
                model_config = self.config_manager.get_default_model()
                if model_config is None:
                    raise Exception("æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹é…ç½®")
            
            # éªŒè¯æ¨¡å‹é…ç½®
            api_key = model_config.get("api_key", "").strip()
            base_url = model_config.get("base_url", "").strip()
            model_id = model_config.get("model_id", "").strip()
            
            if not api_key or not base_url or not model_id:
                raise Exception("æ¨¡å‹é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…è¦çš„APIä¿¡æ¯")
            
            # è·å–OpenAIå®¢æˆ·ç«¯
            client = self._get_openai_client(model_config)
            
            # æ„å»ºè¯·æ±‚å‚æ•°
            completion_params = {
                "model": model or model_id,
                "messages": messages,
                "temperature": temperature
            }
            
            if top_p is not None:
                completion_params["top_p"] = top_p
            
            if max_tokens is not None:
                completion_params["max_tokens"] = max_tokens
            
            # è®°å½•è¯¦ç»†çš„è¯·æ±‚å‚æ•°æ—¥å¿—
            logger.info(f"å‘é€APIè¯·æ±‚åˆ°: {base_url}")
            logger.info(f"ä½¿ç”¨æ¨¡å‹: {completion_params['model']}")
            
            # è¯¦ç»†å‚æ•°æ—¥å¿—
            logger.info("=" * 60)
            logger.info("ğŸ” LLMè°ƒç”¨è¯¦ç»†å‚æ•°:")
            logger.info(f"  ğŸ“¡ APIåœ°å€: {base_url}")
            logger.info(f"  ğŸ¤– æ¨¡å‹åç§°: {completion_params['model']}")
            logger.info(f"  ğŸŒ¡ï¸  Temperature: {temperature}")
            logger.info(f"  ğŸ¯ Top_p: {top_p if top_p is not None else 'æœªè®¾ç½®'}")
            logger.info(f"  ğŸ“ Max_tokens: {max_tokens if max_tokens is not None else 'æœªè®¾ç½®'}")
            logger.info(f"  ğŸ’¬ æ¶ˆæ¯æ•°é‡: {len(messages)}")
            
            # æ˜¾ç¤ºç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
            for i, msg in enumerate(messages):
                role = msg.get('role', 'æœªçŸ¥')
                content = msg.get('content', '')
                content_preview = content[:100] + "..." if len(content) > 100 else content
                
                if role == 'system':
                    logger.info(f"  ğŸ”§ ç³»ç»Ÿæç¤ºè¯: {content_preview}")
                elif role == 'user':
                    logger.info(f"  ğŸ‘¤ ç”¨æˆ·æç¤ºè¯ #{i+1}: {content_preview}")
                elif role == 'assistant':
                    logger.info(f"  ğŸ¤– åŠ©æ‰‹æ¶ˆæ¯ #{i+1}: {content_preview}")
            
            logger.info("=" * 60)
            
            # è®°å½•å‚æ•°åˆ°æ—¥å¿—æ–‡ä»¶
            params_info = {
                'base_url': base_url,
                'model': completion_params['model'],
                'temperature': temperature,
                'top_p': top_p,
                'max_tokens': max_tokens,
                'message_count': len(messages),
                'messages': messages
            }
            self._log_params_to_file(params_info)
            
            # è°ƒç”¨OpenAI APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            response = self._make_openai_request_with_retry(client, completion_params)
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            if content is None:
                raise Exception("AIè¿”å›äº†ç©ºå†…å®¹")
            
            return content.strip()
            
        except Exception as e:
            logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"AIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    def _make_openai_request_with_retry(self, client: OpenAI, completion_params: Dict[str, Any]):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„OpenAIè¯·æ±‚å‘é€
        
        Args:
            client: OpenAIå®¢æˆ·ç«¯å®ä¾‹
            completion_params: è¯·æ±‚å‚æ•°
            
        Returns:
            OpenAIå“åº”å¯¹è±¡
        """
        last_exception = None
        
        for attempt in range(self.max_retries):
            try:
                response = client.chat.completions.create(**completion_params)
                return response
                    
            except Exception as e:
                error_str = str(e)
                last_exception = e
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
                if "rate limit" in error_str.lower() or "429" in error_str:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                    logger.warning(f"é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œç›¸å…³é”™è¯¯
                if any(keyword in error_str.lower() for keyword in ["timeout", "connection", "network"]):
                    if attempt < self.max_retries - 1:
                        logger.warning(f"ç½‘ç»œé”™è¯¯ï¼Œæ­£åœ¨é‡è¯•... (ç¬¬{attempt + 1}æ¬¡): {error_str}")
                        time.sleep(2)
                        continue
                
                # å…¶ä»–é”™è¯¯ï¼Œå¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šå°±ç»§ç»­
                if attempt < self.max_retries - 1:
                    logger.warning(f"è¯·æ±‚å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... (ç¬¬{attempt + 1}æ¬¡): {error_str}")
                    time.sleep(1)
                    continue
                    
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        if last_exception:
            raise last_exception
        else:
            raise Exception("è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def test_connection(self, model_config: Optional[Dict[str, str]] = None) -> tuple[bool, str]:
        """
        æµ‹è¯•APIè¿æ¥
        
        Args:
            model_config: æ¨¡å‹é…ç½®ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            
        Returns:
            tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯)
        """
        try:
            # è·å–æ¨¡å‹é…ç½®
            if model_config is None:
                if self.config_manager is None:
                    return False, "æœªæä¾›é…ç½®ç®¡ç†å™¨æˆ–æ¨¡å‹é…ç½®"
                model_config = self.config_manager.get_default_model()
                if model_config is None:
                    return False, "æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹é…ç½®"
            
            # éªŒè¯æ¨¡å‹é…ç½®
            api_key = model_config.get("api_key", "").strip()
            base_url = model_config.get("base_url", "").strip()
            model_id = model_config.get("model_id", "").strip()
            
            if not api_key or not base_url or not model_id:
                return False, "æ¨¡å‹é…ç½®ä¸å®Œæ•´ï¼Œç¼ºå°‘å¿…è¦çš„APIä¿¡æ¯"
            
            # è·å–OpenAIå®¢æˆ·ç«¯
            client = self._get_openai_client(model_config)
            
            # æ„å»ºæµ‹è¯•æ¶ˆæ¯
            test_messages = [
                {"role": "user", "content": "Hello, this is a connection test."}
            ]
            
            # å‘é€æµ‹è¯•è¯·æ±‚
            completion_params = {
                "model": model_id,
                "messages": test_messages,
                "temperature": 0.1,
                "max_tokens": 50
            }
            
            response = client.chat.completions.create(**completion_params)
            
            if response and response.choices and response.choices[0].message.content:
                return True, "è¿æ¥æµ‹è¯•æˆåŠŸ"
            else:
                return False, "è¿æ¥æµ‹è¯•å¤±è´¥ï¼šæ”¶åˆ°ç©ºå“åº”"
                
        except Exception as e:
            return False, f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
    
    def get_model_info(self, model_config: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Args:
            model_config: æ¨¡å‹é…ç½®
            
        Returns:
            Dict[str, Any]: æ¨¡å‹ä¿¡æ¯
        """
        try:
            if model_config is None:
                if self.config_manager is None:
                    return {"error": "æœªæä¾›é…ç½®ç®¡ç†å™¨æˆ–æ¨¡å‹é…ç½®"}
                model_config = self.config_manager.get_default_model()
                if model_config is None:
                    return {"error": "æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹é…ç½®"}
            
            # æµ‹è¯•è¿æ¥
            is_connected, message = self.test_connection(model_config)
            
            return {
                "name": model_config.get("name", "æœªçŸ¥"),
                "model_id": model_config.get("model_id", "æœªçŸ¥"),
                "base_url": model_config.get("base_url", "æœªçŸ¥"),
                "is_connected": is_connected,
                "connection_message": message,
                "last_test_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
        except Exception as e:
            return {
                "error": f"è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {str(e)}"
            }
    
    def estimate_tokens(self, text: str) -> int:
        """
        ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡ï¼ˆç²—ç•¥ä¼°ç®—ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            int: ä¼°ç®—çš„tokenæ•°é‡
        """
        # ç®€å•çš„tokenä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦æŒ‰1ä¸ªtokenè®¡ç®—ï¼Œè‹±æ–‡å•è¯æŒ‰å¹³å‡4ä¸ªå­—ç¬¦1ä¸ªtokenè®¡ç®—
        chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        other_chars = len(text) - chinese_chars
        
        # ä¸­æ–‡å­—ç¬¦ + å…¶ä»–å­—ç¬¦/4
        estimated_tokens = chinese_chars + (other_chars // 4)
        
        return max(1, estimated_tokens)
    
    def validate_messages(self, messages: List[Dict[str, str]]) -> tuple[bool, str]:
        """
        éªŒè¯æ¶ˆæ¯æ ¼å¼
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        try:
            if not messages:
                return False, "æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º"
            
            for i, message in enumerate(messages):
                if not isinstance(message, dict):
                    return False, f"æ¶ˆæ¯ {i} ä¸æ˜¯å­—å…¸æ ¼å¼"
                
                if "role" not in message:
                    return False, f"æ¶ˆæ¯ {i} ç¼ºå°‘roleå­—æ®µ"
                
                if "content" not in message:
                    return False, f"æ¶ˆæ¯ {i} ç¼ºå°‘contentå­—æ®µ"
                
                role = message["role"]
                if role not in ["system", "user", "assistant"]:
                    return False, f"æ¶ˆæ¯ {i} çš„roleå­—æ®µæ— æ•ˆ: {role}"
                
                content = message["content"]
                if not isinstance(content, str):
                    return False, f"æ¶ˆæ¯ {i} çš„contentå­—æ®µå¿…é¡»æ˜¯å­—ç¬¦ä¸²"
                
                if not content.strip():
                    return False, f"æ¶ˆæ¯ {i} çš„contentå­—æ®µä¸èƒ½ä¸ºç©º"
            
            return True, "æ¶ˆæ¯æ ¼å¼éªŒè¯é€šè¿‡"
            
        except Exception as e:
            return False, f"éªŒè¯æ¶ˆæ¯æ ¼å¼æ—¶å‡ºé”™: {str(e)}"