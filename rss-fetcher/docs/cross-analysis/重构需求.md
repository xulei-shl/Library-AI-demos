DeepRead：基于深度文章分析的主题书目推荐系统
项目概述
本项目旨在构建一个自动化的内容策展系统。通过每日追踪特定 RSS 源，利用大语言模型（LLM）对高质量长文进行多阶段分析（初筛、深读、提取），并将非结构化的文章转化为结构化的“知识卡片”。
最终目标不是为了囤积文章，而是通过周期性聚合分析，识别出近期文章背后的共同“母题 (Mother Topics)”。通过将这些母题与本地图书数据库进行语义关联，系统定期生成具有深层互文性的主题书单，实现“从一篇好文，发现一本好书”**的价值闭环。

这个项目。我已经实现了rss订阅全文爬取，初步过滤，总结，深度分析。现在开始设计通过评分的文章的交叉分析。得到跨文章的底层共同的母题。

我会提供前面几轮的结果字段，excel列：
id，title，llm_score，llm_thematic_essence，llm_tags，llm_mentioned_books，llm_summary（是个完整json）中的summary_long节点内容。

经过前面结果后，excel列数据如下：
id	source	title	article_date	published_date	link	fetch_date	summary	extract_status	extract_error	content	full_text	filter_pass	filter_reason	filter_status	llm_score	llm_reason	llm_thematic_essence	llm_tags	llm_primary_dimension	llm_mentioned_books	llm_summary	llm_summary_status	llm_summary_error	llm_summary_last_try	llm_analysis_status	llm_analysis_error	llm_analysis_last_try	fetch_method	category	author	tags

---

为了让这个交叉分析产生最好的效果，我能想到的需要注意的细节：

#### 1. 输入数据的预处理（Batching Strategy）

不能把数据库里所有的文章一次性扔给 LLM。需要一个**滑动窗口**或**基于时间的批处理**策略。

*   **策略 动态聚类，推荐）**：
    1.  先拿所有高分（可配置的分数阈值，配置文件路径是config\subject_bibliography.yaml ）文章的id，title，`llm_tags、 `llm_thematic_essence` summary_long等合适的字段内容向量做一次简单的数学聚类（如 K-Means）。
#### 2. 聚类分组后的大模型交叉分析    
    2.  把聚在同一类的 3-5 篇文章，作为一组输入发给交叉对比分析llm流程。
        *理由：如果把一篇讲“量子物理”的和一篇讲“红楼梦”的硬凑在一起，LLM 会产生幻觉。先用数学方法粗分，再用 LLM 提炼，效果最好。*
    3.  对聚类后的每一组文章，调用 LLM 进行对比分析，提取出共同的主题。llm调用的逻辑可参考之前的模块，如 src\core\analysis\filter.py。其中llm调用的公用组件在 src\utils\llm。交叉分析的提示词是 `article_cross_analysis`（使用langfuse提供系统提示词），大模型配置是 config\llm.yaml
#### 其他
- 一定要保留文章唯一id（excel的id列），便于分析追溯回原始文章。
- 交叉分析的结果，要保留在excel的新列中，列名是 `llm_cross_analysis`。
- 要考虑中断继续，已完成的跳过，错误重试等等异常情况。大模型返回结果即刻保存，避免调用失败后，丢失已分析的文章。