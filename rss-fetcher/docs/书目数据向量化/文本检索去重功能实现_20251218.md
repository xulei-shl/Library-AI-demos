# 文本检索双重去重功能实现（基于时间优先级）

## 修改背景

根据检索结果去重逻辑检查报告，发现文本检索接口 (`/api/books/text-search`) 缺少去重逻辑，而多子查询检索接口 (`/api/books/multi-query`) 已有完整的去重机制。为了解决文本检索结果重复的问题，首先在文本检索中添加了基于 `book_id` 的去重逻辑。

后续发现数据库中存在重复脏数据，相同 `call_no`（索书号）对应不同 `book_id` 的情况，因此需要增加第二层基于 `call_no` 的去重逻辑。

最后根据用户需求，将去重策略从"保留相似度最高的记录"改为"保留最新的记录"，以更好地处理数据更新场景。

## 修改内容

### 1. 文件修改

- **文件**: `src/core/book_vectorization/retriever.py`
- **方法**: `search_by_text()` (第58-113行)
- **新增方法**: `_deduplicate_by_book_id()` (第318-381行), `_is_record_newer()` (第383-408行)

### 2. 实现逻辑

在 `search_by_text()` 方法中，补充完整书籍信息后添加了双重去重处理，并增加了时间字段：

```python
# 5. 去重处理 - 基于 book_id 和 call_no 去重，保留最新的记录
deduplicated_results = self._deduplicate_by_book_id(enriched_results)
```

### 3. 基于时间的双重去重算法

`_deduplicate_by_book_id()` 方法实现了基于 `book_id` 和 `call_no` 的双重去重逻辑，优先保留最新记录：

#### 第一步：基于 book_id 去重
1. 使用字典按 `book_id` 聚合结果
2. 对于相同的 `book_id`，保留时间最新的记录

#### 第二步：基于 call_no 去重
1. 对第一步去重后的结果，再按 `call_no` 聚合
2. 对于相同的 `call_no`，保留时间最新的记录
3. 对于空的 `call_no`，特殊处理，直接保留

#### 第三步：排序返回
按相似度降序排序返回结果

```python
def _deduplicate_by_book_id(self, results: List[Dict]) -> List[Dict]:
    """
    基于 book_id 和 call_no 双重去重，保留最新的记录
    
    优先级规则：
    1. 如果有 embedding_date 时间字段，保留时间最新的记录
    2. 如果没有时间字段，保留 book_id 最大的记录
    
    Args:
        results: 检索结果列表
        
    Returns:
        去重后的结果列表
    """
    if not results:
        return results
        
    # 第一步：基于 book_id 去重
    book_dict = {}
    for result in results:
        book_id = str(result.get('book_id', ''))
        if not book_id:
            continue
            
        # 判断是否应该保留当前记录
        should_keep = False
        if book_id not in book_dict:
            should_keep = True
        else:
            existing = book_dict[book_id]
            should_keep = self._is_record_newer(result, existing)
        
        if should_keep:
            book_dict[book_id] = result
    
    book_id_deduplicated = list(book_dict.values())
    
    # 第二步：基于 call_no 去重，处理数据库中的重复脏数据
    call_no_dict = {}
    for result in book_id_deduplicated:
        call_no = str(result.get('call_no', '')).strip()
        if not call_no:
            # 如果没有索书号，直接保留
            call_no_dict[f"no_call_no_{result.get('book_id')}"] = result
            continue
                
        # 判断是否应该保留当前记录
        should_keep = False
        if call_no not in call_no_dict:
            should_keep = True
        else:
            existing = call_no_dict[call_no]
            should_keep = self._is_record_newer(result, existing)
        
        if should_keep:
            call_no_dict[call_no] = result
    
    # 按相似度排序并返回
    deduplicated = list(call_no_dict.values())
    deduplicated.sort(key=lambda x: x.get('similarity_score', 0), reverse=True)
    
    logger.info(f"双重去重完成: 原始结果 {len(results)} 条，book_id去重后 {len(book_id_deduplicated)} 条，最终去重后 {len(deduplicated)} 条")
    return deduplicated
```

### 4. 时间优先级判断算法

`_is_record_newer()` 方法实现了基于时间的优先级判断：

```python
def _is_record_newer(self, current: Dict, existing: Dict) -> bool:
    """
    判断当前记录是否比已有记录更新
    
    优先级规则：
    1. 如果有 embedding_date 时间字段，比较时间
    2. 如果没有时间字段，比较 book_id
    
    Args:
        current: 当前记录
        existing: 已有记录
        
    Returns:
        True 如果当前记录更新，False 否则
    """
    # 尝试比较 embedding_date
    current_date = current.get('embedding_date', '').strip()
    existing_date = existing.get('embedding_date', '').strip()
    
    if current_date and existing_date:
        # 如果两个记录都有时间字段，比较时间
        return current_date > existing_date
    
    # 如果只有一个记录有时间字段，有时间字段的记录更新
    if current_date and not existing_date:
        return True
    
    if not current_date and existing_date:
        return False
    
    # 如果都没有时间字段，比较 book_id
    current_id = int(current.get('id', 0))
    existing_id = int(existing.get('id', 0))
    
    return current_id > existing_id
```

## 测试验证

创建了测试脚本 `scripts/test_deduplication_simple.py` 验证基于时间的双重去重功能：

1. 构造包含重复 `book_id` 和重复 `call_no` 的模拟数据，并设置不同的时间字段
2. 验证去重后没有重复的 `book_id`
3. 验证去重后没有重复的非空 `call_no`
4. 验证保留了时间最新的记录

测试结果：
- ✅ book_id 去重功能正常工作 - 没有重复的 book_id
- ✅ call_no 去重功能正常工作 - 没有重复的非空 call_no
- ✅ 正确保留时间最新的记录

测试示例：
```
原始结果数量: 7
原始结果中的 book_id: [1, 2, 1, 3, 4, 5, 6]
原始结果中的 call_no: ['TP18', 'TP181', 'TP18', 'TP181', '', 'TP311', 'TP312']
原始结果中的 embedding_date: ['2025-12-01T10:00:00', '2025-12-10T15:30:00', '2025-12-15T09:20:00', '2025-12-12T11:45:00', '', '', '']
双重去重完成: 原始结果 7 条，book_id去重后 6 条，最终去重后 5 条
```

## 修改效果

- **修改前**: 文本检索可能返回相同书籍的多条记录，且可能返回相同索书号的不同书籍
- **修改后**: 文本检索进行双重去重：
  1. 首先基于 `book_id` 去重，确保每本书只返回一次
  2. 然后基于 `call_no` 去重，解决数据库中的重复脏数据问题
  3. 优先保留时间最新的记录，确保返回最新的数据版本

## 与多子查询检索的一致性

现在文本检索和多子查询检索的去重逻辑完全一致：
1. **文本检索**：基于 `book_id` 和 `call_no` 双重去重，保留时间最新的记录
2. **多子查询检索**：基于 `book_id` 和 `call_no` 双重去重，保留时间最新的记录

### 多子查询检索的去重修改

为了确保一致性，对多子查询检索的去重逻辑进行了以下修改：

#### 1. 修改 `_prefer_higher_similarity` 函数
- 从保留相似度最高的记录改为保留时间最新的记录
- 实现了与文本检索相同的时间优先级判断逻辑

#### 2. 修改 `merge_exact_matches` 函数
- 添加了基于 `call_no` 的第二层去重逻辑
- 确保精确匹配结果也使用相同的双重去重策略
- 添加了 `_is_record_newer` 函数用于时间比较

#### 3. 新增 `_is_record_newer` 函数
- 实现了与文本检索相同的时间优先级判断逻辑
- 优先级规则：
  1. 如果有 `embedding_date` 时间字段，比较时间
  2. 如果没有时间字段，比较 `book_id`

### 多子查询检索测试验证

创建了测试脚本 `scripts/test_multi_query_deduplication.py` 验证多子查询检索的双重去重功能：

1. 测试 `fuse_query_results` 函数的基于时间去重逻辑
2. 测试 `merge_exact_matches` 函数的双重去重逻辑
3. 测试 `_prefer_higher_similarity` 函数的时间优先级判断
4. 测试 `_is_record_newer` 函数的时间比较逻辑

测试结果：
- ✅ `fuse_query_results` 的 book_id 去重功能正常工作
- ✅ `merge_exact_matches` 的 book_id 和 call_no 去重功能正常工作
- ✅ 正确保留时间最新的记录
- ✅ `_prefer_higher_similarity` 和 `_is_record_newer` 函数正常工作

测试示例：
```
原始查询结果数量: 4
融合后结果数量: 3
合并后结果数量: 3
```

## 日志记录

添加了详细的日志记录，显示双重去重的各阶段结果数量：
```
文本检索完成: 返回 X 本书（去重前: Y 本）
双重去重完成: 原始结果 Y 条，book_id去重后 Z 条，最终去重后 X 条
```

## 总结

通过在文本检索接口中添加基于时间的双重去重逻辑，彻底解决了检索结果重复的问题：
1. 第一层去重确保每本书只返回一次
2. 第二层去重解决了数据库中重复索书号的脏数据问题
3. 优先保留时间最新的记录，确保返回最新的数据版本

这一修改提高了文本检索接口的可靠性和用户体验，有效处理了数据质量问题和数据更新场景。时间优先级的去重策略更符合实际业务需求，确保用户看到的是最新的书籍信息。