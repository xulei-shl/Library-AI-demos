## 问题描述与初步分析
精确匹配失败的根本原因是_search_exact_matches方法中提取搜索词的逻辑有问题：

从query_package.books提取时，包含了整个书籍对象的字符串表示，而不仅仅是书名
从query_package.primary和query_package.tags提取时，包含了过长的描述性文本

1. MD 文件格式
从两个 MD 文件可以看出，格式是标准化的：

标签字段：

| 标签 | ['算法批判'、'数字劳动'、'情绪政治'、'平台资本主义'、'AI伦理'] |
提及书籍字段：

| 提及书籍 | [{'title': 'Enshittification'、'author': 'Cory Doctorow'、'context': '作者2022年提出的理论，描述平台通过三阶段劣化用户与商业客户以榨取价值的过程。'}、{'title': "The Reverse Centaur's Guide to Life After AI"、'author': 'Cory Doctorow'、'context': '即将出版的新书，提出'逆向半人马'隐喻，批判AI对劳动的异化。'}] |
2. 解析逻辑的问题
在 _extract_books 方法中，代码使用 _split_list_text 来处理书籍信息：

def _extract_books(self, content: str) -> List[str]:
    matches = BOOK_LINE_PATTERN.findall(content)
    books: List[str] = []
    for raw in matches:
        values = self._split_list_text(raw)  # 这里是问题所在
        books.extend(values)
    return self._deduplicate([b for b in books if b and b not in {"无", "none", "None"}])
而 _split_list_text 方法只是简单地按逗号分割并清理引号，无法正确解析 JSON 格式的书籍信息。

3. 精确匹配逻辑的问题
在 _search_exact_matches 方法中：

def _search_exact_matches(self, query_package: QueryPackage, min_rating: Optional[float], exact_match_top_k: int) -> List[Dict]:
    terms: List[str] = []
    
    # 收集书名（优先）
    terms.extend(query_package.books)  # 这里包含了格式错误的内容
    
    # 从 primary/short tags 提取短语（长度<=10）
    max_len = 10
    for short_term in query_package.primary + query_package.tags:
        if len(short_term) <= max_len:
            terms.append(short_term)
这里的问题是：

query_package.books 包含了整个 JSON 字符串的分割结果，而不是纯书名
从 primary 和 tags 中提取的短语包含了过长的描述性文本

## 问题根源

### 1. 书籍信息解析失败
MD文件中的`提及书籍`字段是JSON格式：
```markdown
| 提及书籍 | [{'title': 'Enshittification'、'author': 'Cory Doctorow'、'context': '...'}、...] |
```

但`_extract_books`方法使用`_split_list_text`简单分割，导致提取出的是：
```
['title: Enshittification', 'author: Cory Doctorow', 'context: 作者2022年提出的理论...']
```
而不是纯书名`['Enshittification', "The Reverse Centaur's Guide to Life After AI"]`

### 2. 关键词提取不准确
精确匹配时包含了大量不适合搜索的描述性文本，如：
- 带前缀的文本：`'title: Enshittification'`, `'author: Cory Doctorow'`
- 过长的描述：`'描述平台通过三阶段劣化用户与商业客户以榨取价值的过程。}'`
- 格式错误的内容：`'{title: The Reverse Centaurs Guide to Life After AI'`

## 优化方案

### 1. 修复书籍信息解析
修改`_extract_books`方法，正确解析JSON格式的书籍信息：
```python
def _extract_books(self, content: str) -> List[str]:
    matches = BOOK_LINE_PATTERN.findall(content)
    books: List[str] = []
    for raw in matches:
        try:
            # 处理中文引号，解析JSON
            cleaned = raw.replace('、', ',').replace('"', "'").replace('"', "'").replace('"', "'")
            book_list = json.loads(f"[{cleaned}]")
            for book in book_list:
                if isinstance(book, dict) and 'title' in book:
                    books.append(book['title'])
        except (json.JSONDecodeError, AttributeError):
            # 回退到原来的方法
            values = self._split_list_text(raw)
            books.extend(values)
    return self._deduplicate([b for b in books if b and b not in {"无", "none", "None"}])
```

### 2. 改进精确匹配逻辑
修改`_search_exact_matches`方法，更精确地提取关键词：
```python
def _search_exact_matches(self, query_package: QueryPackage, min_rating: Optional[float], exact_match_top_k: int) -> List[Dict]:
    terms: List[str] = []
    
    # 收集书名（优先）
    terms.extend(query_package.books)
    
    # 从tags中提取关键词（通常是简洁的标签）
    terms.extend(query_package.tags)
    
    # 从primary中只提取简短的短语（长度<=10）
    max_len = 10
    for short_term in query_package.primary:
        if len(short_term) <= max_len:
            terms.append(short_term)
    
    # 去重
    terms = list(set(terms))
    # 其余逻辑保持不变
```

### 3. 增强关键词分类
可以在QueryPackage中添加专门的`keywords`字段，用于存储精确匹配的关键词，区分适合精确匹配的简洁关键词和描述性文本。

通过这些优化，精确匹配将能够正确提取书名和关键词，显著提高匹配效果，真正发挥补充向量检索的作用。