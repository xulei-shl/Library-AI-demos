# RSS文章定时爬取与LLM分析 初始化指南

面向需要维护或扩展 RSS文章定时爬取与LLM分析 功能的同学，本文总结当前仓库的初始化步骤、依赖与运行入口，帮助快速完成环境搭建、配置校验与三阶段流程验证。

## 1. 项目结构速览

- `main.py`：程序主入口，提供简单的命令行接口，封装 `fetch → extract → analyze` 三个阶段，可单独或串行运行。
- `src/core/pipeline.py`：`SubjectBibliographyPipeline` 是核心流程控制器，支持三阶段解耦运行。
- `src/core/rss_fetcher.py`：负责按 `config/subject_bibliography.yaml` 的时间窗口抓取 RSS。
- `src/core/content_extractors/`：澎湃、BigThink、Wikipedia 三个提取器通过 `ExtractorFactory` 注册，基于 RSS 源名称动态选择。
- `src/core/article_analyzer.py`：`ArticleProcessor` 组合 `UnifiedLLMClient`，保证 LLM 输出 JSON 字段被安全解析。
- `src/core/storage.py`：统一生成 `runtime/outputs/` 下的按月聚合 Excel 文件（格式：YYYY-MM.xlsx），并提供 `load_stage_data`/`find_latest_stage_file` 以支撑断点续跑。每个Excel新增 `article_date` 列记录文章的发布日期。
- `src/utils/logger.py` 与 `src/utils/llm/*`：分别提供日志与 LLM 基础设施，全局共享。

## 2. 环境准备

1. 建议使用 Python 3.10+，创建虚拟环境并升级 pip：
   ```powershell
   python -m venv .venv
   .\.venv\Scripts\activate
   pip install -U pip
   ```
2. 安装运行依赖（含全文提取与 LLM 能力）：
   ```powershell
   pip install feedparser python-dateutil pandas openpyxl beautifulsoup4 requests playwright openai python-dotenv langfuse
   playwright install chromium
   ```
3. 初始化日志与运行目录：
   - 日志：`src/utils/logger.py` 默认输出到 `runtime/logs/`，无需额外配置但需保证目录可写。
   - 阶段产物：`StorageManager` 首次运行会自动创建 `runtime/outputs/`。

## 3. 配置清单

| 文件 | 作用 | 必要操作 |
| --- | --- | --- |
| `config/.env` | LLM/外部服务密钥 | 复制 `.env.example`，填入 `ONEAPI_API_KEY`、`CEREBRAS_API_KEY`、Langfuse、公用账号等字段。 |
| `config/llm.yaml` | Provider & 任务配置 | 核对 `api_providers` 可用性，`tasks.network_article_initial_review` 将引用 `prompts/网络文章主题初评.md`。 |
| `config/subject_bibliography.yaml` | RSS、抓取、输出配置 | 根据环境调整 `rss_feeds`、`fetch_settings`、`output.base_dir`、`llm_analysis.task_name`、`extraction_settings`。 |
| `prompts/网络文章主题初评.md` | LLM 指令模版 | 修改评估维度或 JSON 输出字段时需同步更新。 |

> 提示：`ConfigLoader` 会先加载 `.env` 再解析 `llm.yaml`，支持 `env:VAR` 写法；日志配置若需细化，可在 `src/utils/logger.py` 引用 `config/settings.yaml`（若存在）。

## 4. 初始化步骤

1. **依赖安装**：完成第 2 节中的 pip + playwright 安装。
2. **配置落地**：
   - `.env`：填充 LLM Key、Langfuse、公用账号信息。
   - `subject_bibliography.yaml`：开启/关闭 RSS 源、设定 `hours_lookback` 或 `time_range`。
   - `llm.yaml`：确认 `network_article_initial_review` 的 provider、prompt 路径与 JSON 修复参数。
3. **目录校验**：确保 `runtime/logs/`、`runtime/outputs/` 存在或具有写权限。
4. **可选测试**：运行 `python -m playwright install chromium` 验证浏览器内核，必要时单测 `ExtractorFactory` 或 `ArticleProcessor`。

## 5. 运行与验证

### 主入口程序 (main.py)
程序主入口为 `main.py`，提供简洁的命令行接口：

```powershell
# 完整流程运行 (三阶段)
python main.py

# 阶段1：RSS 抓取
python main.py --stage fetch

# 阶段2：全文解析（基于月文件）
python main.py --stage extract

# 阶段3：LLM 评估（基于月文件）
python main.py --stage analyze

# 指定输入文件运行后续阶段
python main.py --stage extract --input runtime/outputs/2025-12.xlsx
python main.py --stage analyze --input runtime/outputs/2025-12.xlsx

# 显示帮助信息
python main.py --help
```

### 按月聚合输出格式
- **输出目录**: `runtime/outputs/`
- **文件命名**: `YYYY-MM.xlsx` 格式（如：`2025-12.xlsx`）
- **聚合逻辑**: 同一月份的所有文章保存在单个Excel文件中
- **新增列**: 每个Excel文件包含 `article_date` 列，记录文章发布日期（YYYY-MM-DD格式）

验证要点：
- Excel 文件按月聚合，包含对应月份的所有文章数据。
- 所有阶段Excel文件均包含新增的 `article_date` 列。
- `runtime/logs/llm.log`、`debug.log` 中无异常；如 LLM 返回非 JSON，`ArticleProcessor` 会在 `llm_raw_response` 留存原文供排查。
- 阶段2若 `extract_status=skipped`，检查 RSS 源名称是否能被对应提取器 `can_handle` 命中，或 `extraction_settings` 是否缺失必要参数。

## 6. 常见问题

- **RSS 抓取为空**：确认 `hours_lookback` 与 `time_range` 配置合理，并验证 RSS URL 可访问（`src/core/rss_fetcher.py:20`）。
- **提取器未注册**：新增提取器后需在 `src/core/content_extractors/__init__.py` 调用 `ExtractorFactory.register`。
- **LLM 失败**：检查 `.env` 密钥、`config/llm.yaml` 的 `api_providers` base_url，必要时开启 `langfuse.debug` 追踪。
- **Excel 写入错误**：确认 `pandas/openpyxl` 版本一致且输出目录可写，或者检查是否有同名文件被占用。
- **按月聚合问题**：确保文章 `published_date` 格式正确，系统会根据文章发布日期自动归类到对应月份的Excel文件中。
