# RSS文章抓取与LLM分析系统 - 代码运行逻辑流程图

## 整体数据流转流程

```mermaid
flowchart TD
    START([程序启动]) --> INIT[初始化环境<br/>验证配置文件和目录]
    
    INIT --> MODE{启动模式判断}
    
    MODE -->|无参数| INTERACTIVE[进入交互式模式]
    MODE -->|有参数| COMMAND[进入命令行模式]
    MODE -->|帮助请求| HELP[显示帮助信息]
    
    INTERACTIVE --> MENU[显示主菜单]
    COMMAND --> PARSE_ARGS[解析命令行参数]
    HELP --> END([程序结束])
    
    PARSE_ARGS --> STAGE{选择执行阶段}
    MENU --> STAGE
    
    STAGE -->|all| ALL_PIPELINE[执行完整流程]
    STAGE -->|fetch| FETCH_STAGE[阶段1: RSS获取]
    STAGE -->|extract| EXTRACT_STAGE[阶段2: 全文解析]
    STAGE -->|filter| FILTER_STAGE[阶段3: 文章过滤]
    STAGE -->|summary| SUMMARY_STAGE[阶段4: 文章总结]
    STAGE -->|analysis| ANALYSIS_STAGE[阶段5: 深度分析]
    STAGE -->|cross| CROSS_STAGE[阶段6: 交叉主题分析]
    STAGE -->|md_processing| MD_STAGE[MD文档处理]
    
    ALL_PIPELINE --> FETCH_STAGE
    FETCH_STAGE --> EXTRACT_STAGE
    EXTRACT_STAGE --> FILTER_STAGE
    FILTER_STAGE --> SUMMARY_STAGE
    SUMMARY_STAGE --> ANALYSIS_STAGE
    ANALYSIS_STAGE --> CROSS_STAGE
    
    FETCH_STAGE --> SAVE1[保存到YYYY-MM.xlsx<br/>按月聚合]
    EXTRACT_STAGE --> SAVE2[更新到YYYY-MM.xlsx<br/>添加全文内容]
    FILTER_STAGE --> SAVE3[更新到YYYY-MM.xlsx<br/>添加过滤结果]
    SUMMARY_STAGE --> SAVE4[更新到YYYY-MM.xlsx<br/>添加总结内容]
    ANALYSIS_STAGE --> SAVE5[更新到YYYY-MM.xlsx<br/>添加分析结果]
    CROSS_STAGE --> SAVE6[生成交叉分析报告]
    MD_STAGE --> SAVE7[保存MD处理结果]
    
    SAVE1 --> SUCCESS{处理成功?}
    SAVE2 --> SUCCESS
    SAVE3 --> SUCCESS
    SAVE4 --> SUCCESS
    SAVE5 --> SUCCESS
    SAVE6 --> SUCCESS
    SAVE7 --> SUCCESS
    
    SUCCESS -->|是| CONTINUE{继续处理?}
    SUCCESS -->|否| ERROR[记录错误信息]
    
    CONTINUE -->|是| STAGE
    CONTINUE -->|否| END
    
    ERROR --> STAGE
    HELP --> END
    END
```

## 阶段1: RSS获取详细流程

```mermaid
flowchart TD
    FETCH_START[阶段1: RSS获取] --> LOAD_CONFIG[加载配置文件<br/>subject_bibliography.yaml]
    
    LOAD_CONFIG --> PARSE_SOURCES[解析RSS源配置]
    
    PARSE_SOURCES --> CATEGORIZE{分类RSS源}
    
    CATEGORIZE -->|常规RSS| REGULAR_FEED[常规RSS源]
    CATEGORIZE -->|RSSHub协议| RSSHUB_FEED[RSSHub源]
    CATEGORIZE -->|动态网站| PLAYWRIGHT_SITE[Playwright网站]
    
    REGULAR_FEED --> INIT_RSS[初始化RSSFetcher]
    RSSHUB_FEED --> INIT_RSSHUB[初始化RSSHubFetcher]
    PLAYWRIGHT_SITE --> INIT_PLAYWRIGHT[初始化PlaywrightSiteFetcher]
    
    INIT_RSS --> FETCH_RSS[抓取常规RSS]
    INIT_RSSHUB --> FETCH_RSSHUB[抓取RSSHub源]
    INIT_PLAYWRIGHT --> FETCH_PLAYWRIGHT[抓取动态网站]
    
    FETCH_RSSHUB --> CONVERT_URL[转换rsshub://为HTTP URL]
    CONVERT_URL --> TRY_INSTANCES[尝试多个RSSHub实例<br/>故障转移机制]
    
    FETCH_RSS --> RETRY_MECHANISM[重试机制<br/>主URL + 备用URL]
    FETCH_PLAYWRIGHT --> SETUP_BROWSER[启动无头浏览器<br/>模拟移动设备]
    
    TRY_INSTANCES --> PARSE_FEED[解析RSS Feed]
    RETRY_MECHANISM --> PARSE_FEED
    SETUP_BROWSER --> SCROLL_LOAD[滚动加载内容]
    
    PARSE_FEED --> TIME_FILTER[时间范围过滤]
    SCROLL_LOAD --> EXTRACT_ELEMENTS[提取页面元素]
    
    TIME_FILTER --> GENERATE_ID[生成唯一文章ID]
    EXTRACT_ELEMENTS --> EXTRACT_CONTENT[提取标题、链接、时间]
    
    GENERATE_ID --> BUILD_ARTICLE[构建文章数据结构]
    EXTRACT_CONTENT --> BUILD_ARTICLE
    
    BUILD_ARTICLE --> DEDUPLICATE[去重检查<br/>基于ID/URL/标题+时间]
    DEDUPLICATE --> SAVE_RESULTS[保存到按月聚合文件]
    
    SAVE_RESULTS --> FETCH_END[阶段1完成]
```

## 阶段2: 全文解析详细流程

```mermaid
flowchart TD
    EXTRACT_START[阶段2: 全文解析] --> LOAD_FETCH_DATA[加载阶段1数据]
    
    LOAD_FETCH_DATA --> CHECK_EXTRACT_STATUS[检查提取状态]
    
    CHECK_EXTRACT_STATUS --> FILTER_NEED_EXTRACT[筛选需要提取的文章<br/>full_text为空或提取失败]
    
    FILTER_NEED_EXTRACT --> INIT_EXTRACTOR[初始化提取器工厂]
    
    INIT_EXTRACTOR --> FOR_EACH_ARTICLE[遍历需要提取的文章]
    
    FOR_EACH_ARTICLE --> GET_EXTRACTOR{获取对应提取器}
    
    GET_EXTRACTOR -->|找到提取器| EXTRACT_FULL_TEXT[调用提取器获取全文]
    GET_EXTRACTOR -->|未找到提取器| MARK_SKIPPED[标记为跳过<br/>缺少提取器]
    
    EXTRACT_FULL_TEXT --> EXTRACTOR_SUCCESS{提取成功?}
    
    EXTRACTOR_SUCCESS -->|是| UPDATE_STATUS[更新提取状态为success]
    EXTRACTOR_SUCCESS -->|否| UPDATE_STATUS_FAILED[更新提取状态为failed<br/>记录错误信息]
    
    UPDATE_STATUS --> SAVE_INCREMENTAL[增量保存结果<br/>单条即时保存策略]
    UPDATE_STATUS_FAILED --> SAVE_INCREMENTAL
    
    MARK_SKIPPED --> SAVE_INCREMENTAL
    
    SAVE_INCREMENTAL --> NEXT_ARTICLE{还有更多文章?}
    
    NEXT_ARTICLE -->|是| FOR_EACH_ARTICLE
    NEXT_ARTICLE -->|否| RETRY_FAILED[兜底重试机制<br/>重新提取失败的文章]
    
    RETRY_FAILED --> FINAL_SAVE[最终保存结果]
    FINAL_SAVE --> EXTRACT_END[阶段2完成]
    
    EXTRACT_FULL_TEXT --> CONTENT_CLEANING[内容清洗<br/>去除HTML标签、格式化]
    CONTENT_CLEANING --> UPDATE_STATUS
```

## 阶段3: 文章过滤详细流程

```mermaid
flowchart TD
    FILTER_START[阶段3: 文章过滤] --> LOAD_EXTRACT_DATA[加载阶段2数据]
    
    LOAD_EXTRACT_DATA --> CHECK_FILTER_STATUS[检查过滤状态<br/>filter_status字段]
    
    CHECK_FILTER_STATUS --> FILTER_UNPROCESSED[筛选未处理文章<br/>提取成功且未过滤]
    
    FILTER_UNPROCESSED --> INIT_FILTER[初始化ArticleFilter]
    
    INIT_FILTER --> FOR_EACH_ARTICLE_FILTER[遍历需要过滤的文章]
    
    FOR_EACH_ARTICLE_FILTER --> PREPARE_CONTENT[准备过滤内容<br/>标题 + 前1000字符]
    
    PREPARE_CONTENT --> CALL_LLM_FILTER[调用LLM进行初筛<br/>使用article_filter任务]
    
    CALL_LLM_FILTER --> PARSE_LLM_RESPONSE[解析LLM返回结果<br/>JSON格式]
    
    PARSE_LLM_RESPONSE --> PARSE_SUCCESS{解析成功?}
    
    PARSE_SUCCESS -->|是| CHECK_PASS{过滤结果}
    
    PARSE_SUCCESS -->|否| MARK_FILTER_FAILED[标记为失败<br/>JSON解析错误]
    
    CHECK_PASS -->|通过| MARK_PASS[标记为通过<br/>filter_pass=true]
    CHECK_PASS -->|拒绝| MARK_REJECT[标记为拒绝<br/>filter_pass=false<br/>记录拒绝理由]
    
    MARK_PASS --> UPDATE_FILTER_STATUS[更新filter_status为"成功"]
    MARK_REJECT --> UPDATE_FILTER_STATUS[更新filter_status为"已拒绝"]
    MARK_FILTER_FAILED --> UPDATE_FILTER_STATUS[更新filter_status为"失败"]
    
    UPDATE_FILTER_STATUS --> SAVE_FILTER_RESULT[保存过滤结果<br/>即时保存策略]
    
    SAVE_FILTER_RESULT --> NEXT_FILTER{还有更多文章?}
    
    NEXT_FILTER -->|是| FOR_EACH_ARTICLE_FILTER
    NEXT_FILTER -->|否| FILTER_END[阶段3完成]
    
    FILTER_UNPROCESSED --> CONTENT_CHECK[内容完整性检查<br/>确保有full_text或content]
    CONTENT_CHECK -->|缺少内容| SKIP_NO_CONTENT[跳过并标记原因]
    CONTENT_CHECK -->|有内容| FOR_EACH_ARTICLE_FILTER
    
    SKIP_NO_CONTENT --> SAVE_FILTER_RESULT
```

## 阶段4: 文章总结详细流程

```mermaid
flowchart TD
    SUMMARY_START[阶段4: 文章总结] --> LOAD_FILTER_DATA[加载阶段3数据]
    
    LOAD_FILTER_DATA --> SELECT_PASSED_ARTICLES[筛选通过过滤的文章<br/>filter_pass=true]
    
    SELECT_PASSED_ARTICLES --> CHECK_SUMMARY_STATUS[检查总结状态<br/>llm_summary_status]
    
    CHECK_SUMMARY_STATUS --> FILTER_NEED_SUMMARY[筛选需要总结的文章<br/>状态非"成功"且有内容]
    
    FILTER_NEED_SUMMARY --> INIT_SUMMARY_AGENT[初始化ArticleSummaryAgent]
    
    INIT_SUMMARY_AGENT --> FOR_EACH_ARTICLE_SUM[遍历需要总结的文章]
    
    FOR_EACH_ARTICLE_SUM --> BUILD_SUMMARY_PROMPT[构建总结提示词<br/>标题 + 来源 + 正文]
    
    BUILD_SUMMARY_PROMPT --> CALL_LLM_SUMMARY[调用LLM进行总结<br/>使用article_summary任务]
    
    CALL_LLM_SUMMARY --> PROCESS_LLM_OUTPUT[处理LLM输出<br/>JSON或文本格式]
    
    PROCESS_LLM_OUTPUT --> VALIDATE_SUMMARY{总结结果有效?}
    
    VALIDATE_SUMMARY -->|是| SAVE_SUMMARY[保存总结结果<br/>llm_summary字段]
    VALIDATE_SUMMARY -->|否| SAVE_SUMMARY_ERROR[保存错误信息<br/>llm_summary_error字段]
    
    SAVE_SUMMARY --> UPDATE_SUMMARY_STATUS[更新总结状态为"成功"]
    SAVE_SUMMARY_ERROR --> UPDATE_SUMMARY_STATUS[更新总结状态为"失败"]
    
    UPDATE_SUMMARY_STATUS --> SAVE_SUMMARY_RESULT[保存总结结果<br/>即时保存策略]
    
    SAVE_SUMMARY_RESULT --> RETRY_FAILED_SUMMARY{重试失败文章?}
    
    RETRY_FAILED_SUMMARY -->|是| RETRY_SUMMARY[兜底重试机制<br/>最多2次重试]
    RETRY_FAILED_SUMMARY -->|否| NEXT_SUMMARY{还有更多文章?}
    
    RETRY_SUMMARY --> CALL_LLM_SUMMARY
    NEXT_SUMMARY -->|是| FOR_EACH_ARTICLE_SUM
    NEXT_SUMMARY -->|否| SUMMARY_END[阶段4完成]
    
    FILTER_NEED_SUMMARY --> CONTENT_VALIDATION[内容验证<br/>确保有full_text或content]
    CONTENT_VALIDATION -->|内容不足| SKIP_INSUFFICIENT[跳过并标记原因]
    CONTENT_VALIDATION -->|内容充足| FOR_EACH_ARTICLE_SUM
    
    SKIP_INSUFFICIENT --> SAVE_SUMMARY_RESULT
```

## 阶段5: 深度分析详细流程

```mermaid
flowchart TD
    ANALYSIS_START[阶段5: 深度分析] --> LOAD_SUMMARY_DATA[加载阶段4数据]
    
    LOAD_SUMMARY_DATA --> SELECT_SUMMARIZED[筛选已完成总结的文章<br/>llm_summary_status="成功"]
    
    SELECT_SUMMARIZED --> CHECK_ANALYSIS_STATUS[检查分析状态<br/>llm_analysis_status]
    
    CHECK_ANALYSIS_STATUS --> FILTER_NEED_ANALYSIS[筛选需要分析的文章<br/>状态非"成功"]
    
    FILTER_NEED_ANALYSIS --> INIT_ANALYST[初始化ArticleAnalyst]
    
    INIT_ANALYST --> FOR_EACH_ARTICLE_ANALYZE[遍历需要分析的文章]
    
    FOR_EACH_ARTICLE_ANALYZE --> PREPARE_ANALYSIS[准备分析内容<br/>基于llm_summary]
    
    PREPARE_ANALYSIS --> CALL_LLM_ANALYSIS[调用LLM进行深度分析<br/>使用article_analysis任务]
    
    CALL_LLM_ANALYSIS --> PARSE_ANALYSIS_RESULT[解析分析结果<br/>JSON格式提取多维度信息]
    
    PARSE_ANALYSIS_RESULT --> EXTRACT_FIELDS{提取结构化字段}
    
    EXTRACT_FIELDS -->|成功| EXTRACT_SCORE[提取评分0-100]
    EXTRACT_FIELDS -->|失败| MARK_ANALYSIS_ERROR[标记为分析失败]
    
    EXTRACT_SCORE --> EXTRACT_DIMENSION[提取主要维度<br/>四大原则之一]
    EXTRACT_DIMENSION --> EXTRACT_TOPIC[提取主题聚焦<br/>50字用于聚类]
    EXTRACT_TOPIC --> EXTRACT_THEME[提取母题本质<br/>150-200字用于向量库]
    
    EXTRACT_THEME --> EXTRACT_TAGS[提取标签列表<br/>JSON数组格式]
    EXTRACT_TAGS --> EXTRACT_BOOKS[提取提及书籍<br/>JSON数组格式]
    
    EXTRACT_BOOKS --> SAVE_ANALYSIS_DATA[保存分析数据<br/>多字段更新]
    MARK_ANALYSIS_ERROR --> SAVE_ANALYSIS_ERROR[保存错误信息]
    
    SAVE_ANALYSIS_DATA --> UPDATE_ANALYSIS_STATUS[更新分析状态为"成功"]
    SAVE_ANALYSIS_ERROR --> UPDATE_ANALYSIS_STATUS[更新分析状态为"失败"]
    
    UPDATE_ANALYSIS_STATUS --> SAVE_ANALYSIS_RESULT[保存分析结果<br/>即时保存策略]
    
    SAVE_ANALYSIS_RESULT --> RETRY_FAILED_ANALYSIS{重试失败文章?}
    
    RETRY_FAILED_ANALYSIS -->|是| RETRY_ANALYSIS[兜底重试机制<br/>最多2次重试]
    RETRY_FAILED_ANALYSIS -->|否| NEXT_ANALYSIS{还有更多文章?}
    
    RETRY_ANALYSIS --> CALL_LLM_ANALYSIS
    NEXT_ANALYSIS -->|是| FOR_EACH_ARTICLE_ANALYZE
    NEXT_ANALYSIS -->|否| SCORE_STATISTICS[生成评分统计分析]
    
    SCORE_STATISTICS --> ANALYSIS_END[阶段5完成]
```

## 存储管理详细流程

```mermaid
flowchart TD
    STORAGE_START[存储管理] --> DETECT_MONTH[根据文章日期确定月份<br/>生成YYYY-MM.xlsx文件名]
    
    DETECT_MONTH --> CHECK_EXISTING[检查现有文件是否存在]
    
    CHECK_EXISTING -->|存在| LOAD_EXISTING[加载现有Excel数据]
    CHECK_EXISTING -->|不存在| CREATE_NEW[创建新的Excel文件]
    
    LOAD_EXISTING --> DEDUPLICATE_CHECK[去重检查<br/>基于ID/URL/标题+时间组合]
    
    DEDUPLICATE_CHECK --> MERGE_DATA[合并新旧数据<br/>保留所有字段]
    
    CREATE_NEW --> PREPARE_STRUCTURE[准备数据结构<br/>定义标准字段顺序]
    
    MERGE_DATA --> NORMALIZE_COLUMNS[标准化列格式<br/>布尔值、日期时间处理]
    PREPARE_STRUCTURE --> NORMALIZE_COLUMNS
    
    NORMALIZE_COLUMNS --> EXCEL_SAVE[保存到Excel文件<br/>使用pandas]
    
    EXCEL_SAVE --> VERIFY_SAVE{保存验证}
    
    VERIFY_SAVE -->|成功| STORAGE_SUCCESS[存储成功<br/>返回文件路径]
    VERIFY_SAVE -->|失败| STORAGE_ERROR[存储失败<br/>记录错误信息]
    
    STORAGE_SUCCESS --> STORAGE_END[存储流程完成]
    STORAGE_ERROR --> RETRY_STORAGE{重试存储?}
    
    RETRY_STORAGE -->|是| EXCEL_SAVE
    RETRY_STORAGE -->|否| STORAGE_END
    
    DEDUPLICATE_CHECK --> CHECK_DUPLICATE{发现重复?}
    CHECK_DUPLICATE -->|是| SKIP_DUPLICATE[跳过重复数据<br/>记录统计信息]
    CHECK_DUPLICATE -->|否| MERGE_DATA
    
    SKIP_DUPLICATE --> MERGE_DATA
```

这个流程图详细展示了系统各个阶段的处理逻辑，包括数据流转、错误处理、重试机制和存储管理。系统采用了增量处理、即时保存和兜底重试的策略，确保了处理的可靠性和数据的安全性。